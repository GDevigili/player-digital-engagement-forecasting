{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "(arranjar um nome melhor para o notebook)\n",
    "\n",
    "Notebook para o treinamento de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-25 18:44:27.113971: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-25 18:44:27.219147: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-25 18:44:27.219164: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-03-25 18:44:27.788334: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-25 18:44:27.788417: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-25 18:44:27.788423: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# models\n",
    "import sklearn\n",
    "import sktime\n",
    "import keras\n",
    "import statsmodels.api as sm\n",
    "from sktime.forecasting.naive import NaiveForecaster\n",
    "from sktime.forecasting.exp_smoothing import ExponentialSmoothing\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# model selection and metrics\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sktime.forecasting.model_selection import temporal_train_test_split\n",
    "from sktime.performance_metrics.forecasting import MeanAbsoluteError\n",
    "\n",
    "# variables\n",
    "processed_data_path = '../data/processed-data/'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxiliary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_time_series(df, groupby = 'median', cols = ['target1', 'target2', 'target3', 'target4']):\n",
    "    df_melted = df.groupby('Dt').median()[cols]\\\n",
    "    .melt(var_name='target', value_name='value', ignore_index=False)\n",
    "    df_melted.reset_index(inplace=True)\n",
    "\n",
    "    sns.set(rc={'figure.figsize':(10,20)})\n",
    "    sns.FacetGrid(df_melted, col='target', col_wrap=2, height=9,aspect=2, sharey=False)\\\n",
    "    .map(sns.lineplot, 'Dt', 'value');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_test_pred(train, test, pred = pd.DataFrame(), groupby = 'median', cols = ['target1', 'target2', 'target3', 'target4']):\n",
    "    train['type'] = 'train'\n",
    "    test['type'] = 'test'\n",
    "    pred['type'] = 'pred'\n",
    "    \n",
    "    cols.append('type')\n",
    "\n",
    "    df = pd.concat([train, test, pred], axis=0)\n",
    "    df_melted = df.groupby('Dt').median()[cols]\\\n",
    "        .melt(var_name='target', value_name='value', ignore_index=False)\n",
    "    df_melted.reset_index(inplace=True)\n",
    "    \n",
    "    sns.set(rc={'figure.figsize':(10,20)})\n",
    "    sns.FacetGrid(df_melted, col='target', col_wrap=2, height=9,aspect=2, sharey=False)\\\n",
    "        .map(sns.lineplot, 'Dt', 'value', hue='type');"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "Apenas realizar modificações necessárias para os modelos como *splitting* dos datasets e normalização. Toda a limpeza de dados deve ser feita em **/src/data-engineering/data-preparation**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_targets = pd.read_pickle(processed_data_path + 'targets.pkl')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = ['target1', 'target2', 'target3', 'target4']\n",
    "train = df_targets[df_targets['Dt'] <= '2021-04-30']\n",
    "y_train = train[target_cols]\n",
    "x_train = train.drop(target_cols, axis=1)\n",
    "test = df_targets[df_targets['Dt'] > '2021-04-30']\n",
    "y_test = test[target_cols]\n",
    "x_test = test.drop(target_cols, axis=1)\n",
    "del df_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2506176, 7)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(189612, 7)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train, test, y_cols = ['target1', 'target2', 'target3', 'target4']):\n",
    "    results = {}\n",
    "    for col in y_cols:\n",
    "        y_train = train[col].set_axis(train['Dt'])\n",
    "        y_test = test[col].set_axis(test['Dt'])\n",
    "        model.fit(y_train)\n",
    "        pred = model.predict(y_test)\n",
    "        results[col] = pred\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_baseline_model(model, train, fh_size, y_cols = ['target1', 'target2', 'target3', 'target4']):\n",
    "    results = {}\n",
    "    fh = np.arange(len(fh_size)) + 1\n",
    "    for col in y_cols:\n",
    "        y_train = train[col].set_axis(train['Dt'])\n",
    "        model.fit(y_train)\n",
    "        pred = model.predict(fh)\n",
    "        results[col] = pred\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2506176 entries, 0 to 2506175\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Dtype         \n",
      "---  ------      -----         \n",
      " 0   Dt          datetime64[ns]\n",
      " 1   IdPlayer    int64         \n",
      " 2   target1     float32       \n",
      " 3   target2     float32       \n",
      " 4   target3     float32       \n",
      " 5   target4     float32       \n",
      " 6   IdDtPlayer  object        \n",
      "dtypes: datetime64[ns](1), float32(4), int64(1), object(1)\n",
      "memory usage: 114.7+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Naive\n",
    "# naive = NaiveForecaster(strategy='last').fit(train)\n",
    "# y_pred_naive = naive.predict(test)\n",
    "\n",
    "# # Mean\n",
    "# mean = NaiveForecaster(strategy=\"mean\").fit(train)\n",
    "# y_pred_mean = mean.predict(test)\n",
    "\n",
    "# # Drift\n",
    "# drift = NaiveForecaster(strategy=\"drift\").fit(train)\n",
    "# y_pred_drift = drift.predict(test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_value(train, dt, id_player, target):\n",
    "    last_date = train['Dt'].max()\n",
    "    return train[train['IdDtPlayer'] == str(last_date) + '_' + str(id_player)]\n",
    "    # return train[train['Dt'] == last_date][id_player].values[0]\n",
    "\n",
    "def NaiveForecaster(train, x_test):\n",
    "    y_pred = pd.DataFrame()\n",
    "    for idx, row in x_test.iterrows():\n",
    "        pred_targets = {}\n",
    "        id_player = row['IdPlayer']\n",
    "        dt = row['Dt']\n",
    "        for target in target_cols:\n",
    "            pred_targets[target] = get_last_value(train, dt, id_player, target)\n",
    "        y_pred = y_pred.concat(pred_targets, ignore_index=True)\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### testing the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train[train['IdPlayer'] == 663399].head(1)\n",
      "             Dt  IdPlayer  target1  target2  target3   target4  \\\n",
      "2059 2018-01-01    663399      0.0      0.0      0.0  0.098039   \n",
      "\n",
      "                      IdDtPlayer  \n",
      "2059  2018-01-01 00:00:00_663399  \n",
      "\n",
      "test[test['IdPlayer'] == 663399].head(1)\n",
      "                Dt  IdPlayer   target1   target2  target3   target4  \\\n",
      "2508214 2021-05-01    663399  0.000409  0.107825      0.0  0.158343   \n",
      "\n",
      "                         IdDtPlayer  \n",
      "2508214  2021-05-01 00:00:00_663399  \n",
      "\n",
      "train[train['IdDtPlayer'] == str(train['Dt'].max()) + '_663399']\n",
      "                Dt  IdPlayer   target1   target2  target3   target4  \\\n",
      "2505410 2021-04-30    663399  0.000263  0.089871      0.0  0.136565   \n",
      "\n",
      "                         IdDtPlayer  \n",
      "2505410  2021-04-30 00:00:00_663399  \n",
      "\n",
      "get_last_value(train, '2021-05-02', 663399, 'target1')\n",
      "                Dt  IdPlayer   target1   target2  target3   target4  \\\n",
      "2505410 2021-04-30    663399  0.000263  0.089871      0.0  0.136565   \n",
      "\n",
      "                         IdDtPlayer  \n",
      "2505410  2021-04-30 00:00:00_663399  \n"
     ]
    }
   ],
   "source": [
    "print(\"\\ntrain[train['IdPlayer'] == 663399].head(1)\")\n",
    "print(train[train['IdPlayer'] == 663399].head(1))\n",
    "print(\"\\ntest[test['IdPlayer'] == 663399].head(1)\")\n",
    "print(test[test['IdPlayer'] == 663399].head(1))\n",
    "print(\"\\ntrain[train['IdDtPlayer'] == str(train['Dt'].max()) + '_663399']\")\n",
    "print(train[train['IdDtPlayer'] == str(train['Dt'].max()) + '_663399'])\n",
    "print(\"\\nget_last_value(train, '2021-05-02', 663399, 'target1')\")\n",
    "print(get_last_value(train, '2021-05-02', 663399, 'target1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'concat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/gianlucca/Documents/GitHub/player-digital-engagement-forecasting/src/models/modeling copy.ipynb Cell 24\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/gianlucca/Documents/GitHub/player-digital-engagement-forecasting/src/models/modeling%20copy.ipynb#X61sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m y_pred_naive \u001b[39m=\u001b[39m NaiveForecaster(train, x_test)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/gianlucca/Documents/GitHub/player-digital-engagement-forecasting/src/models/modeling%20copy.ipynb#X61sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m y_pred_naive\n",
      "\u001b[1;32m/home/gianlucca/Documents/GitHub/player-digital-engagement-forecasting/src/models/modeling copy.ipynb Cell 24\u001b[0m in \u001b[0;36mNaiveForecaster\u001b[0;34m(train, x_test)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gianlucca/Documents/GitHub/player-digital-engagement-forecasting/src/models/modeling%20copy.ipynb#X61sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39mfor\u001b[39;00m target \u001b[39min\u001b[39;00m target_cols:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gianlucca/Documents/GitHub/player-digital-engagement-forecasting/src/models/modeling%20copy.ipynb#X61sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m         pred_targets[target] \u001b[39m=\u001b[39m get_last_value(train, dt, id_player, target)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/gianlucca/Documents/GitHub/player-digital-engagement-forecasting/src/models/modeling%20copy.ipynb#X61sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     y_pred \u001b[39m=\u001b[39m y_pred\u001b[39m.\u001b[39;49mconcat(pred_targets, ignore_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gianlucca/Documents/GitHub/player-digital-engagement-forecasting/src/models/modeling%20copy.ipynb#X61sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mreturn\u001b[39;00m y_pred\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/generic.py:5575\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5568\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   5569\u001b[0m     name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_internal_names_set\n\u001b[1;32m   5570\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metadata\n\u001b[1;32m   5571\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accessors\n\u001b[1;32m   5572\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info_axis\u001b[39m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[1;32m   5573\u001b[0m ):\n\u001b[1;32m   5574\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m[name]\n\u001b[0;32m-> 5575\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mobject\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__getattribute__\u001b[39;49m(\u001b[39mself\u001b[39;49m, name)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'concat'"
     ]
    }
   ],
   "source": [
    "y_pred_naive = NaiveForecaster(train, x_test)\n",
    "y_pred_naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
