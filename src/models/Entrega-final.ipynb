{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Fundação Getúlio Vargas - RJ <br>\n",
    "> Escola de Matemática Aplicada (EMAp) <br>\n",
    "> Graduação em Ciência de Dados e Inteligência Artificial <br>\n",
    "> Alunos: Gianlucca Devigili e Maisa O. Fraiz <br>\n",
    "# Projetos em Ciência de Dados - A1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instruções de execução\n",
    "\n",
    "__(#1)__ De modo a tornar mais rápida a carga dos dados, o projeto utiliza uma cópia dos arquivos em formato pickle (`.pkl`). Para executar o projeto utilizando o o dataset em formato `.csv`, atribua o valor `True` para a variável `V_load_from_csv`\n",
    "\n",
    "**(#2)** Redefina a variável `raw_data_path` para o caminho até o arquivo `train_updated.csv`. Substitua o nome do arquivo caso necessário.\n",
    "\n",
    "**(#3)** Atribua o valor `True` para a variável `save_files` caso ainda não tenha os arquivos `.pkl` dos datasets auxiliares salvos. (Necessário apenas para a primeira execução da sessão de preparação de dados).\n",
    "\n",
    "**(#4)** Atribua o valor `True` para a variável `prepare_data` caso deseje executar a sessão de preparação de dados. (Necessário apenas para a primeira execução da sessão de preparação de dados). Caso contrário as variáveis serão carregadas a partir dos arquivos `.pkl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Variáveis de configuração\n",
    "# (#1) Variável que define se o dataset será carregado de um .csv ou de um .pkl\n",
    "load_from_csv = False\n",
    "\n",
    "# Caminho para o dataset\n",
    "raw_data_path = '../data/raw-data/'\n",
    "dataset_path = raw_data_path + 'train_updated.csv'\n",
    "\n",
    "# Caminho onde serão salvos os dados processados\n",
    "processed_data_path = '../data/processed-data/'\n",
    "\n",
    "# Prepare data\n",
    "# (#4) Variável que define se o dataset será processado ou se será carregado de um .pkl\n",
    "prepare_data = False\n",
    "\n",
    "save_files = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Setup Inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pickle as pkl\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "# disable warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variáveis globais\n",
    "\n",
    "PROCESSED_DATA_PATH = '../data/processed-data/'\n",
    "MODEL_PATH = '../models/trained-models/'\n",
    "\n",
    "TARGET_COLS = ['target1', 'target2', 'target3', 'target4']\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "TEST_SPLIT_DATE = '2021-04-30'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparação dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funções Auxiliares\n",
    "\n",
    "Algumas funções utilizadas para a preparação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funções auxiliares para carregar os dados\n",
    "def unpack_json(json_str):\n",
    "    return pd.DataFrame() if pd.isna(json_str) else pd.read_json(json_str)\n",
    "\n",
    "def unpack_data(data, dfs=None, n_jobs=-1):\n",
    "    if dfs is not None:\n",
    "        data = data.loc[:, dfs]\n",
    "    unnested_dfs = {}\n",
    "    for name, column in data.iteritems():\n",
    "        daily_dfs = Parallel(n_jobs=n_jobs)(\n",
    "            delayed(unpack_json)(item) for date, item in column.iteritems())\n",
    "        df = pd.concat(daily_dfs)\n",
    "        unnested_dfs[name] = df\n",
    "    return unnested_dfs\n",
    "\n",
    "def create_id(df, id_cols, id_col_name, dt_col_name = 'Dt'):\n",
    "    df['Id' + dt_col_name + id_col_name] = df[id_cols].apply(lambda x: '_'.join(x.astype(str)), axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# (#1)\n",
    "if load_from_csv:\n",
    "    df_train = pd.read_csv(dataset_path)\n",
    "else: \n",
    "    dataset_path = raw_data_path + 'train.pkl'\n",
    "    df_train = pd.read_pickle(dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cria o Dataframe Targets\n",
    "\n",
    "Dataframe contendo as 4 variáveis _target_ bem como suas respectivas chaves `IdPlayer` e `Dt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n",
      "Compiler : 126 ms\n",
      "Parser   : 659 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "if prepare_data:\n",
    "    # criação do dataset de targets\n",
    "    # unpack the data\n",
    "    Y = unpack_data(df_train, dfs = ['nextDayPlayerEngagement'])['nextDayPlayerEngagement']\n",
    "\n",
    "    # change datatypes\n",
    "    Y = Y.astype({name: np.float32 for name in [\"target1\", \"target2\", \"target3\", \"target4\"]})\n",
    "\n",
    "    # match target dates to feature dates and create date index\n",
    "    Y = Y.rename(columns={'engagementMetricsDate': 'date'})\n",
    "\n",
    "    # change datatypes\n",
    "    Y['date'] = pd.to_datetime(Y['date'])\n",
    "\n",
    "    # reset index\n",
    "    Y = Y.set_index('date').to_period('D')\n",
    "    Y.index = Y.index - 1\n",
    "    Y = Y.reset_index()\n",
    "\n",
    "    # rename and select columns\n",
    "    cols_Y = {\n",
    "        'date': 'Dt',\n",
    "        'playerId': 'IdPlayer',\n",
    "        'target1': 'target1',\n",
    "        'target2': 'target2',\n",
    "        'target3': 'target3',\n",
    "        'target4': 'target4'\n",
    "    }\n",
    "    Y = Y[list(cols_Y)]\n",
    "    Y.columns = list(cols_Y.values())\n",
    "    Y['Dt'] = Y['Dt'].astype('datetime64[ns]')\n",
    "    Y = create_id(Y, ['Dt', 'IdPlayer'], 'Player')\n",
    "\n",
    "    if save_files:\n",
    "        pd.to_pickle(Y, processed_data_path + 'targets.pkl')\n",
    "\n",
    "    del Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cria o Dataframe Player Box Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if prepare_data:\n",
    "    # load the data\n",
    "    df_playerBoxScores = unpack_data(df_train, dfs = ['playerBoxScores'])['playerBoxScores']\n",
    "\n",
    "    # Cria o dataset de jogos\n",
    "    cols = {\n",
    "        # columns related to other dimensions\n",
    "        'gamePk': 'IdGame',\n",
    "        'gameDate': 'DtGame',\n",
    "        'gameTimeUTC': 'DtGameUTC',\n",
    "        'playerId': 'IdPlayer',\n",
    "        'teamId': 'IdTeam',\n",
    "        'jerseyNum': 'NuJersey',\n",
    "        'positionCode': 'CdPosition',\n",
    "        # suggested column\n",
    "        'strikeOutsPitching': 'NuStrikeOutsPitching',\n",
    "    }  \n",
    "    # numeric columns\n",
    "    for numeric_col in list(df_playerBoxScores.columns[12:]):\n",
    "        # skip the columns that contains data about pitching due the amount of Nan values\n",
    "        if 'Pitching' not in numeric_col:\n",
    "            cols[numeric_col] = 'Nu' + numeric_col[0].upper() + numeric_col[1:]\n",
    "\n",
    "    df_playerBoxScores['gameDate'] = df_playerBoxScores['gameDate'] + \" 00:00:00\"\n",
    "\n",
    "    df_playerBoxScores = df_playerBoxScores[list(cols)]\n",
    "    df_playerBoxScores.columns = list(cols.values())\n",
    "    df_playerBoxScores = create_id(df_playerBoxScores, ['DtGame', 'IdPlayer'], 'Player')\n",
    "\n",
    "    # Salva o dataset\n",
    "    if save_files:\n",
    "        pd.to_pickle(df_playerBoxScores, processed_data_path + 'playerBoxScores.pkl')\n",
    "    del df_playerBoxScores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparação dos dados target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(processed_data_path + 'targets.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funções Auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funções auxiliares para o pré-processamento dos dados\n",
    "def sort_df(df: pd.DataFrame, columns: list = ['IdPlayer', 'Dt']) -> None:\n",
    "    \"\"\"Sort the dataframe by the columns passed as argument.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Dataframe to be sorted.\n",
    "        columns (list, optional): Columns to sort the dataframe. Defaults to ['IdPlayer', 'Dt'].\n",
    "        \n",
    "        Returns:\n",
    "            None\n",
    "    \"\"\"\n",
    "    df.sort_values(by=columns, inplace=True)\n",
    "    # reset index\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "def shift_targets(df, shift_vals: list = [1, 2, 3, 4, 5, 6, 7, 14, 30]):\n",
    "    \"\"\"Shift the targets by the values passed as argument.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Dataframe to be shifted.\n",
    "        shift_vals (list, optional): Values to shift the targets. Defaults to [1, 2, 3, 4, 5, 6, 7, 14, 30].\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Dataframe with the shifted targets.\n",
    "    \"\"\"\n",
    "    df_aux = pd.DataFrame()\n",
    "    # Iterate over players to make the shift only using the player data\n",
    "    for player in df['IdPlayer'].unique():\n",
    "        df_player = df[df['IdPlayer'] == player]\n",
    "        # Iterate over the pre-defined shift values\n",
    "        for shift_val in shift_vals:\n",
    "            # Iterate over the targets\n",
    "            for target in TARGET_COLS:\n",
    "                # Make the shift\n",
    "                df_player[f'{target}_shift_{shift_val}'] = df_player[target].shift(shift_val)\n",
    "        # Concatenate the player data with the rest of the data\n",
    "        df_aux = pd.concat([df_aux, df_player], axis=0)\n",
    "        # Remove the player data from memory\n",
    "        del df_player\n",
    "    # df.dropna(inplace=True)\n",
    "    return df_aux\n",
    "\n",
    "\n",
    "def train_test_split(\n",
    "    df: pd.DataFrame\n",
    "    ,test_split_date: str = TEST_SPLIT_DATE\n",
    "    ):\n",
    "    \"\"\"Split the dataframe into train and test sets.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Dataframe to be split.\n",
    "        test_split_date (str, optional): Date to split the dataframe. Defaults to TEST_SPLIT_DATE.\n",
    "    \"\"\"\n",
    "\n",
    "    train = df[(df.Dt <= \"2021-01-31\") & (df.Dt >= \"2018-01-01\")] \n",
    "    val = df[(df.Dt <= \"2021-04-30\") & (df.Dt >= \"2021-02-01\")] \n",
    "    test = df[(df.Dt <= \"2021-07-31\") & (df.Dt >= \"2021-05-01\")]\n",
    "    # train.to_csv('train.csv', index=None)\n",
    "    # val.to_csv('validation.csv', index=None) \n",
    "    # test.to_csv('test.csv', index=None) \n",
    "\n",
    "    return train, test, val\n",
    "\n",
    "\n",
    "def x_y_split(df: pd.DataFrame, target_cols: list = TARGET_COLS):\n",
    "    \"\"\"Split the dataframe into x and y sets.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Dataframe to be split.\n",
    "    \"\"\"\n",
    "    y = df[target_cols]\n",
    "    x = df.drop(target_cols, axis=1)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordenação dos valores\n",
    "\n",
    "Os dados serão ordenados por jogador e então por data, para facilitar a criação das variáveis de _shift_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dt</th>\n",
       "      <th>IdPlayer</th>\n",
       "      <th>target1</th>\n",
       "      <th>target2</th>\n",
       "      <th>target3</th>\n",
       "      <th>target4</th>\n",
       "      <th>IdDtPlayer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>112526</td>\n",
       "      <td>0.055277</td>\n",
       "      <td>5.496109</td>\n",
       "      <td>0.025839</td>\n",
       "      <td>16.176470</td>\n",
       "      <td>2018-01-01 00:00:00_112526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>112526</td>\n",
       "      <td>0.060625</td>\n",
       "      <td>3.252914</td>\n",
       "      <td>0.030486</td>\n",
       "      <td>8.541353</td>\n",
       "      <td>2018-01-02 00:00:00_112526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>112526</td>\n",
       "      <td>0.029341</td>\n",
       "      <td>1.648352</td>\n",
       "      <td>0.032613</td>\n",
       "      <td>10.490111</td>\n",
       "      <td>2018-01-03 00:00:00_112526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>112526</td>\n",
       "      <td>0.014799</td>\n",
       "      <td>2.665894</td>\n",
       "      <td>0.087422</td>\n",
       "      <td>19.091467</td>\n",
       "      <td>2018-01-04 00:00:00_112526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>112526</td>\n",
       "      <td>0.083916</td>\n",
       "      <td>1.161002</td>\n",
       "      <td>0.024759</td>\n",
       "      <td>6.643879</td>\n",
       "      <td>2018-01-05 00:00:00_112526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Dt  IdPlayer   target1   target2   target3    target4  \\\n",
       "0 2018-01-01    112526  0.055277  5.496109  0.025839  16.176470   \n",
       "1 2018-01-02    112526  0.060625  3.252914  0.030486   8.541353   \n",
       "2 2018-01-03    112526  0.029341  1.648352  0.032613  10.490111   \n",
       "3 2018-01-04    112526  0.014799  2.665894  0.087422  19.091467   \n",
       "4 2018-01-05    112526  0.083916  1.161002  0.024759   6.643879   \n",
       "\n",
       "                   IdDtPlayer  \n",
       "0  2018-01-01 00:00:00_112526  \n",
       "1  2018-01-02 00:00:00_112526  \n",
       "2  2018-01-03 00:00:00_112526  \n",
       "3  2018-01-04 00:00:00_112526  \n",
       "4  2018-01-05 00:00:00_112526  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sort_df(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dt</th>\n",
       "      <th>IdPlayer</th>\n",
       "      <th>target1</th>\n",
       "      <th>target2</th>\n",
       "      <th>target3</th>\n",
       "      <th>target4</th>\n",
       "      <th>IdDtPlayer</th>\n",
       "      <th>target1_shift_1</th>\n",
       "      <th>target2_shift_1</th>\n",
       "      <th>target3_shift_1</th>\n",
       "      <th>...</th>\n",
       "      <th>target3_shift_5</th>\n",
       "      <th>target4_shift_5</th>\n",
       "      <th>target1_shift_6</th>\n",
       "      <th>target2_shift_6</th>\n",
       "      <th>target3_shift_6</th>\n",
       "      <th>target4_shift_6</th>\n",
       "      <th>target1_shift_7</th>\n",
       "      <th>target2_shift_7</th>\n",
       "      <th>target3_shift_7</th>\n",
       "      <th>target4_shift_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>112526</td>\n",
       "      <td>0.055277</td>\n",
       "      <td>5.496109</td>\n",
       "      <td>0.025839</td>\n",
       "      <td>16.176470</td>\n",
       "      <td>2018-01-01 00:00:00_112526</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>112526</td>\n",
       "      <td>0.060625</td>\n",
       "      <td>3.252914</td>\n",
       "      <td>0.030486</td>\n",
       "      <td>8.541353</td>\n",
       "      <td>2018-01-02 00:00:00_112526</td>\n",
       "      <td>0.055277</td>\n",
       "      <td>5.496109</td>\n",
       "      <td>0.025839</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>112526</td>\n",
       "      <td>0.029341</td>\n",
       "      <td>1.648352</td>\n",
       "      <td>0.032613</td>\n",
       "      <td>10.490111</td>\n",
       "      <td>2018-01-03 00:00:00_112526</td>\n",
       "      <td>0.060625</td>\n",
       "      <td>3.252914</td>\n",
       "      <td>0.030486</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>112526</td>\n",
       "      <td>0.014799</td>\n",
       "      <td>2.665894</td>\n",
       "      <td>0.087422</td>\n",
       "      <td>19.091467</td>\n",
       "      <td>2018-01-04 00:00:00_112526</td>\n",
       "      <td>0.029341</td>\n",
       "      <td>1.648352</td>\n",
       "      <td>0.032613</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>112526</td>\n",
       "      <td>0.083916</td>\n",
       "      <td>1.161002</td>\n",
       "      <td>0.024759</td>\n",
       "      <td>6.643879</td>\n",
       "      <td>2018-01-05 00:00:00_112526</td>\n",
       "      <td>0.014799</td>\n",
       "      <td>2.665894</td>\n",
       "      <td>0.087422</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Dt  IdPlayer   target1   target2   target3    target4  \\\n",
       "0 2018-01-01    112526  0.055277  5.496109  0.025839  16.176470   \n",
       "1 2018-01-02    112526  0.060625  3.252914  0.030486   8.541353   \n",
       "2 2018-01-03    112526  0.029341  1.648352  0.032613  10.490111   \n",
       "3 2018-01-04    112526  0.014799  2.665894  0.087422  19.091467   \n",
       "4 2018-01-05    112526  0.083916  1.161002  0.024759   6.643879   \n",
       "\n",
       "                   IdDtPlayer  target1_shift_1  target2_shift_1  \\\n",
       "0  2018-01-01 00:00:00_112526              NaN              NaN   \n",
       "1  2018-01-02 00:00:00_112526         0.055277         5.496109   \n",
       "2  2018-01-03 00:00:00_112526         0.060625         3.252914   \n",
       "3  2018-01-04 00:00:00_112526         0.029341         1.648352   \n",
       "4  2018-01-05 00:00:00_112526         0.014799         2.665894   \n",
       "\n",
       "   target3_shift_1  ...  target3_shift_5  target4_shift_5  target1_shift_6  \\\n",
       "0              NaN  ...              NaN              NaN              NaN   \n",
       "1         0.025839  ...              NaN              NaN              NaN   \n",
       "2         0.030486  ...              NaN              NaN              NaN   \n",
       "3         0.032613  ...              NaN              NaN              NaN   \n",
       "4         0.087422  ...              NaN              NaN              NaN   \n",
       "\n",
       "   target2_shift_6  target3_shift_6  target4_shift_6  target1_shift_7  \\\n",
       "0              NaN              NaN              NaN              NaN   \n",
       "1              NaN              NaN              NaN              NaN   \n",
       "2              NaN              NaN              NaN              NaN   \n",
       "3              NaN              NaN              NaN              NaN   \n",
       "4              NaN              NaN              NaN              NaN   \n",
       "\n",
       "   target2_shift_7  target3_shift_7  target4_shift_7  \n",
       "0              NaN              NaN              NaN  \n",
       "1              NaN              NaN              NaN  \n",
       "2              NaN              NaN              NaN  \n",
       "3              NaN              NaN              NaN  \n",
       "4              NaN              NaN              NaN  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = shift_targets(df, shift_vals=[1, 2, 3, 4, 5, 6, 7])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cria dados com playerBoxScores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_playerBoxScores = pd.read_pickle(processed_data_path + 'playerBoxScores.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2698457 entries, 0 to 2698456\n",
      "Data columns (total 88 columns):\n",
      " #   Column                    Non-Null Count    Dtype         \n",
      "---  ------                    --------------    -----         \n",
      " 0   Dt                        2698457 non-null  datetime64[ns]\n",
      " 1   IdPlayer_x                2698457 non-null  int64         \n",
      " 2   target1                   2698457 non-null  float32       \n",
      " 3   target2                   2698457 non-null  float32       \n",
      " 4   target3                   2698457 non-null  float32       \n",
      " 5   target4                   2698457 non-null  float32       \n",
      " 6   IdDtPlayer                2698457 non-null  object        \n",
      " 7   target1_shift_1           2696396 non-null  float32       \n",
      " 8   target2_shift_1           2696396 non-null  float32       \n",
      " 9   target3_shift_1           2696396 non-null  float32       \n",
      " 10  target4_shift_1           2696396 non-null  float32       \n",
      " 11  target1_shift_2           2694335 non-null  float32       \n",
      " 12  target2_shift_2           2694335 non-null  float32       \n",
      " 13  target3_shift_2           2694335 non-null  float32       \n",
      " 14  target4_shift_2           2694335 non-null  float32       \n",
      " 15  target1_shift_3           2692274 non-null  float32       \n",
      " 16  target2_shift_3           2692274 non-null  float32       \n",
      " 17  target3_shift_3           2692274 non-null  float32       \n",
      " 18  target4_shift_3           2692274 non-null  float32       \n",
      " 19  target1_shift_4           2690213 non-null  float32       \n",
      " 20  target2_shift_4           2690213 non-null  float32       \n",
      " 21  target3_shift_4           2690213 non-null  float32       \n",
      " 22  target4_shift_4           2690213 non-null  float32       \n",
      " 23  target1_shift_5           2688152 non-null  float32       \n",
      " 24  target2_shift_5           2688152 non-null  float32       \n",
      " 25  target3_shift_5           2688152 non-null  float32       \n",
      " 26  target4_shift_5           2688152 non-null  float32       \n",
      " 27  target1_shift_6           2686091 non-null  float32       \n",
      " 28  target2_shift_6           2686091 non-null  float32       \n",
      " 29  target3_shift_6           2686091 non-null  float32       \n",
      " 30  target4_shift_6           2686091 non-null  float32       \n",
      " 31  target1_shift_7           2684030 non-null  float32       \n",
      " 32  target2_shift_7           2684030 non-null  float32       \n",
      " 33  target3_shift_7           2684030 non-null  float32       \n",
      " 34  target4_shift_7           2684030 non-null  float32       \n",
      " 35  IdGame                    218800 non-null   float64       \n",
      " 36  DtGame                    218800 non-null   object        \n",
      " 37  DtGameUTC                 218800 non-null   object        \n",
      " 38  IdPlayer_y                218800 non-null   float64       \n",
      " 39  IdTeam                    218800 non-null   float64       \n",
      " 40  NuJersey                  218763 non-null   object        \n",
      " 41  CdPosition                218800 non-null   float64       \n",
      " 42  NuStrikeOutsPitching      65252 non-null    float64       \n",
      " 43  NuBattingOrder            182559 non-null   float64       \n",
      " 44  NuGamesPlayedBatting      182564 non-null   float64       \n",
      " 45  NuFlyOuts                 182564 non-null   float64       \n",
      " 46  NuGroundOuts              182564 non-null   float64       \n",
      " 47  NuRunsScored              182564 non-null   float64       \n",
      " 48  NuDoubles                 182564 non-null   float64       \n",
      " 49  NuTriples                 182564 non-null   float64       \n",
      " 50  NuHomeRuns                182564 non-null   float64       \n",
      " 51  NuStrikeOuts              182564 non-null   float64       \n",
      " 52  NuBaseOnBalls             182564 non-null   float64       \n",
      " 53  NuIntentionalWalks        182564 non-null   float64       \n",
      " 54  NuHits                    182564 non-null   float64       \n",
      " 55  NuHitByPitch              182564 non-null   float64       \n",
      " 56  NuAtBats                  182564 non-null   float64       \n",
      " 57  NuCaughtStealing          182564 non-null   float64       \n",
      " 58  NuStolenBases             182564 non-null   float64       \n",
      " 59  NuGroundIntoDoublePlay    182564 non-null   float64       \n",
      " 60  NuGroundIntoTriplePlay    182564 non-null   float64       \n",
      " 61  NuPlateAppearances        182564 non-null   float64       \n",
      " 62  NuTotalBases              182564 non-null   float64       \n",
      " 63  NuRbi                     182564 non-null   float64       \n",
      " 64  NuLeftOnBase              182564 non-null   float64       \n",
      " 65  NuSacBunts                182564 non-null   float64       \n",
      " 66  NuSacFlies                182564 non-null   float64       \n",
      " 67  NuCatchersInterference    182564 non-null   float64       \n",
      " 68  NuPickoffs                182564 non-null   float64       \n",
      " 69  NuInningsPitched          65252 non-null    float64       \n",
      " 70  NuSaveOpportunities       65252 non-null    float64       \n",
      " 71  NuEarnedRuns              65252 non-null    float64       \n",
      " 72  NuBattersFaced            65252 non-null    float64       \n",
      " 73  NuPitchesThrown           65252 non-null    float64       \n",
      " 74  NuBalls                   65252 non-null    float64       \n",
      " 75  NuStrikes                 65252 non-null    float64       \n",
      " 76  NuHitBatsmen              65252 non-null    float64       \n",
      " 77  NuBalks                   65252 non-null    float64       \n",
      " 78  NuWildPitches             65252 non-null    float64       \n",
      " 79  NuInheritedRunners        65252 non-null    float64       \n",
      " 80  NuInheritedRunnersScored  65252 non-null    float64       \n",
      " 81  NuSaves                   55424 non-null    float64       \n",
      " 82  NuHolds                   55424 non-null    float64       \n",
      " 83  NuBlownSaves              55424 non-null    float64       \n",
      " 84  NuAssists                 184461 non-null   float64       \n",
      " 85  NuPutOuts                 184461 non-null   float64       \n",
      " 86  NuErrors                  184461 non-null   float64       \n",
      " 87  NuChances                 184461 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float32(32), float64(50), int64(1), object(4)\n",
      "memory usage: 1.5+ GB\n"
     ]
    }
   ],
   "source": [
    "df_join = pd.merge(df, df_playerBoxScores, on=['IdDtPlayer'], how='left')\n",
    "df_join.info(null_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = [c for c in df_join.columns if c not in ['IdGame',\n",
    "                                              'DtGame',\n",
    "                                              'DtGameUTC',\n",
    "                                              'IdPlayer_y',\n",
    "                                              'IdTeam',\n",
    "                                              'NuJersey',\n",
    "                                              'CdPosition', \n",
    "                                              'target1_shift_1', \n",
    "                                              'target2_shift_1',\n",
    "                                              'target3_shift_1',\n",
    "                                              'target1_shift_2',\n",
    "                                              'target3_shift_2',\n",
    "                                              'target4_shift_2',\n",
    "                                              'target1_shift_3',\n",
    "                                              'target2_shift_3',\n",
    "                                              'target3_shift_3',\n",
    "                                              'target4_shift_3',\n",
    "                                              'target1_shift_4',\n",
    "                                              'target2_shift_4',\n",
    "                                              'target3_shift_4',\n",
    "                                              'target4_shift_4',\n",
    "                                              'target1_shift_5',\n",
    "                                              'target2_shift_5',\n",
    "                                              'target3_shift_5',\n",
    "                                              'target4_shift_5',\n",
    "                                              'target1_shift_6',\n",
    "                                              'target2_shift_6',\n",
    "                                              'target3_shift_6',\n",
    "                                              'target4_shift_6',\n",
    "                                              'target1_shift_7',\n",
    "                                              'target2_shift_7',\n",
    "                                              'target3_shift_7',\n",
    "                                              'target4_shift_7']]\n",
    "\n",
    "df_join[f] = df_join[f].fillna(0)                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2698457 entries, 0 to 2698456\n",
      "Data columns (total 88 columns):\n",
      " #   Column                    Non-Null Count    Dtype         \n",
      "---  ------                    --------------    -----         \n",
      " 0   Dt                        2698457 non-null  datetime64[ns]\n",
      " 1   IdPlayer_x                2698457 non-null  int64         \n",
      " 2   target1                   2698457 non-null  float32       \n",
      " 3   target2                   2698457 non-null  float32       \n",
      " 4   target3                   2698457 non-null  float32       \n",
      " 5   target4                   2698457 non-null  float32       \n",
      " 6   IdDtPlayer                2698457 non-null  object        \n",
      " 7   target1_shift_1           2696396 non-null  float32       \n",
      " 8   target2_shift_1           2696396 non-null  float32       \n",
      " 9   target3_shift_1           2696396 non-null  float32       \n",
      " 10  target4_shift_1           2698457 non-null  float32       \n",
      " 11  target1_shift_2           2694335 non-null  float32       \n",
      " 12  target2_shift_2           2698457 non-null  float32       \n",
      " 13  target3_shift_2           2694335 non-null  float32       \n",
      " 14  target4_shift_2           2694335 non-null  float32       \n",
      " 15  target1_shift_3           2692274 non-null  float32       \n",
      " 16  target2_shift_3           2692274 non-null  float32       \n",
      " 17  target3_shift_3           2692274 non-null  float32       \n",
      " 18  target4_shift_3           2692274 non-null  float32       \n",
      " 19  target1_shift_4           2690213 non-null  float32       \n",
      " 20  target2_shift_4           2690213 non-null  float32       \n",
      " 21  target3_shift_4           2690213 non-null  float32       \n",
      " 22  target4_shift_4           2690213 non-null  float32       \n",
      " 23  target1_shift_5           2688152 non-null  float32       \n",
      " 24  target2_shift_5           2688152 non-null  float32       \n",
      " 25  target3_shift_5           2688152 non-null  float32       \n",
      " 26  target4_shift_5           2688152 non-null  float32       \n",
      " 27  target1_shift_6           2686091 non-null  float32       \n",
      " 28  target2_shift_6           2686091 non-null  float32       \n",
      " 29  target3_shift_6           2686091 non-null  float32       \n",
      " 30  target4_shift_6           2686091 non-null  float32       \n",
      " 31  target1_shift_7           2684030 non-null  float32       \n",
      " 32  target2_shift_7           2684030 non-null  float32       \n",
      " 33  target3_shift_7           2684030 non-null  float32       \n",
      " 34  target4_shift_7           2684030 non-null  float32       \n",
      " 35  IdGame                    218800 non-null   float64       \n",
      " 36  DtGame                    218800 non-null   object        \n",
      " 37  DtGameUTC                 218800 non-null   object        \n",
      " 38  IdPlayer_y                218800 non-null   float64       \n",
      " 39  IdTeam                    218800 non-null   float64       \n",
      " 40  NuJersey                  218763 non-null   object        \n",
      " 41  CdPosition                218800 non-null   float64       \n",
      " 42  NuStrikeOutsPitching      2698457 non-null  float64       \n",
      " 43  NuBattingOrder            2698457 non-null  float64       \n",
      " 44  NuGamesPlayedBatting      2698457 non-null  float64       \n",
      " 45  NuFlyOuts                 2698457 non-null  float64       \n",
      " 46  NuGroundOuts              2698457 non-null  float64       \n",
      " 47  NuRunsScored              2698457 non-null  float64       \n",
      " 48  NuDoubles                 2698457 non-null  float64       \n",
      " 49  NuTriples                 2698457 non-null  float64       \n",
      " 50  NuHomeRuns                2698457 non-null  float64       \n",
      " 51  NuStrikeOuts              2698457 non-null  float64       \n",
      " 52  NuBaseOnBalls             2698457 non-null  float64       \n",
      " 53  NuIntentionalWalks        2698457 non-null  float64       \n",
      " 54  NuHits                    2698457 non-null  float64       \n",
      " 55  NuHitByPitch              2698457 non-null  float64       \n",
      " 56  NuAtBats                  2698457 non-null  float64       \n",
      " 57  NuCaughtStealing          2698457 non-null  float64       \n",
      " 58  NuStolenBases             2698457 non-null  float64       \n",
      " 59  NuGroundIntoDoublePlay    2698457 non-null  float64       \n",
      " 60  NuGroundIntoTriplePlay    2698457 non-null  float64       \n",
      " 61  NuPlateAppearances        2698457 non-null  float64       \n",
      " 62  NuTotalBases              2698457 non-null  float64       \n",
      " 63  NuRbi                     2698457 non-null  float64       \n",
      " 64  NuLeftOnBase              2698457 non-null  float64       \n",
      " 65  NuSacBunts                2698457 non-null  float64       \n",
      " 66  NuSacFlies                2698457 non-null  float64       \n",
      " 67  NuCatchersInterference    2698457 non-null  float64       \n",
      " 68  NuPickoffs                2698457 non-null  float64       \n",
      " 69  NuInningsPitched          2698457 non-null  float64       \n",
      " 70  NuSaveOpportunities       2698457 non-null  float64       \n",
      " 71  NuEarnedRuns              2698457 non-null  float64       \n",
      " 72  NuBattersFaced            2698457 non-null  float64       \n",
      " 73  NuPitchesThrown           2698457 non-null  float64       \n",
      " 74  NuBalls                   2698457 non-null  float64       \n",
      " 75  NuStrikes                 2698457 non-null  float64       \n",
      " 76  NuHitBatsmen              2698457 non-null  float64       \n",
      " 77  NuBalks                   2698457 non-null  float64       \n",
      " 78  NuWildPitches             2698457 non-null  float64       \n",
      " 79  NuInheritedRunners        2698457 non-null  float64       \n",
      " 80  NuInheritedRunnersScored  2698457 non-null  float64       \n",
      " 81  NuSaves                   2698457 non-null  float64       \n",
      " 82  NuHolds                   2698457 non-null  float64       \n",
      " 83  NuBlownSaves              2698457 non-null  float64       \n",
      " 84  NuAssists                 2698457 non-null  float64       \n",
      " 85  NuPutOuts                 2698457 non-null  float64       \n",
      " 86  NuErrors                  2698457 non-null  float64       \n",
      " 87  NuChances                 2698457 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float32(32), float64(50), int64(1), object(4)\n",
      "memory usage: 1.5+ GB\n"
     ]
    }
   ],
   "source": [
    "df_join.info(null_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join = df_join.dropna(subset=[             \n",
    "    'target1_shift_1', \n",
    "    'target2_shift_1',\n",
    "    'target3_shift_1',\n",
    "    'target1_shift_2',\n",
    "    'target3_shift_2',\n",
    "    'target4_shift_2',\n",
    "    'target1_shift_3',\n",
    "    'target2_shift_3',\n",
    "    'target3_shift_3',\n",
    "    'target4_shift_3',\n",
    "    'target1_shift_4',\n",
    "    'target2_shift_4',\n",
    "    'target3_shift_4',\n",
    "    'target4_shift_4',\n",
    "    'target1_shift_5',\n",
    "    'target3_shift_5',\n",
    "    'target4_shift_5', \n",
    "    'target1_shift_6',\n",
    "    'target2_shift_6',\n",
    "    'target3_shift_6',\n",
    "    'target4_shift_6',\n",
    "    'target1_shift_7',\n",
    "    'target2_shift_7',\n",
    "    'target3_shift_7',\n",
    "    'target4_shift_7'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join.drop(['IdGame',\n",
    "             'DtGame',\n",
    "             'DtGameUTC',\n",
    "             'IdPlayer_y',\n",
    "             'IdTeam',\n",
    "             'NuJersey',\n",
    "             'CdPosition'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: bool)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_join.isna().any()[lambda x: x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join.rename(columns={'IdPlayer_x': 'IdPlayer'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_train, df_playerBoxScores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2684030 entries, 7 to 2698456\n",
      "Data columns (total 81 columns):\n",
      " #   Column                    Dtype         \n",
      "---  ------                    -----         \n",
      " 0   Dt                        datetime64[ns]\n",
      " 1   IdPlayer                  int64         \n",
      " 2   target1                   float32       \n",
      " 3   target2                   float32       \n",
      " 4   target3                   float32       \n",
      " 5   target4                   float32       \n",
      " 6   IdDtPlayer                object        \n",
      " 7   target1_shift_1           float32       \n",
      " 8   target2_shift_1           float32       \n",
      " 9   target3_shift_1           float32       \n",
      " 10  target4_shift_1           float32       \n",
      " 11  target1_shift_2           float32       \n",
      " 12  target2_shift_2           float32       \n",
      " 13  target3_shift_2           float32       \n",
      " 14  target4_shift_2           float32       \n",
      " 15  target1_shift_3           float32       \n",
      " 16  target2_shift_3           float32       \n",
      " 17  target3_shift_3           float32       \n",
      " 18  target4_shift_3           float32       \n",
      " 19  target1_shift_4           float32       \n",
      " 20  target2_shift_4           float32       \n",
      " 21  target3_shift_4           float32       \n",
      " 22  target4_shift_4           float32       \n",
      " 23  target1_shift_5           float32       \n",
      " 24  target2_shift_5           float32       \n",
      " 25  target3_shift_5           float32       \n",
      " 26  target4_shift_5           float32       \n",
      " 27  target1_shift_6           float32       \n",
      " 28  target2_shift_6           float32       \n",
      " 29  target3_shift_6           float32       \n",
      " 30  target4_shift_6           float32       \n",
      " 31  target1_shift_7           float32       \n",
      " 32  target2_shift_7           float32       \n",
      " 33  target3_shift_7           float32       \n",
      " 34  target4_shift_7           float32       \n",
      " 35  NuStrikeOutsPitching      float64       \n",
      " 36  NuBattingOrder            float64       \n",
      " 37  NuGamesPlayedBatting      float64       \n",
      " 38  NuFlyOuts                 float64       \n",
      " 39  NuGroundOuts              float64       \n",
      " 40  NuRunsScored              float64       \n",
      " 41  NuDoubles                 float64       \n",
      " 42  NuTriples                 float64       \n",
      " 43  NuHomeRuns                float64       \n",
      " 44  NuStrikeOuts              float64       \n",
      " 45  NuBaseOnBalls             float64       \n",
      " 46  NuIntentionalWalks        float64       \n",
      " 47  NuHits                    float64       \n",
      " 48  NuHitByPitch              float64       \n",
      " 49  NuAtBats                  float64       \n",
      " 50  NuCaughtStealing          float64       \n",
      " 51  NuStolenBases             float64       \n",
      " 52  NuGroundIntoDoublePlay    float64       \n",
      " 53  NuGroundIntoTriplePlay    float64       \n",
      " 54  NuPlateAppearances        float64       \n",
      " 55  NuTotalBases              float64       \n",
      " 56  NuRbi                     float64       \n",
      " 57  NuLeftOnBase              float64       \n",
      " 58  NuSacBunts                float64       \n",
      " 59  NuSacFlies                float64       \n",
      " 60  NuCatchersInterference    float64       \n",
      " 61  NuPickoffs                float64       \n",
      " 62  NuInningsPitched          float64       \n",
      " 63  NuSaveOpportunities       float64       \n",
      " 64  NuEarnedRuns              float64       \n",
      " 65  NuBattersFaced            float64       \n",
      " 66  NuPitchesThrown           float64       \n",
      " 67  NuBalls                   float64       \n",
      " 68  NuStrikes                 float64       \n",
      " 69  NuHitBatsmen              float64       \n",
      " 70  NuBalks                   float64       \n",
      " 71  NuWildPitches             float64       \n",
      " 72  NuInheritedRunners        float64       \n",
      " 73  NuInheritedRunnersScored  float64       \n",
      " 74  NuSaves                   float64       \n",
      " 75  NuHolds                   float64       \n",
      " 76  NuBlownSaves              float64       \n",
      " 77  NuAssists                 float64       \n",
      " 78  NuPutOuts                 float64       \n",
      " 79  NuErrors                  float64       \n",
      " 80  NuChances                 float64       \n",
      "dtypes: datetime64[ns](1), float32(32), float64(46), int64(1), object(1)\n",
      "memory usage: 1.3+ GB\n"
     ]
    }
   ],
   "source": [
    "df_join.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divisão treino, teste e validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (2322747, 35), Test shape: (189612, 35), Val shape: (183429, 35)\n"
     ]
    }
   ],
   "source": [
    "train, test, val = train_test_split(df)\n",
    "print(f\"Train shape: {train.shape}, Test shape: {test.shape}, Val shape: {val.shape}\")\n",
    "\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (2322747, 35), Test shape: (189612, 35), Val shape: (183429, 35)\n"
     ]
    }
   ],
   "source": [
    "train_join, test_join, val_join = train_test_split(df_join)\n",
    "print(f\"Train shape: {train.shape}, Test shape: {test.shape}, Val shape: {val.shape}\")\n",
    "\n",
    "del df_join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinando Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(columns = ['model', 'target1', 'target2', 'target3', 'target4', 'average'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funções Auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to train, predict and evaluate models\n",
    "def train_models(model, x_train, y_train):\n",
    "    \"\"\"Train a model for each target column\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model : sklearn model\n",
    "        Model to be trained\n",
    "    x_train : pd.DataFrame\n",
    "        Training features\n",
    "    y_train : pd.DataFrame\n",
    "        Training targets\n",
    "    \n",
    "    Returns\n",
    "    \n",
    "    -------\n",
    "    list\n",
    "        List of trained models\n",
    "    \"\"\"\n",
    "\n",
    "    models = []\n",
    "    for target in TARGET_COLS:\n",
    "        model.fit(x_train, y_train[target])\n",
    "        models.append(model)\n",
    "    return models\n",
    "\n",
    "\n",
    "def predict_targets(models, x_test):\n",
    "    \"\"\"Predict the targets for each model\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    models : list\n",
    "        List of trained models\n",
    "    x_test : pd.DataFrame\n",
    "        Test features\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Predictions for each target column\n",
    "    \"\"\"\n",
    "\n",
    "    y_preds = pd.DataFrame(columns=TARGET_COLS)\n",
    "    for target, model in zip(TARGET_COLS, models):\n",
    "        y_preds[target] = model.predict(x_test)\n",
    "    return y_preds\n",
    "\n",
    "\n",
    "def evaluate_mae(y_true, y_pred):\n",
    "    \"\"\"Evaluate the mean absolute error for each target column and the average MAE\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : pd.DataFrame\n",
    "        True labels\n",
    "    y_pred : pd.DataFrame\n",
    "        Predictions\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Mean absolute error for each target column\n",
    "    \"\"\"\n",
    "    maes = {}\n",
    "    for target in TARGET_COLS:\n",
    "        mae = mean_absolute_error(y_true[target], y_pred[target])\n",
    "        maes[target] = mae\n",
    "    maes['average'] = np.mean(list(maes.values()))\n",
    "    return maes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val = pd.concat([train, val], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "media = train_val[TARGET_COLS].mean()\n",
    "media_por_jogador = train_val.groupby('IdPlayer')[TARGET_COLS].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "mediana = train_val[TARGET_COLS].median()\n",
    "mediana_por_jogador = train_val.groupby('IdPlayer')[TARGET_COLS].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive = train_val[train_val['Dt']=='2021-04-30'].set_index('IdPlayer')[TARGET_COLS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>target1</th>\n",
       "      <th>target2</th>\n",
       "      <th>target3</th>\n",
       "      <th>target4</th>\n",
       "      <th>average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [model, target1, target2, target3, target4, average]\n",
       "Index: []"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mae_media = []\n",
    "#mae_mediapj = []\n",
    "#mae_mediana = []\n",
    "#mae_medianapj = []\n",
    "#mae_naive = []\n",
    "summary = pd.DataFrame(columns=TARGET_COLS,index=['Média','Média por Jogador','Mediana','Mediana por Jogador','Naive'])\n",
    "\n",
    "for target in TARGET_COLS:\n",
    "    \n",
    "    y_true = test[target]\n",
    "    \n",
    "    mediapj_pred = test['IdPlayer'].map(media_por_jogador[target].to_dict())\n",
    "    medianapj_pred = test['IdPlayer'].map(mediana_por_jogador[target].to_dict())\n",
    "    naive_pred = test['IdPlayer'].map(naive[target].to_dict())\n",
    "    \n",
    "    mediana_pred = [mediana[target] for i in test.index]\n",
    "    media_pred = [media[target] for i in test.index]\n",
    "    \n",
    "\n",
    "    summary.loc['Média',target]  = mean_absolute_error(y_true,media_pred)\n",
    "    summary.loc['Média por Jogador',target]  = mean_absolute_error(y_true,mediapj_pred)\n",
    "    summary.loc['Mediana',target]  = mean_absolute_error(y_true,mediana_pred)\n",
    "    summary.loc['Mediana por Jogador',target]  = mean_absolute_error(y_true,medianapj_pred)\n",
    "    summary.loc['Naive',target]  = mean_absolute_error(y_true,naive_pred)\n",
    "    \n",
    "summary['Average'] = summary.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1254551"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary.loc[\"Média\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Can only append a dict if ignore_index=True",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11880\\3860033085.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_results\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'model'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'Média'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'target1'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0msummary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Média\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'target2'\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0msummary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Média\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mappend\u001b[1;34m(self, other, ignore_index, verify_integrity, sort)\u001b[0m\n\u001b[0;32m   9037\u001b[0m         )\n\u001b[0;32m   9038\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 9039\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_append\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_integrity\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   9040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   9041\u001b[0m     def _append(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_append\u001b[1;34m(self, other, ignore_index, verify_integrity, sort)\u001b[0m\n\u001b[0;32m   9050\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   9051\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 9052\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Can only append a dict if ignore_index=True\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   9053\u001b[0m                 \u001b[0mother\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   9054\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Can only append a dict if ignore_index=True"
     ]
    }
   ],
   "source": [
    "df_results = df_results.append({'model': 'Média', mean_absolute_err}, ignore_index=True)\n",
    "    #df_results = df_results.append({'model': 'Média por Jogador', mean_absolute_error(y_true,mediapj_pred)}, ignore_index=True)\n",
    "    #df_results = df_results.append({'model': 'Mediana', mean_absolute_error(y_true,mediana_pred)}, ignore_index=True)\n",
    "    #df_results = df_results.append({'model': 'Mediana por Jogador', mean_absolute_error(y_true,medianapj_pred)}, ignore_index=True)\n",
    "    #df_results = df_results.append({'model': 'Naive', mean_absolute_error(y_true,naive_pred)}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train =train.drop(['Dt', 'IdDtPlayer'], axis=1)\n",
    "train = train.dropna()\n",
    "val = val.drop(['Dt', 'IdDtPlayer'], axis=1)  \n",
    "test = test.drop(['Dt', 'IdDtPlayer'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 5s, sys: 45.7 s, total: 2min 51s\n",
      "Wall time: 26.6 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>target1</th>\n",
       "      <th>target2</th>\n",
       "      <th>target3</th>\n",
       "      <th>target4</th>\n",
       "      <th>average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lasso | alpha = 0.1</td>\n",
       "      <td>1.353516</td>\n",
       "      <td>1.446735</td>\n",
       "      <td>1.303287</td>\n",
       "      <td>0.753244</td>\n",
       "      <td>1.214195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model   target1   target2   target3   target4   average\n",
       "0  Lasso | alpha = 0.1  1.353516  1.446735  1.303287  0.753244  1.214195"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = Lasso(alpha=0.1, random_state=RANDOM_SEED)\n",
    "\n",
    "# train the models\n",
    "models = train_models(\n",
    "            model = model, \n",
    "            x_train = train.drop(TARGET_COLS, axis=1), \n",
    "            y_train = train[TARGET_COLS]\n",
    "        )\n",
    "\n",
    "# predict the targets for each trained model\n",
    "y_pred = predict_targets(models, test.drop(TARGET_COLS, axis=1))\n",
    "\n",
    "# evaluate the models\n",
    "mae = evaluate_mae(y_true = test[TARGET_COLS], y_pred = y_pred)\n",
    "\n",
    "# save the results\n",
    "df_results = df_results.append({'model': 'Lasso | alpha = 0.1', **mae}, ignore_index=True)\n",
    "\n",
    "# delete the variables to save RAM\n",
    "del models, y_pred, mae\n",
    "\n",
    "# show the results\n",
    "df_results[df_results['model'] == 'Lasso | alpha = 0.1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lasso CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 21s, sys: 46.1 s, total: 2min 7s\n",
      "Wall time: 57.9 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>target1</th>\n",
       "      <th>target2</th>\n",
       "      <th>target3</th>\n",
       "      <th>target4</th>\n",
       "      <th>average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LassoCV</td>\n",
       "      <td>1.580195</td>\n",
       "      <td>1.968568</td>\n",
       "      <td>1.446175</td>\n",
       "      <td>1.43636</td>\n",
       "      <td>1.607824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model   target1   target2   target3  target4   average\n",
       "1  LassoCV  1.580195  1.968568  1.446175  1.43636  1.607824"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = LassoCV(random_state=RANDOM_SEED)\n",
    "\n",
    "# train the models\n",
    "models = train_models(\n",
    "            model = model, \n",
    "            x_train = train.drop(TARGET_COLS, axis=1), \n",
    "            y_train = train[TARGET_COLS]\n",
    "        )\n",
    "\n",
    "# predict the targets for each trained model\n",
    "y_pred = predict_targets(models, test.drop(TARGET_COLS, axis=1))\n",
    "\n",
    "# evaluate the models\n",
    "mae = evaluate_mae(y_true = test[TARGET_COLS], y_pred = y_pred)\n",
    "\n",
    "# save the results\n",
    "df_results = df_results.append({'model': 'LassoCV', **mae}, ignore_index=True)\n",
    "\n",
    "# delete the variables to save RAM\n",
    "del models, y_pred, mae\n",
    "\n",
    "# show the results\n",
    "df_results[df_results['model'] == 'LassoCV']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Tree Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import export_graphviz "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12min 43s, sys: 1.09 s, total: 12min 44s\n",
      "Wall time: 12min 44s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>target1</th>\n",
       "      <th>target2</th>\n",
       "      <th>target3</th>\n",
       "      <th>target4</th>\n",
       "      <th>average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree Regressor</td>\n",
       "      <td>1.535279</td>\n",
       "      <td>1.712461</td>\n",
       "      <td>1.48524</td>\n",
       "      <td>1.119111</td>\n",
       "      <td>1.463023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model   target1   target2  target3   target4   average\n",
       "2  Decision Tree Regressor  1.535279  1.712461  1.48524  1.119111  1.463023"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = DecisionTreeRegressor(random_state=RANDOM_SEED)\n",
    "\n",
    "# train the models\n",
    "models = train_models(\n",
    "            model = model, \n",
    "            x_train = train.drop(TARGET_COLS, axis=1), \n",
    "            y_train = train[TARGET_COLS]\n",
    "        )\n",
    "\n",
    "# predict the targets for each trained model\n",
    "y_pred = predict_targets(models, test.drop(TARGET_COLS, axis=1))\n",
    "\n",
    "# evaluate the models\n",
    "mae = evaluate_mae(y_true = test[TARGET_COLS], y_pred = y_pred)\n",
    "\n",
    "# save the results\n",
    "df_results = df_results.append({'model': 'Decision Tree Regressor', **mae}, ignore_index=True)\n",
    "\n",
    "# delete the variables to save RAM\n",
    "del models, y_pred, mae\n",
    "\n",
    "df_results[df_results['model'] == 'Decision Tree Regressor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model = RandomForestRegressor(random_state=RANDOM_SEED)\n",
    "\n",
    "# train the models\n",
    "models = train_models(\n",
    "            model = model, \n",
    "            x_train = train.drop(TARGET_COLS, axis=1), \n",
    "            y_train = train[TARGET_COLS]\n",
    "        )\n",
    "\n",
    "# predict the targets for each trained model\n",
    "y_pred = predict_targets(models, test.drop(TARGET_COLS, axis=1))\n",
    "\n",
    "# evaluate the models\n",
    "mae = evaluate_mae(y_true = test[TARGET_COLS], y_pred = y_pred)\n",
    "\n",
    "# save the results\n",
    "df_results = df_results.append({'model': 'Random Forest Regressor', **mae}, ignore_index=True)\n",
    "\n",
    "# delete the variables to save RAM\n",
    "del models, y_pred, mae\n",
    "\n",
    "df_results[df_results['model'] == 'Random Forest Regressor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model = GradientBoostingRegressor(random_state=RANDOM_SEED)\n",
    "\n",
    "# train the models\n",
    "models = train_models(\n",
    "            model = model,\n",
    "            x_train = train.drop(TARGET_COLS, axis=1),\n",
    "            y_train = train[TARGET_COLS]\n",
    "        )\n",
    "\n",
    "# predict the targets for each trained model\n",
    "y_pred = predict_targets(models, test.drop(TARGET_COLS, axis=1))\n",
    "\n",
    "# evaluate the models\n",
    "mae = evaluate_mae(y_true = test[TARGET_COLS], y_pred = y_pred)\n",
    "\n",
    "# save the results\n",
    "df_results = df_results.append({'model': 'Gradient Boosting Regressor', **mae}, ignore_index=True)\n",
    "\n",
    "# delete the variables to save RAM\n",
    "del models, y_pred, mae\n",
    "\n",
    "df_results[df_results['model'] == 'Gradient Boosting Regressor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model = AdaBoostRegressor(random_state=RANDOM_SEED)\n",
    "\n",
    "# train the models\n",
    "models = train_models(\n",
    "            model = model,\n",
    "            x_train = train.drop(TARGET_COLS, axis=1),\n",
    "            y_train = train[TARGET_COLS]\n",
    "        )\n",
    "\n",
    "# predict the targets for each trained model\n",
    "y_pred = predict_targets(models, test.drop(TARGET_COLS, axis=1))\n",
    "\n",
    "# evaluate the models\n",
    "mae = evaluate_mae(y_true = test[TARGET_COLS], y_pred = y_pred)\n",
    "\n",
    "# save the results\n",
    "df_results = df_results.append({'model': 'AdaBoost Regressor', **mae}, ignore_index=True)\n",
    "\n",
    "# delete the variables to save RAM\n",
    "del models, y_pred, mae\n",
    "\n",
    "df_results[df_results['model'] == 'AdaBoost Regressor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model = BaggingRegressor(random_state=RANDOM_SEED)\n",
    "\n",
    "# train the models\n",
    "models = train_models(\n",
    "            model = model,\n",
    "            x_train = train.drop(TARGET_COLS, axis=1),\n",
    "            y_train = train[TARGET_COLS]\n",
    "        )\n",
    "\n",
    "# predict the targets for each trained model\n",
    "y_pred = predict_targets(models, test.drop(TARGET_COLS, axis=1))\n",
    "\n",
    "# evaluate the models\n",
    "mae = evaluate_mae(y_true = test[TARGET_COLS], y_pred = y_pred)\n",
    "\n",
    "# save the results\n",
    "df_results = df_results.append({'model': 'Bagging Regressor', **mae}, ignore_index=True)\n",
    "\n",
    "# delete the variables to save RAM\n",
    "del models, y_pred, mae\n",
    "\n",
    "df_results[df_results['model'] == 'Bagging Regressor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
