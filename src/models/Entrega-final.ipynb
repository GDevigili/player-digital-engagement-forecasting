{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Fundação Getúlio Vargas - RJ <br>\n",
    "> Escola de Matemática Aplicada (EMAp) <br>\n",
    "> Graduação em Ciência de Dados e Inteligência Artificial <br>\n",
    "> Alunos: Gianlucca Devigili e Maisa O. Fraiz <br>\n",
    "# Projetos em Ciência de Dados - A1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instruções de execução\n",
    "\n",
    "__(#1)__ De modo a tornar mais rápida a carga dos dados, o projeto utiliza uma cópia dos arquivos em formato pickle (`.pkl`). Para executar o projeto utilizando o o dataset em formato `.csv`, atribua o valor `True` para a variável `V_load_from_csv`\n",
    "\n",
    "**(#2)** Redefina a variável `raw_data_path` para o caminho até o arquivo `train_updated.csv`. Substitua o nome do arquivo caso necessário.\n",
    "\n",
    "**(#3)** Atribua o valor `True` para a variável `save_files` caso ainda não tenha os arquivos `.pkl` dos datasets auxiliares salvos. (Necessário apenas para a primeira execução da sessão de preparação de dados).\n",
    "\n",
    "**(#4)** Atribua o valor `True` para a variável `prepare_data` caso deseje executar a sessão de preparação de dados. (Necessário apenas para a primeira execução da sessão de preparação de dados). Caso contrário as variáveis serão carregadas a partir dos arquivos `.pkl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Variáveis de configuração\n",
    "# (#1) Variável que define se o dataset será carregado de um .csv ou de um .pkl\n",
    "load_from_csv = False\n",
    "\n",
    "# Caminho para o dataset\n",
    "raw_data_path = '../data/raw-data/'\n",
    "dataset_path = raw_data_path + 'train_updated.csv'\n",
    "\n",
    "# Caminho onde serão salvos os dados processados\n",
    "processed_data_path = '../data/processed-data/'\n",
    "\n",
    "# Prepare data\n",
    "# (#4) Variável que define se o dataset será processado ou se será carregado de um .pkl\n",
    "prepare_data = False\n",
    "\n",
    "save_files = False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Setup Inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pickle as pkl\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "# disable warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variáveis globais\n",
    "\n",
    "PROCESSED_DATA_PATH = '../data/processed-data/'\n",
    "MODEL_PATH = '../models/trained-models/'\n",
    "\n",
    "TARGET_COLS = ['target1', 'target2', 'target3', 'target4']\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "TEST_SPLIT_DATE = '2021-04-30'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparação dos Dados"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funções Auxiliares\n",
    "\n",
    "Algumas funções utilizadas para a preparação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funções auxiliares para carregar os dados\n",
    "def unpack_json(json_str):\n",
    "    return pd.DataFrame() if pd.isna(json_str) else pd.read_json(json_str)\n",
    "\n",
    "def unpack_data(data, dfs=None, n_jobs=-1):\n",
    "    if dfs is not None:\n",
    "        data = data.loc[:, dfs]\n",
    "    unnested_dfs = {}\n",
    "    for name, column in data.iteritems():\n",
    "        daily_dfs = Parallel(n_jobs=n_jobs)(\n",
    "            delayed(unpack_json)(item) for date, item in column.iteritems())\n",
    "        df = pd.concat(daily_dfs)\n",
    "        unnested_dfs[name] = df\n",
    "    return unnested_dfs\n",
    "\n",
    "def create_id(df, id_cols, id_col_name, dt_col_name = 'Dt'):\n",
    "    df['Id' + dt_col_name + id_col_name] = df[id_cols].apply(lambda x: '_'.join(x.astype(str)), axis=1)\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.79 s, sys: 9.45 s, total: 12.2 s\n",
      "Wall time: 19.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# (#1)\n",
    "if load_from_csv:\n",
    "    df_train = pd.read_csv(dataset_path)\n",
    "else: \n",
    "    dataset_path = raw_data_path + 'train.pkl'\n",
    "    df_train = pd.read_pickle(dataset_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cria o Dataframe Targets\n",
    "\n",
    "Dataframe contendo as 4 variáveis _target_ bem como suas respectivas chaves `IdPlayer` e `Dt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19 µs, sys: 0 ns, total: 19 µs\n",
      "Wall time: 32.4 µs\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "if prepare_data:\n",
    "    # criação do dataset de targets\n",
    "    # unpack the data\n",
    "    Y = unpack_data(df_train, dfs = ['nextDayPlayerEngagement'])['nextDayPlayerEngagement']\n",
    "\n",
    "    # change datatypes\n",
    "    Y = Y.astype({name: np.float32 for name in [\"target1\", \"target2\", \"target3\", \"target4\"]})\n",
    "\n",
    "    # match target dates to feature dates and create date index\n",
    "    Y = Y.rename(columns={'engagementMetricsDate': 'date'})\n",
    "\n",
    "    # change datatypes\n",
    "    Y['date'] = pd.to_datetime(Y['date'])\n",
    "\n",
    "    # reset index\n",
    "    Y = Y.set_index('date').to_period('D')\n",
    "    Y.index = Y.index - 1\n",
    "    Y = Y.reset_index()\n",
    "\n",
    "    # rename and select columns\n",
    "    cols_Y = {\n",
    "        'date': 'Dt',\n",
    "        'playerId': 'IdPlayer',\n",
    "        'target1': 'target1',\n",
    "        'target2': 'target2',\n",
    "        'target3': 'target3',\n",
    "        'target4': 'target4'\n",
    "    }\n",
    "    Y = Y[list(cols_Y)]\n",
    "    Y.columns = list(cols_Y.values())\n",
    "    Y['Dt'] = Y['Dt'].astype('datetime64[ns]')\n",
    "    Y = create_id(Y, ['Dt', 'IdPlayer'], 'Player')\n",
    "\n",
    "    if save_files:\n",
    "        pd.to_pickle(Y, processed_data_path + 'targets.pkl')\n",
    "\n",
    "    del Y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cria o Dataframe Player Box Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if prepare_data:\n",
    "    # load the data\n",
    "    df_playerBoxScores = unpack_data(df_train, dfs = ['playerBoxScores'])['playerBoxScores']\n",
    "\n",
    "    # Cria o dataset de jogos\n",
    "    cols = {\n",
    "        # columns related to other dimensions\n",
    "        'gamePk': 'IdGame',\n",
    "        'gameDate': 'DtGame',\n",
    "        'gameTimeUTC': 'DtGameUTC',\n",
    "        'playerId': 'IdPlayer',\n",
    "        'teamId': 'IdTeam',\n",
    "        'jerseyNum': 'NuJersey',\n",
    "        'positionCode': 'CdPosition',\n",
    "        # suggested column\n",
    "        'strikeOutsPitching': 'NuStrikeOutsPitching',\n",
    "    }  \n",
    "    # numeric columns\n",
    "    for numeric_col in list(df_playerBoxScores.columns[12:]):\n",
    "        # skip the columns that contains data about pitching due the amount of Nan values\n",
    "        if 'Pitching' not in numeric_col:\n",
    "            cols[numeric_col] = 'Nu' + numeric_col[0].upper() + numeric_col[1:]\n",
    "\n",
    "    df_playerBoxScores['gameDate'] = df_playerBoxScores['gameDate'] + \" 00:00:00\"\n",
    "\n",
    "    df_playerBoxScores = df_playerBoxScores[list(cols)]\n",
    "    df_playerBoxScores.columns = list(cols.values())\n",
    "    df_playerBoxScores = create_id(df_playerBoxScores, ['DtGame', 'IdPlayer'], 'Player')\n",
    "\n",
    "    # Salva o dataset\n",
    "    if save_files:\n",
    "        pd.to_pickle(df_playerBoxScores, processed_data_path + 'playerBoxScores.pkl')\n",
    "    del df_playerBoxScores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(processed_data_path + 'targets.pkl')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funções Auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funções auxiliares para o pré-processamento dos dados\n",
    "def sort_df(df: pd.DataFrame, columns: list = ['IdPlayer', 'Dt']) -> None:\n",
    "    \"\"\"Sort the dataframe by the columns passed as argument.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Dataframe to be sorted.\n",
    "        columns (list, optional): Columns to sort the dataframe. Defaults to ['IdPlayer', 'Dt'].\n",
    "        \n",
    "        Returns:\n",
    "            None\n",
    "    \"\"\"\n",
    "    df.sort_values(by=columns, inplace=True)\n",
    "    # reset index\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "def shift_targets(df, shift_vals: list = [1, 2, 3, 4, 5, 6, 7, 14, 30]):\n",
    "    \"\"\"Shift the targets by the values passed as argument.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Dataframe to be shifted.\n",
    "        shift_vals (list, optional): Values to shift the targets. Defaults to [1, 2, 3, 4, 5, 6, 7, 14, 30].\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Dataframe with the shifted targets.\n",
    "    \"\"\"\n",
    "    df_aux = pd.DataFrame()\n",
    "    # Iterate over players to make the shift only using the player data\n",
    "    for player in df['IdPlayer'].unique():\n",
    "        df_player = df[df['IdPlayer'] == player]\n",
    "        # Iterate over the pre-defined shift values\n",
    "        for shift_val in shift_vals:\n",
    "            # Iterate over the targets\n",
    "            for target in TARGET_COLS:\n",
    "                # Make the shift\n",
    "                df_player[f'{target}_shift_{shift_val}'] = df_player[target].shift(shift_val)\n",
    "        # Concatenate the player data with the rest of the data\n",
    "        df_aux = pd.concat([df_aux, df_player], axis=0)\n",
    "        # Remove the player data from memory\n",
    "        del df_player\n",
    "    # df.dropna(inplace=True)\n",
    "    return df_aux\n",
    "\n",
    "\n",
    "def train_test_split(\n",
    "    df: pd.DataFrame\n",
    "    ,test_split_date: str = TEST_SPLIT_DATE\n",
    "    ):\n",
    "    \"\"\"Split the dataframe into train and test sets.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Dataframe to be split.\n",
    "        test_split_date (str, optional): Date to split the dataframe. Defaults to TEST_SPLIT_DATE.\n",
    "    \"\"\"\n",
    "\n",
    "    train = df[(df.Dt <= \"2021-01-31\") & (df.Dt >= \"2018-01-01\")] \n",
    "    val = df[(df.Dt <= \"2021-04-30\") & (df.Dt >= \"2021-02-01\")] \n",
    "    test = df[(df.Dt <= \"2021-07-31\") & (df.Dt >= \"2021-05-01\")]\n",
    "    # train.to_csv('train.csv', index=None)\n",
    "    # val.to_csv('validation.csv', index=None) \n",
    "    # test.to_csv('test.csv', index=None) \n",
    "\n",
    "    return train, test, val\n",
    "\n",
    "\n",
    "def x_y_split(df: pd.DataFrame, target_cols: list = TARGET_COLS):\n",
    "    \"\"\"Split the dataframe into x and y sets.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Dataframe to be split.\n",
    "    \"\"\"\n",
    "    y = df[target_cols]\n",
    "    x = df.drop(target_cols, axis=1)\n",
    "    return x, y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordenação dos valores\n",
    "\n",
    "Os dados serão ordenados por jogador e então por data, para facilitar a criação das variáveis de _shift_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dt</th>\n",
       "      <th>IdPlayer</th>\n",
       "      <th>target1</th>\n",
       "      <th>target2</th>\n",
       "      <th>target3</th>\n",
       "      <th>target4</th>\n",
       "      <th>IdDtPlayer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>112526</td>\n",
       "      <td>0.055277</td>\n",
       "      <td>5.496109</td>\n",
       "      <td>0.025839</td>\n",
       "      <td>16.176470</td>\n",
       "      <td>2018-01-01 00:00:00_112526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>112526</td>\n",
       "      <td>0.060625</td>\n",
       "      <td>3.252914</td>\n",
       "      <td>0.030486</td>\n",
       "      <td>8.541353</td>\n",
       "      <td>2018-01-02 00:00:00_112526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>112526</td>\n",
       "      <td>0.029341</td>\n",
       "      <td>1.648352</td>\n",
       "      <td>0.032613</td>\n",
       "      <td>10.490111</td>\n",
       "      <td>2018-01-03 00:00:00_112526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>112526</td>\n",
       "      <td>0.014799</td>\n",
       "      <td>2.665894</td>\n",
       "      <td>0.087422</td>\n",
       "      <td>19.091467</td>\n",
       "      <td>2018-01-04 00:00:00_112526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>112526</td>\n",
       "      <td>0.083916</td>\n",
       "      <td>1.161002</td>\n",
       "      <td>0.024759</td>\n",
       "      <td>6.643879</td>\n",
       "      <td>2018-01-05 00:00:00_112526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Dt  IdPlayer   target1   target2   target3    target4  \\\n",
       "0 2018-01-01    112526  0.055277  5.496109  0.025839  16.176470   \n",
       "1 2018-01-02    112526  0.060625  3.252914  0.030486   8.541353   \n",
       "2 2018-01-03    112526  0.029341  1.648352  0.032613  10.490111   \n",
       "3 2018-01-04    112526  0.014799  2.665894  0.087422  19.091467   \n",
       "4 2018-01-05    112526  0.083916  1.161002  0.024759   6.643879   \n",
       "\n",
       "                   IdDtPlayer  \n",
       "0  2018-01-01 00:00:00_112526  \n",
       "1  2018-01-02 00:00:00_112526  \n",
       "2  2018-01-03 00:00:00_112526  \n",
       "3  2018-01-04 00:00:00_112526  \n",
       "4  2018-01-05 00:00:00_112526  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sort_df(df)\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dt</th>\n",
       "      <th>IdPlayer</th>\n",
       "      <th>target1</th>\n",
       "      <th>target2</th>\n",
       "      <th>target3</th>\n",
       "      <th>target4</th>\n",
       "      <th>IdDtPlayer</th>\n",
       "      <th>target1_shift_1</th>\n",
       "      <th>target2_shift_1</th>\n",
       "      <th>target3_shift_1</th>\n",
       "      <th>...</th>\n",
       "      <th>target3_shift_5</th>\n",
       "      <th>target4_shift_5</th>\n",
       "      <th>target1_shift_6</th>\n",
       "      <th>target2_shift_6</th>\n",
       "      <th>target3_shift_6</th>\n",
       "      <th>target4_shift_6</th>\n",
       "      <th>target1_shift_7</th>\n",
       "      <th>target2_shift_7</th>\n",
       "      <th>target3_shift_7</th>\n",
       "      <th>target4_shift_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>112526</td>\n",
       "      <td>0.055277</td>\n",
       "      <td>5.496109</td>\n",
       "      <td>0.025839</td>\n",
       "      <td>16.176470</td>\n",
       "      <td>2018-01-01 00:00:00_112526</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>112526</td>\n",
       "      <td>0.060625</td>\n",
       "      <td>3.252914</td>\n",
       "      <td>0.030486</td>\n",
       "      <td>8.541353</td>\n",
       "      <td>2018-01-02 00:00:00_112526</td>\n",
       "      <td>0.055277</td>\n",
       "      <td>5.496109</td>\n",
       "      <td>0.025839</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>112526</td>\n",
       "      <td>0.029341</td>\n",
       "      <td>1.648352</td>\n",
       "      <td>0.032613</td>\n",
       "      <td>10.490111</td>\n",
       "      <td>2018-01-03 00:00:00_112526</td>\n",
       "      <td>0.060625</td>\n",
       "      <td>3.252914</td>\n",
       "      <td>0.030486</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>112526</td>\n",
       "      <td>0.014799</td>\n",
       "      <td>2.665894</td>\n",
       "      <td>0.087422</td>\n",
       "      <td>19.091467</td>\n",
       "      <td>2018-01-04 00:00:00_112526</td>\n",
       "      <td>0.029341</td>\n",
       "      <td>1.648352</td>\n",
       "      <td>0.032613</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>112526</td>\n",
       "      <td>0.083916</td>\n",
       "      <td>1.161002</td>\n",
       "      <td>0.024759</td>\n",
       "      <td>6.643879</td>\n",
       "      <td>2018-01-05 00:00:00_112526</td>\n",
       "      <td>0.014799</td>\n",
       "      <td>2.665894</td>\n",
       "      <td>0.087422</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Dt  IdPlayer   target1   target2   target3    target4  \\\n",
       "0 2018-01-01    112526  0.055277  5.496109  0.025839  16.176470   \n",
       "1 2018-01-02    112526  0.060625  3.252914  0.030486   8.541353   \n",
       "2 2018-01-03    112526  0.029341  1.648352  0.032613  10.490111   \n",
       "3 2018-01-04    112526  0.014799  2.665894  0.087422  19.091467   \n",
       "4 2018-01-05    112526  0.083916  1.161002  0.024759   6.643879   \n",
       "\n",
       "                   IdDtPlayer  target1_shift_1  target2_shift_1  \\\n",
       "0  2018-01-01 00:00:00_112526              NaN              NaN   \n",
       "1  2018-01-02 00:00:00_112526         0.055277         5.496109   \n",
       "2  2018-01-03 00:00:00_112526         0.060625         3.252914   \n",
       "3  2018-01-04 00:00:00_112526         0.029341         1.648352   \n",
       "4  2018-01-05 00:00:00_112526         0.014799         2.665894   \n",
       "\n",
       "   target3_shift_1  ...  target3_shift_5  target4_shift_5  target1_shift_6  \\\n",
       "0              NaN  ...              NaN              NaN              NaN   \n",
       "1         0.025839  ...              NaN              NaN              NaN   \n",
       "2         0.030486  ...              NaN              NaN              NaN   \n",
       "3         0.032613  ...              NaN              NaN              NaN   \n",
       "4         0.087422  ...              NaN              NaN              NaN   \n",
       "\n",
       "   target2_shift_6  target3_shift_6  target4_shift_6  target1_shift_7  \\\n",
       "0              NaN              NaN              NaN              NaN   \n",
       "1              NaN              NaN              NaN              NaN   \n",
       "2              NaN              NaN              NaN              NaN   \n",
       "3              NaN              NaN              NaN              NaN   \n",
       "4              NaN              NaN              NaN              NaN   \n",
       "\n",
       "   target2_shift_7  target3_shift_7  target4_shift_7  \n",
       "0              NaN              NaN              NaN  \n",
       "1              NaN              NaN              NaN  \n",
       "2              NaN              NaN              NaN  \n",
       "3              NaN              NaN              NaN  \n",
       "4              NaN              NaN              NaN  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = shift_targets(df, shift_vals=[1, 2, 3, 4, 5, 6, 7])\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divisão treino, teste e validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (2322747, 35), Test shape: (189612, 35), Val shape: (183429, 35)\n"
     ]
    }
   ],
   "source": [
    "train, test, val = train_test_split(df)\n",
    "del df\n",
    "print(f\"Train shape: {train.shape}, Test shape: {test.shape}, Val shape: {val.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinando Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(columns = ['model', 'target1', 'target2', 'target3', 'target4', 'average'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funções Auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to train, predict and evaluate models\n",
    "def train_models(model, x_train, y_train):\n",
    "    \"\"\"Train a model for each target column\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model : sklearn model\n",
    "        Model to be trained\n",
    "    x_train : pd.DataFrame\n",
    "        Training features\n",
    "    y_train : pd.DataFrame\n",
    "        Training targets\n",
    "    \n",
    "    Returns\n",
    "    \n",
    "    -------\n",
    "    list\n",
    "        List of trained models\n",
    "    \"\"\"\n",
    "\n",
    "    models = []\n",
    "    for target in TARGET_COLS:\n",
    "        model.fit(x_train, y_train[target])\n",
    "        models.append(model)\n",
    "    return models\n",
    "\n",
    "\n",
    "def predict_targets(models, x_test):\n",
    "    \"\"\"Predict the targets for each model\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    models : list\n",
    "        List of trained models\n",
    "    x_test : pd.DataFrame\n",
    "        Test features\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Predictions for each target column\n",
    "    \"\"\"\n",
    "\n",
    "    y_preds = pd.DataFrame(columns=TARGET_COLS)\n",
    "    for target, model in zip(TARGET_COLS, models):\n",
    "        y_preds[target] = model.predict(x_test)\n",
    "    return y_preds\n",
    "\n",
    "\n",
    "def evaluate_mae(y_true, y_pred):\n",
    "    \"\"\"Evaluate the mean absolute error for each target column and the average MAE\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : pd.DataFrame\n",
    "        True labels\n",
    "    y_pred : pd.DataFrame\n",
    "        Predictions\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Mean absolute error for each target column\n",
    "    \"\"\"\n",
    "    maes = {}\n",
    "    for target in TARGET_COLS:\n",
    "        mae = mean_absolute_error(y_true[target], y_pred[target])\n",
    "        maes[target] = mae\n",
    "    maes['average'] = np.mean(list(maes.values()))\n",
    "    return maes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train =train.drop(['Dt', 'IdDtPlayer'], axis=1)\n",
    "train = train.dropna()\n",
    "val = val.drop(['Dt', 'IdDtPlayer'], axis=1)  \n",
    "test = test.drop(['Dt', 'IdDtPlayer'], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 5s, sys: 45.7 s, total: 2min 51s\n",
      "Wall time: 26.6 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>target1</th>\n",
       "      <th>target2</th>\n",
       "      <th>target3</th>\n",
       "      <th>target4</th>\n",
       "      <th>average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lasso | alpha = 0.1</td>\n",
       "      <td>1.353516</td>\n",
       "      <td>1.446735</td>\n",
       "      <td>1.303287</td>\n",
       "      <td>0.753244</td>\n",
       "      <td>1.214195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model   target1   target2   target3   target4   average\n",
       "0  Lasso | alpha = 0.1  1.353516  1.446735  1.303287  0.753244  1.214195"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = Lasso(alpha=0.1, random_state=RANDOM_SEED)\n",
    "\n",
    "# train the models\n",
    "models = train_models(\n",
    "            model = model, \n",
    "            x_train = train.drop(TARGET_COLS, axis=1), \n",
    "            y_train = train[TARGET_COLS]\n",
    "        )\n",
    "\n",
    "# predict the targets for each trained model\n",
    "y_pred = predict_targets(models, test.drop(TARGET_COLS, axis=1))\n",
    "\n",
    "# evaluate the models\n",
    "mae = evaluate_mae(y_true = test[TARGET_COLS], y_pred = y_pred)\n",
    "\n",
    "# save the results\n",
    "df_results = df_results.append({'model': 'Lasso | alpha = 0.1', **mae}, ignore_index=True)\n",
    "\n",
    "# delete the variables to save RAM\n",
    "del models, y_pred, mae\n",
    "\n",
    "# show the results\n",
    "df_results[df_results['model'] == 'Lasso | alpha = 0.1']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lasso CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 21s, sys: 46.1 s, total: 2min 7s\n",
      "Wall time: 57.9 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>target1</th>\n",
       "      <th>target2</th>\n",
       "      <th>target3</th>\n",
       "      <th>target4</th>\n",
       "      <th>average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LassoCV</td>\n",
       "      <td>1.580195</td>\n",
       "      <td>1.968568</td>\n",
       "      <td>1.446175</td>\n",
       "      <td>1.43636</td>\n",
       "      <td>1.607824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model   target1   target2   target3  target4   average\n",
       "1  LassoCV  1.580195  1.968568  1.446175  1.43636  1.607824"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = LassoCV(random_state=RANDOM_SEED)\n",
    "\n",
    "# train the models\n",
    "models = train_models(\n",
    "            model = model, \n",
    "            x_train = train.drop(TARGET_COLS, axis=1), \n",
    "            y_train = train[TARGET_COLS]\n",
    "        )\n",
    "\n",
    "# predict the targets for each trained model\n",
    "y_pred = predict_targets(models, test.drop(TARGET_COLS, axis=1))\n",
    "\n",
    "# evaluate the models\n",
    "mae = evaluate_mae(y_true = test[TARGET_COLS], y_pred = y_pred)\n",
    "\n",
    "# save the results\n",
    "df_results = df_results.append({'model': 'LassoCV', **mae}, ignore_index=True)\n",
    "\n",
    "# delete the variables to save RAM\n",
    "del models, y_pred, mae\n",
    "\n",
    "# show the results\n",
    "df_results[df_results['model'] == 'LassoCV']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Tree Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import export_graphviz "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12min 43s, sys: 1.09 s, total: 12min 44s\n",
      "Wall time: 12min 44s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>target1</th>\n",
       "      <th>target2</th>\n",
       "      <th>target3</th>\n",
       "      <th>target4</th>\n",
       "      <th>average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree Regressor</td>\n",
       "      <td>1.535279</td>\n",
       "      <td>1.712461</td>\n",
       "      <td>1.48524</td>\n",
       "      <td>1.119111</td>\n",
       "      <td>1.463023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model   target1   target2  target3   target4   average\n",
       "2  Decision Tree Regressor  1.535279  1.712461  1.48524  1.119111  1.463023"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = DecisionTreeRegressor(random_state=RANDOM_SEED)\n",
    "\n",
    "# train the models\n",
    "models = train_models(\n",
    "            model = model, \n",
    "            x_train = train.drop(TARGET_COLS, axis=1), \n",
    "            y_train = train[TARGET_COLS]\n",
    "        )\n",
    "\n",
    "# predict the targets for each trained model\n",
    "y_pred = predict_targets(models, test.drop(TARGET_COLS, axis=1))\n",
    "\n",
    "# evaluate the models\n",
    "mae = evaluate_mae(y_true = test[TARGET_COLS], y_pred = y_pred)\n",
    "\n",
    "# save the results\n",
    "df_results = df_results.append({'model': 'Decision Tree Regressor', **mae}, ignore_index=True)\n",
    "\n",
    "# delete the variables to save RAM\n",
    "del models, y_pred, mae\n",
    "\n",
    "df_results[df_results['model'] == 'Decision Tree Regressor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model = RandomForestRegressor(random_state=RANDOM_SEED)\n",
    "\n",
    "# train the models\n",
    "models = train_models(\n",
    "            model = model, \n",
    "            x_train = train.drop(TARGET_COLS, axis=1), \n",
    "            y_train = train[TARGET_COLS]\n",
    "        )\n",
    "\n",
    "# predict the targets for each trained model\n",
    "y_pred = predict_targets(models, test.drop(TARGET_COLS, axis=1))\n",
    "\n",
    "# evaluate the models\n",
    "mae = evaluate_mae(y_true = test[TARGET_COLS], y_pred = y_pred)\n",
    "\n",
    "# save the results\n",
    "df_results = df_results.append({'model': 'Random Forest Regressor', **mae}, ignore_index=True)\n",
    "\n",
    "# delete the variables to save RAM\n",
    "del models, y_pred, mae\n",
    "\n",
    "df_results[df_results['model'] == 'Random Forest Regressor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model = GradientBoostingRegressor(random_state=RANDOM_SEED)\n",
    "\n",
    "# train the models\n",
    "models = train_models(\n",
    "            model = model,\n",
    "            x_train = train.drop(TARGET_COLS, axis=1),\n",
    "            y_train = train[TARGET_COLS]\n",
    "        )\n",
    "\n",
    "# predict the targets for each trained model\n",
    "y_pred = predict_targets(models, test.drop(TARGET_COLS, axis=1))\n",
    "\n",
    "# evaluate the models\n",
    "mae = evaluate_mae(y_true = test[TARGET_COLS], y_pred = y_pred)\n",
    "\n",
    "# save the results\n",
    "df_results = df_results.append({'model': 'Gradient Boosting Regressor', **mae}, ignore_index=True)\n",
    "\n",
    "# delete the variables to save RAM\n",
    "del models, y_pred, mae\n",
    "\n",
    "df_results[df_results['model'] == 'Gradient Boosting Regressor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model = AdaBoostRegressor(random_state=RANDOM_SEED)\n",
    "\n",
    "# train the models\n",
    "models = train_models(\n",
    "            model = model,\n",
    "            x_train = train.drop(TARGET_COLS, axis=1),\n",
    "            y_train = train[TARGET_COLS]\n",
    "        )\n",
    "\n",
    "# predict the targets for each trained model\n",
    "y_pred = predict_targets(models, test.drop(TARGET_COLS, axis=1))\n",
    "\n",
    "# evaluate the models\n",
    "mae = evaluate_mae(y_true = test[TARGET_COLS], y_pred = y_pred)\n",
    "\n",
    "# save the results\n",
    "df_results = df_results.append({'model': 'AdaBoost Regressor', **mae}, ignore_index=True)\n",
    "\n",
    "# delete the variables to save RAM\n",
    "del models, y_pred, mae\n",
    "\n",
    "df_results[df_results['model'] == 'AdaBoost Regressor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model = BaggingRegressor(random_state=RANDOM_SEED)\n",
    "\n",
    "# train the models\n",
    "models = train_models(\n",
    "            model = model,\n",
    "            x_train = train.drop(TARGET_COLS, axis=1),\n",
    "            y_train = train[TARGET_COLS]\n",
    "        )\n",
    "\n",
    "# predict the targets for each trained model\n",
    "y_pred = predict_targets(models, test.drop(TARGET_COLS, axis=1))\n",
    "\n",
    "# evaluate the models\n",
    "mae = evaluate_mae(y_true = test[TARGET_COLS], y_pred = y_pred)\n",
    "\n",
    "# save the results\n",
    "df_results = df_results.append({'model': 'Bagging Regressor', **mae}, ignore_index=True)\n",
    "\n",
    "# delete the variables to save RAM\n",
    "del models, y_pred, mae\n",
    "\n",
    "df_results[df_results['model'] == 'Bagging Regressor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
