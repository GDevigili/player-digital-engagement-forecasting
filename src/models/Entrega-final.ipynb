{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Fundação Getúlio Vargas - RJ <br>\n",
    "> Escola de Matemática Aplicada (EMAp) <br>\n",
    "> Graduação em Ciência de Dados e Inteligência Artificial <br>\n",
    "> Alunos: Gianlucca Devigili e Maisa de O. Fraiz <br>\n",
    "# Projetos em Ciência de Dados - A1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instruções de execução\n",
    "\n",
    "__(#1)__ De modo a tornar mais rápida a carga dos dados, o projeto utiliza uma cópia dos arquivos em formato pickle (`.pkl`). Para executar o projeto utilizando o o dataset em formato `.csv`, atribua o valor `True` para a variável `V_load_from_csv`\n",
    "\n",
    "**(#2)** Redefina a variável `raw_data_path` para o caminho até o arquivo `train_updated.csv`. Substitua o nome do arquivo caso necessário.\n",
    "\n",
    "**(#3)** Atribua o valor `True` para a variável `save_files` caso ainda não tenha os arquivos `.pkl` dos datasets auxiliares salvos. (Necessário apenas para a primeira execução da sessão de preparação de dados).\n",
    "\n",
    "**(#4)** Atribua o valor `True` para a variável `prepare_data` caso deseje executar a sessão de preparação de dados. (Necessário apenas para a primeira execução da sessão de preparação de dados). Caso contrário as variáveis serão carregadas a partir dos arquivos `.pkl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Variáveis de configuração\n",
    "# (#1) Variável que define se o dataset será carregado de um .csv ou de um .pkl\n",
    "load_from_csv = True\n",
    "\n",
    "# Caminho para o dataset\n",
    "raw_data_path = '../data/raw-data/'\n",
    "dataset_path = raw_data_path + 'train_updated.csv'\n",
    "\n",
    "# Caminho onde serão salvos os dados processados\n",
    "processed_data_path = '../data/processed-data/'\n",
    "\n",
    "# Prepare data\n",
    "# (#4) Variável que define se o dataset será processado ou se será carregado de um .pkl\n",
    "prepare_data = True\n",
    "\n",
    "save_files = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pickle as pkl\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "# disable warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variáveis globais\n",
    "\n",
    "PROCESSED_DATA_PATH = '../data/processed-data/'\n",
    "MODEL_PATH = '../models/trained-models/'\n",
    "\n",
    "TARGET_COLS = ['target1', 'target2', 'target3', 'target4']\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "TEST_SPLIT_DATE = '2021-04-30'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparação dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funções Auxiliares\n",
    "\n",
    "Segue algumas funções utilizadas para a preparação dos dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funções auxiliares para carregar os dados\n",
    "def unpack_json(json_str):\n",
    "    return pd.DataFrame() if pd.isna(json_str) else pd.read_json(json_str)\n",
    "\n",
    "def unpack_data(data, dfs=None, n_jobs=-1):\n",
    "    if dfs is not None:\n",
    "        data = data.loc[:, dfs]\n",
    "    unnested_dfs = {}\n",
    "    for name, column in data.iteritems():\n",
    "        daily_dfs = Parallel(n_jobs=n_jobs)(\n",
    "            delayed(unpack_json)(item) for date, item in column.iteritems())\n",
    "        df = pd.concat(daily_dfs)\n",
    "        unnested_dfs[name] = df\n",
    "    return unnested_dfs\n",
    "\n",
    "def create_id(df, id_cols, id_col_name, dt_col_name = 'Dt'):\n",
    "    df['Id' + dt_col_name + id_col_name] = df[id_cols].apply(lambda x: '_'.join(x.astype(str)), axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 39.4 s\n",
      "Wall time: 40.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# (#1)\n",
    "if load_from_csv:\n",
    "    df_train = pd.read_csv(dataset_path)\n",
    "else: \n",
    "    dataset_path = raw_data_path + 'train.pkl'\n",
    "    df_train = pd.read_pickle(dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cria o Dataframe Targets\n",
    "\n",
    "Dataframe contendo as 4 variáveis _target_ bem como suas respectivas chaves `IdPlayer` e `Dt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2min 28s\n",
      "Wall time: 2min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "if prepare_data:\n",
    "    # criação do dataset de targets\n",
    "    # unpack the data\n",
    "    Y = unpack_data(df_train, dfs = ['nextDayPlayerEngagement'])['nextDayPlayerEngagement']\n",
    "\n",
    "    # change datatypes\n",
    "    Y = Y.astype({name: np.float32 for name in [\"target1\", \"target2\", \"target3\", \"target4\"]})\n",
    "\n",
    "    # match target dates to feature dates and create date index\n",
    "    Y = Y.rename(columns={'engagementMetricsDate': 'date'})\n",
    "\n",
    "    # change datatypes\n",
    "    Y['date'] = pd.to_datetime(Y['date'])\n",
    "\n",
    "    # reset index\n",
    "    Y = Y.set_index('date').to_period('D')\n",
    "    Y.index = Y.index - 1\n",
    "    Y = Y.reset_index()\n",
    "\n",
    "    # rename and select columns\n",
    "    cols_Y = {\n",
    "        'date': 'Dt',\n",
    "        'playerId': 'IdPlayer',\n",
    "        'target1': 'target1',\n",
    "        'target2': 'target2',\n",
    "        'target3': 'target3',\n",
    "        'target4': 'target4'\n",
    "    }\n",
    "    Y = Y[list(cols_Y)]\n",
    "    Y.columns = list(cols_Y.values())\n",
    "    Y['Dt'] = Y['Dt'].astype('datetime64[ns]')\n",
    "    Y = create_id(Y, ['Dt', 'IdPlayer'], 'Player')\n",
    "\n",
    "    if save_files:\n",
    "        pd.to_pickle(Y, processed_data_path + 'targets.pkl')\n",
    "\n",
    "    del Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cria o Dataframe Player Box Scores\n",
    "\n",
    "Cria um dataframe chamado \"playerBoxScores\", que contém informações como o time do jogador e a sua posição no jogo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if prepare_data:\n",
    "    # load the data\n",
    "    df_playerBoxScores = unpack_data(df_train, dfs = ['playerBoxScores'])['playerBoxScores']\n",
    "\n",
    "    # Cria o dataset de jogos\n",
    "    cols = {\n",
    "        # columns related to other dimensions\n",
    "        'gamePk': 'IdGame',\n",
    "        'gameDate': 'DtGame',\n",
    "        'gameTimeUTC': 'DtGameUTC',\n",
    "        'playerId': 'IdPlayer',\n",
    "        'teamId': 'IdTeam',\n",
    "        'jerseyNum': 'NuJersey',\n",
    "        'positionCode': 'CdPosition',\n",
    "        # suggested column\n",
    "        'strikeOutsPitching': 'NuStrikeOutsPitching',\n",
    "    }  \n",
    "    # numeric columns\n",
    "    for numeric_col in list(df_playerBoxScores.columns[12:]):\n",
    "        # skip the columns that contains data about pitching due the amount of Nan values\n",
    "        if 'Pitching' not in numeric_col:\n",
    "            cols[numeric_col] = 'Nu' + numeric_col[0].upper() + numeric_col[1:]\n",
    "\n",
    "    df_playerBoxScores['gameDate'] = df_playerBoxScores['gameDate'] + \" 00:00:00\"\n",
    "\n",
    "    df_playerBoxScores = df_playerBoxScores[list(cols)]\n",
    "    df_playerBoxScores.columns = list(cols.values())\n",
    "    df_playerBoxScores = create_id(df_playerBoxScores, ['DtGame', 'IdPlayer'], 'Player')\n",
    "\n",
    "    # Salva o dataset\n",
    "    if save_files:\n",
    "        pd.to_pickle(df_playerBoxScores, processed_data_path + 'playerBoxScores.pkl')\n",
    "    del df_playerBoxScores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparação dos dados target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(processed_data_path + 'targets.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funções Auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funções auxiliares para o pré-processamento dos dados\n",
    "def sort_df(df: pd.DataFrame, columns: list = ['IdPlayer', 'Dt']) -> None:\n",
    "    \"\"\"Sort the dataframe by the columns passed as argument.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Dataframe to be sorted.\n",
    "        columns (list, optional): Columns to sort the dataframe. Defaults to ['IdPlayer', 'Dt'].\n",
    "        \n",
    "        Returns:\n",
    "            None\n",
    "    \"\"\"\n",
    "    df.sort_values(by=columns, inplace=True)\n",
    "    # reset index\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "def shift_targets(df, shift_vals: list = [1, 2, 3, 4, 5, 6, 7, 14, 30]):\n",
    "    \"\"\"Shift the targets by the values passed as argument.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Dataframe to be shifted.\n",
    "        shift_vals (list, optional): Values to shift the targets. Defaults to [1, 2, 3, 4, 5, 6, 7, 14, 30].\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Dataframe with the shifted targets.\n",
    "    \"\"\"\n",
    "    df_aux = pd.DataFrame()\n",
    "    # Iterate over players to make the shift only using the player data\n",
    "    for player in df['IdPlayer'].unique():\n",
    "        df_player = df[df['IdPlayer'] == player]\n",
    "        # Iterate over the pre-defined shift values\n",
    "        for shift_val in shift_vals:\n",
    "            # Iterate over the targets\n",
    "            for target in TARGET_COLS:\n",
    "                # Make the shift\n",
    "                df_player[f'{target}_shift_{shift_val}'] = df_player[target].shift(shift_val)\n",
    "        # Concatenate the player data with the rest of the data\n",
    "        df_aux = pd.concat([df_aux, df_player], axis=0)\n",
    "        # Remove the player data from memory\n",
    "        del df_player\n",
    "    # df.dropna(inplace=True)\n",
    "    return df_aux\n",
    "\n",
    "\n",
    "def train_test_split(\n",
    "    df: pd.DataFrame\n",
    "    ,test_split_date: str = TEST_SPLIT_DATE\n",
    "    ):\n",
    "    \"\"\"Split the dataframe into train and test sets.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Dataframe to be split.\n",
    "        test_split_date (str, optional): Date to split the dataframe. Defaults to TEST_SPLIT_DATE.\n",
    "    \"\"\"\n",
    "\n",
    "    train = df[(df.Dt <= \"2021-01-31\") & (df.Dt >= \"2018-01-01\")] \n",
    "    val = df[(df.Dt <= \"2021-04-30\") & (df.Dt >= \"2021-02-01\")] \n",
    "    test = df[(df.Dt <= \"2021-07-31\") & (df.Dt >= \"2021-05-01\")]\n",
    "    # train.to_csv('train.csv', index=None)\n",
    "    # val.to_csv('validation.csv', index=None) \n",
    "    # test.to_csv('test.csv', index=None) \n",
    "\n",
    "    return train, test, val\n",
    "\n",
    "\n",
    "def x_y_split(df: pd.DataFrame, target_cols: list = TARGET_COLS):\n",
    "    \"\"\"Split the dataframe into x and y sets.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Dataframe to be split.\n",
    "    \"\"\"\n",
    "    y = df[target_cols]\n",
    "    x = df.drop(target_cols, axis=1)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordenação dos valores\n",
    "\n",
    "Os dados são ordenados por jogador e então por data, para a correta criação das variáveis de _shift_, já que as mesmas são por jogador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dt</th>\n",
       "      <th>IdPlayer</th>\n",
       "      <th>target1</th>\n",
       "      <th>target2</th>\n",
       "      <th>target3</th>\n",
       "      <th>target4</th>\n",
       "      <th>IdDtPlayer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>112526</td>\n",
       "      <td>0.055277</td>\n",
       "      <td>5.496109</td>\n",
       "      <td>0.025839</td>\n",
       "      <td>16.176470</td>\n",
       "      <td>2018-01-01 00:00:00_112526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>112526</td>\n",
       "      <td>0.060625</td>\n",
       "      <td>3.252914</td>\n",
       "      <td>0.030486</td>\n",
       "      <td>8.541353</td>\n",
       "      <td>2018-01-02 00:00:00_112526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>112526</td>\n",
       "      <td>0.029341</td>\n",
       "      <td>1.648352</td>\n",
       "      <td>0.032613</td>\n",
       "      <td>10.490111</td>\n",
       "      <td>2018-01-03 00:00:00_112526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>112526</td>\n",
       "      <td>0.014799</td>\n",
       "      <td>2.665894</td>\n",
       "      <td>0.087422</td>\n",
       "      <td>19.091467</td>\n",
       "      <td>2018-01-04 00:00:00_112526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>112526</td>\n",
       "      <td>0.083916</td>\n",
       "      <td>1.161002</td>\n",
       "      <td>0.024759</td>\n",
       "      <td>6.643879</td>\n",
       "      <td>2018-01-05 00:00:00_112526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Dt  IdPlayer   target1   target2   target3    target4  \\\n",
       "0 2018-01-01    112526  0.055277  5.496109  0.025839  16.176470   \n",
       "1 2018-01-02    112526  0.060625  3.252914  0.030486   8.541353   \n",
       "2 2018-01-03    112526  0.029341  1.648352  0.032613  10.490111   \n",
       "3 2018-01-04    112526  0.014799  2.665894  0.087422  19.091467   \n",
       "4 2018-01-05    112526  0.083916  1.161002  0.024759   6.643879   \n",
       "\n",
       "                   IdDtPlayer  \n",
       "0  2018-01-01 00:00:00_112526  \n",
       "1  2018-01-02 00:00:00_112526  \n",
       "2  2018-01-03 00:00:00_112526  \n",
       "3  2018-01-04 00:00:00_112526  \n",
       "4  2018-01-05 00:00:00_112526  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sort_df(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shifts\n",
    "\n",
    "Cria shifts 1 até 7. Shifts maiores foram desconsiderado pelos testes envolvendo _feature_ selection, que priorizaram os shifts, 1, 2 e 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dt</th>\n",
       "      <th>IdPlayer</th>\n",
       "      <th>target1</th>\n",
       "      <th>target2</th>\n",
       "      <th>target3</th>\n",
       "      <th>target4</th>\n",
       "      <th>IdDtPlayer</th>\n",
       "      <th>target1_shift_1</th>\n",
       "      <th>target2_shift_1</th>\n",
       "      <th>target3_shift_1</th>\n",
       "      <th>...</th>\n",
       "      <th>target3_shift_5</th>\n",
       "      <th>target4_shift_5</th>\n",
       "      <th>target1_shift_6</th>\n",
       "      <th>target2_shift_6</th>\n",
       "      <th>target3_shift_6</th>\n",
       "      <th>target4_shift_6</th>\n",
       "      <th>target1_shift_7</th>\n",
       "      <th>target2_shift_7</th>\n",
       "      <th>target3_shift_7</th>\n",
       "      <th>target4_shift_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>112526</td>\n",
       "      <td>0.055277</td>\n",
       "      <td>5.496109</td>\n",
       "      <td>0.025839</td>\n",
       "      <td>16.176470</td>\n",
       "      <td>2018-01-01 00:00:00_112526</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>112526</td>\n",
       "      <td>0.060625</td>\n",
       "      <td>3.252914</td>\n",
       "      <td>0.030486</td>\n",
       "      <td>8.541353</td>\n",
       "      <td>2018-01-02 00:00:00_112526</td>\n",
       "      <td>0.055277</td>\n",
       "      <td>5.496109</td>\n",
       "      <td>0.025839</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>112526</td>\n",
       "      <td>0.029341</td>\n",
       "      <td>1.648352</td>\n",
       "      <td>0.032613</td>\n",
       "      <td>10.490111</td>\n",
       "      <td>2018-01-03 00:00:00_112526</td>\n",
       "      <td>0.060625</td>\n",
       "      <td>3.252914</td>\n",
       "      <td>0.030486</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>112526</td>\n",
       "      <td>0.014799</td>\n",
       "      <td>2.665894</td>\n",
       "      <td>0.087422</td>\n",
       "      <td>19.091467</td>\n",
       "      <td>2018-01-04 00:00:00_112526</td>\n",
       "      <td>0.029341</td>\n",
       "      <td>1.648352</td>\n",
       "      <td>0.032613</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>112526</td>\n",
       "      <td>0.083916</td>\n",
       "      <td>1.161002</td>\n",
       "      <td>0.024759</td>\n",
       "      <td>6.643879</td>\n",
       "      <td>2018-01-05 00:00:00_112526</td>\n",
       "      <td>0.014799</td>\n",
       "      <td>2.665894</td>\n",
       "      <td>0.087422</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Dt  IdPlayer   target1   target2   target3    target4  \\\n",
       "0 2018-01-01    112526  0.055277  5.496109  0.025839  16.176470   \n",
       "1 2018-01-02    112526  0.060625  3.252914  0.030486   8.541353   \n",
       "2 2018-01-03    112526  0.029341  1.648352  0.032613  10.490111   \n",
       "3 2018-01-04    112526  0.014799  2.665894  0.087422  19.091467   \n",
       "4 2018-01-05    112526  0.083916  1.161002  0.024759   6.643879   \n",
       "\n",
       "                   IdDtPlayer  target1_shift_1  target2_shift_1  \\\n",
       "0  2018-01-01 00:00:00_112526              NaN              NaN   \n",
       "1  2018-01-02 00:00:00_112526         0.055277         5.496109   \n",
       "2  2018-01-03 00:00:00_112526         0.060625         3.252914   \n",
       "3  2018-01-04 00:00:00_112526         0.029341         1.648352   \n",
       "4  2018-01-05 00:00:00_112526         0.014799         2.665894   \n",
       "\n",
       "   target3_shift_1  ...  target3_shift_5  target4_shift_5  target1_shift_6  \\\n",
       "0              NaN  ...              NaN              NaN              NaN   \n",
       "1         0.025839  ...              NaN              NaN              NaN   \n",
       "2         0.030486  ...              NaN              NaN              NaN   \n",
       "3         0.032613  ...              NaN              NaN              NaN   \n",
       "4         0.087422  ...              NaN              NaN              NaN   \n",
       "\n",
       "   target2_shift_6  target3_shift_6  target4_shift_6  target1_shift_7  \\\n",
       "0              NaN              NaN              NaN              NaN   \n",
       "1              NaN              NaN              NaN              NaN   \n",
       "2              NaN              NaN              NaN              NaN   \n",
       "3              NaN              NaN              NaN              NaN   \n",
       "4              NaN              NaN              NaN              NaN   \n",
       "\n",
       "   target2_shift_7  target3_shift_7  target4_shift_7  \n",
       "0              NaN              NaN              NaN  \n",
       "1              NaN              NaN              NaN  \n",
       "2              NaN              NaN              NaN  \n",
       "3              NaN              NaN              NaN  \n",
       "4              NaN              NaN              NaN  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = shift_targets(df, shift_vals=[1, 2, 3, 4, 5, 6, 7])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Junção do dataset playerBoxScores\n",
    "\n",
    "Para rodar nossos modelos, usaremos um dataset que é união do df (targets) e dos playerBoxScores.\n",
    "\n",
    "Também são tratados os NaN dos dados: \n",
    "- Para algumas colunas como NuHits, NuStrikes, etc, os valores são substituídos por 0\n",
    "- Para colunas com poucos valores NaN onde a substituição por 0 não faz sentido (como datas, ID e targets), as linhas contendo NaN são dropadas\n",
    "- Colunas com muitos NaN onde a substituição por outro valor não faz sentido, commo NuJersey ou CdPosition, não serão utilizadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2698457 entries, 0 to 2698456\n",
      "Data columns (total 88 columns):\n",
      " #   Column                    Non-Null Count    Dtype         \n",
      "---  ------                    --------------    -----         \n",
      " 0   Dt                        2698457 non-null  datetime64[ns]\n",
      " 1   IdPlayer_x                2698457 non-null  int64         \n",
      " 2   target1                   2698457 non-null  float32       \n",
      " 3   target2                   2698457 non-null  float32       \n",
      " 4   target3                   2698457 non-null  float32       \n",
      " 5   target4                   2698457 non-null  float32       \n",
      " 6   IdDtPlayer                2698457 non-null  object        \n",
      " 7   target1_shift_1           2696396 non-null  float32       \n",
      " 8   target2_shift_1           2696396 non-null  float32       \n",
      " 9   target3_shift_1           2696396 non-null  float32       \n",
      " 10  target4_shift_1           2696396 non-null  float32       \n",
      " 11  target1_shift_2           2694335 non-null  float32       \n",
      " 12  target2_shift_2           2694335 non-null  float32       \n",
      " 13  target3_shift_2           2694335 non-null  float32       \n",
      " 14  target4_shift_2           2694335 non-null  float32       \n",
      " 15  target1_shift_3           2692274 non-null  float32       \n",
      " 16  target2_shift_3           2692274 non-null  float32       \n",
      " 17  target3_shift_3           2692274 non-null  float32       \n",
      " 18  target4_shift_3           2692274 non-null  float32       \n",
      " 19  target1_shift_4           2690213 non-null  float32       \n",
      " 20  target2_shift_4           2690213 non-null  float32       \n",
      " 21  target3_shift_4           2690213 non-null  float32       \n",
      " 22  target4_shift_4           2690213 non-null  float32       \n",
      " 23  target1_shift_5           2688152 non-null  float32       \n",
      " 24  target2_shift_5           2688152 non-null  float32       \n",
      " 25  target3_shift_5           2688152 non-null  float32       \n",
      " 26  target4_shift_5           2688152 non-null  float32       \n",
      " 27  target1_shift_6           2686091 non-null  float32       \n",
      " 28  target2_shift_6           2686091 non-null  float32       \n",
      " 29  target3_shift_6           2686091 non-null  float32       \n",
      " 30  target4_shift_6           2686091 non-null  float32       \n",
      " 31  target1_shift_7           2684030 non-null  float32       \n",
      " 32  target2_shift_7           2684030 non-null  float32       \n",
      " 33  target3_shift_7           2684030 non-null  float32       \n",
      " 34  target4_shift_7           2684030 non-null  float32       \n",
      " 35  IdGame                    218800 non-null   float64       \n",
      " 36  DtGame                    218800 non-null   object        \n",
      " 37  DtGameUTC                 218800 non-null   object        \n",
      " 38  IdPlayer_y                218800 non-null   float64       \n",
      " 39  IdTeam                    218800 non-null   float64       \n",
      " 40  NuJersey                  218763 non-null   object        \n",
      " 41  CdPosition                218800 non-null   float64       \n",
      " 42  NuStrikeOutsPitching      65252 non-null    float64       \n",
      " 43  NuBattingOrder            182559 non-null   float64       \n",
      " 44  NuGamesPlayedBatting      182564 non-null   float64       \n",
      " 45  NuFlyOuts                 182564 non-null   float64       \n",
      " 46  NuGroundOuts              182564 non-null   float64       \n",
      " 47  NuRunsScored              182564 non-null   float64       \n",
      " 48  NuDoubles                 182564 non-null   float64       \n",
      " 49  NuTriples                 182564 non-null   float64       \n",
      " 50  NuHomeRuns                182564 non-null   float64       \n",
      " 51  NuStrikeOuts              182564 non-null   float64       \n",
      " 52  NuBaseOnBalls             182564 non-null   float64       \n",
      " 53  NuIntentionalWalks        182564 non-null   float64       \n",
      " 54  NuHits                    182564 non-null   float64       \n",
      " 55  NuHitByPitch              182564 non-null   float64       \n",
      " 56  NuAtBats                  182564 non-null   float64       \n",
      " 57  NuCaughtStealing          182564 non-null   float64       \n",
      " 58  NuStolenBases             182564 non-null   float64       \n",
      " 59  NuGroundIntoDoublePlay    182564 non-null   float64       \n",
      " 60  NuGroundIntoTriplePlay    182564 non-null   float64       \n",
      " 61  NuPlateAppearances        182564 non-null   float64       \n",
      " 62  NuTotalBases              182564 non-null   float64       \n",
      " 63  NuRbi                     182564 non-null   float64       \n",
      " 64  NuLeftOnBase              182564 non-null   float64       \n",
      " 65  NuSacBunts                182564 non-null   float64       \n",
      " 66  NuSacFlies                182564 non-null   float64       \n",
      " 67  NuCatchersInterference    182564 non-null   float64       \n",
      " 68  NuPickoffs                182564 non-null   float64       \n",
      " 69  NuInningsPitched          65252 non-null    float64       \n",
      " 70  NuSaveOpportunities       65252 non-null    float64       \n",
      " 71  NuEarnedRuns              65252 non-null    float64       \n",
      " 72  NuBattersFaced            65252 non-null    float64       \n",
      " 73  NuPitchesThrown           65252 non-null    float64       \n",
      " 74  NuBalls                   65252 non-null    float64       \n",
      " 75  NuStrikes                 65252 non-null    float64       \n",
      " 76  NuHitBatsmen              65252 non-null    float64       \n",
      " 77  NuBalks                   65252 non-null    float64       \n",
      " 78  NuWildPitches             65252 non-null    float64       \n",
      " 79  NuInheritedRunners        65252 non-null    float64       \n",
      " 80  NuInheritedRunnersScored  65252 non-null    float64       \n",
      " 81  NuSaves                   55424 non-null    float64       \n",
      " 82  NuHolds                   55424 non-null    float64       \n",
      " 83  NuBlownSaves              55424 non-null    float64       \n",
      " 84  NuAssists                 184461 non-null   float64       \n",
      " 85  NuPutOuts                 184461 non-null   float64       \n",
      " 86  NuErrors                  184461 non-null   float64       \n",
      " 87  NuChances                 184461 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float32(32), float64(50), int64(1), object(4)\n",
      "memory usage: 1.5+ GB\n"
     ]
    }
   ],
   "source": [
    "df_playerBoxScores = pd.read_pickle(processed_data_path + 'playerBoxScores.pkl')\n",
    "\n",
    "df_join = pd.merge(df, df_playerBoxScores, on=['IdDtPlayer'], how='left')\n",
    "df_join.info(null_counts=True)\n",
    "\n",
    "# Substitui os valores Nan das seguintes colunas por 0\n",
    "f = [c for c in df_join.columns if c not in ['IdGame',\n",
    "                                              'DtGame',\n",
    "                                              'DtGameUTC',\n",
    "                                              'IdPlayer_y',\n",
    "                                              'IdTeam',\n",
    "                                              'NuJersey',\n",
    "                                              'CdPosition', \n",
    "                                              'target1_shift_1', \n",
    "                                              'target2_shift_1',\n",
    "                                              'target3_shift_1',\n",
    "                                              'target1_shift_2',\n",
    "                                              'target3_shift_2',\n",
    "                                              'target4_shift_2',\n",
    "                                              'target1_shift_3',\n",
    "                                              'target2_shift_3',\n",
    "                                              'target3_shift_3',\n",
    "                                              'target4_shift_3',\n",
    "                                              'target1_shift_4',\n",
    "                                              'target2_shift_4',\n",
    "                                              'target3_shift_4',\n",
    "                                              'target4_shift_4',\n",
    "                                              'target1_shift_5',\n",
    "                                              'target2_shift_5',\n",
    "                                              'target3_shift_5',\n",
    "                                              'target4_shift_5',\n",
    "                                              'target1_shift_6',\n",
    "                                              'target2_shift_6',\n",
    "                                              'target3_shift_6',\n",
    "                                              'target4_shift_6',\n",
    "                                              'target1_shift_7',\n",
    "                                              'target2_shift_7',\n",
    "                                              'target3_shift_7',\n",
    "                                              'target4_shift_7']]\n",
    "\n",
    "df_join[f] = df_join[f].fillna(0)        \n",
    "\n",
    "# Remove os na das seguintes colunas\n",
    "df_join = df_join.dropna(subset=[             \n",
    "    'target1_shift_1', \n",
    "    'target2_shift_1',\n",
    "    'target3_shift_1',\n",
    "    'target1_shift_2',\n",
    "    'target3_shift_2',\n",
    "    'target4_shift_2',\n",
    "    'target1_shift_3',\n",
    "    'target2_shift_3',\n",
    "    'target3_shift_3',\n",
    "    'target4_shift_3',\n",
    "    'target1_shift_4',\n",
    "    'target2_shift_4',\n",
    "    'target3_shift_4',\n",
    "    'target4_shift_4',\n",
    "    'target1_shift_5',\n",
    "    'target3_shift_5',\n",
    "    'target4_shift_5', \n",
    "    'target1_shift_6',\n",
    "    'target2_shift_6',\n",
    "    'target3_shift_6',\n",
    "    'target4_shift_6',\n",
    "    'target1_shift_7',\n",
    "    'target2_shift_7',\n",
    "    'target3_shift_7',\n",
    "    'target4_shift_7'])\n",
    "\n",
    "# Dropa colunas com vários valores Nan\n",
    "df_join.drop(['IdGame',\n",
    "             'DtGame',\n",
    "             'DtGameUTC',\n",
    "             'IdPlayer_y',\n",
    "             'IdTeam',\n",
    "             'NuJersey',\n",
    "             'CdPosition',\n",
    "             'IdDtPlayer'], axis = 1, inplace = True)\n",
    "\n",
    "\n",
    "df_join.rename(columns={'IdPlayer_x': 'IdPlayer'}, inplace=True)\n",
    "\n",
    "del df_train, df_playerBoxScores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2684030 entries, 7 to 2698456\n",
      "Data columns (total 80 columns):\n",
      " #   Column                    Dtype         \n",
      "---  ------                    -----         \n",
      " 0   Dt                        datetime64[ns]\n",
      " 1   IdPlayer                  int64         \n",
      " 2   target1                   float32       \n",
      " 3   target2                   float32       \n",
      " 4   target3                   float32       \n",
      " 5   target4                   float32       \n",
      " 6   target1_shift_1           float32       \n",
      " 7   target2_shift_1           float32       \n",
      " 8   target3_shift_1           float32       \n",
      " 9   target4_shift_1           float32       \n",
      " 10  target1_shift_2           float32       \n",
      " 11  target2_shift_2           float32       \n",
      " 12  target3_shift_2           float32       \n",
      " 13  target4_shift_2           float32       \n",
      " 14  target1_shift_3           float32       \n",
      " 15  target2_shift_3           float32       \n",
      " 16  target3_shift_3           float32       \n",
      " 17  target4_shift_3           float32       \n",
      " 18  target1_shift_4           float32       \n",
      " 19  target2_shift_4           float32       \n",
      " 20  target3_shift_4           float32       \n",
      " 21  target4_shift_4           float32       \n",
      " 22  target1_shift_5           float32       \n",
      " 23  target2_shift_5           float32       \n",
      " 24  target3_shift_5           float32       \n",
      " 25  target4_shift_5           float32       \n",
      " 26  target1_shift_6           float32       \n",
      " 27  target2_shift_6           float32       \n",
      " 28  target3_shift_6           float32       \n",
      " 29  target4_shift_6           float32       \n",
      " 30  target1_shift_7           float32       \n",
      " 31  target2_shift_7           float32       \n",
      " 32  target3_shift_7           float32       \n",
      " 33  target4_shift_7           float32       \n",
      " 34  NuStrikeOutsPitching      float64       \n",
      " 35  NuBattingOrder            float64       \n",
      " 36  NuGamesPlayedBatting      float64       \n",
      " 37  NuFlyOuts                 float64       \n",
      " 38  NuGroundOuts              float64       \n",
      " 39  NuRunsScored              float64       \n",
      " 40  NuDoubles                 float64       \n",
      " 41  NuTriples                 float64       \n",
      " 42  NuHomeRuns                float64       \n",
      " 43  NuStrikeOuts              float64       \n",
      " 44  NuBaseOnBalls             float64       \n",
      " 45  NuIntentionalWalks        float64       \n",
      " 46  NuHits                    float64       \n",
      " 47  NuHitByPitch              float64       \n",
      " 48  NuAtBats                  float64       \n",
      " 49  NuCaughtStealing          float64       \n",
      " 50  NuStolenBases             float64       \n",
      " 51  NuGroundIntoDoublePlay    float64       \n",
      " 52  NuGroundIntoTriplePlay    float64       \n",
      " 53  NuPlateAppearances        float64       \n",
      " 54  NuTotalBases              float64       \n",
      " 55  NuRbi                     float64       \n",
      " 56  NuLeftOnBase              float64       \n",
      " 57  NuSacBunts                float64       \n",
      " 58  NuSacFlies                float64       \n",
      " 59  NuCatchersInterference    float64       \n",
      " 60  NuPickoffs                float64       \n",
      " 61  NuInningsPitched          float64       \n",
      " 62  NuSaveOpportunities       float64       \n",
      " 63  NuEarnedRuns              float64       \n",
      " 64  NuBattersFaced            float64       \n",
      " 65  NuPitchesThrown           float64       \n",
      " 66  NuBalls                   float64       \n",
      " 67  NuStrikes                 float64       \n",
      " 68  NuHitBatsmen              float64       \n",
      " 69  NuBalks                   float64       \n",
      " 70  NuWildPitches             float64       \n",
      " 71  NuInheritedRunners        float64       \n",
      " 72  NuInheritedRunnersScored  float64       \n",
      " 73  NuSaves                   float64       \n",
      " 74  NuHolds                   float64       \n",
      " 75  NuBlownSaves              float64       \n",
      " 76  NuAssists                 float64       \n",
      " 77  NuPutOuts                 float64       \n",
      " 78  NuErrors                  float64       \n",
      " 79  NuChances                 float64       \n",
      "dtypes: datetime64[ns](1), float32(32), float64(46), int64(1)\n",
      "memory usage: 1.3 GB\n"
     ]
    }
   ],
   "source": [
    "df_join.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divisão treino, teste e validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (2322747, 35), Test shape: (189612, 35), Val shape: (183429, 35)\n"
     ]
    }
   ],
   "source": [
    "train, test, val = train_test_split(df)\n",
    "print(f\"Train shape: {train.shape}, Test shape: {test.shape}, Val shape: {val.shape}\")\n",
    "\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (2322747, 35), Test shape: (189612, 35), Val shape: (183429, 35)\n"
     ]
    }
   ],
   "source": [
    "train_join, test_join, val_join = train_test_split(df_join)\n",
    "print(f\"Train shape: {train.shape}, Test shape: {test.shape}, Val shape: {val.shape}\")\n",
    "\n",
    "del df_join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinando Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(columns = ['model', 'target1', 'target2', 'target3', 'target4', 'average'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funções Auxiliares\n",
    "\n",
    "+ A função `train_models` realiza o treinamento para cada uma das features separadamente e retorna os modelos treinados. A própria função já realiza o processo de `fitting` e retorna os modelos já treinados.\n",
    "+ A função `predict_targets` recebe um modelo e o conjunto de teste e então retorna um dataframe com os valores preditos para os 4 targets.\n",
    "+ A função `evaluate_mae` utiliza os valores preditos pela função acima e compara com o `y_true` retornando os resultados de cada um dos targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to train, predict and evaluate models\n",
    "def train_models(model, x_train, y_train):\n",
    "    \"\"\"Train a model for each target column\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model : sklearn model\n",
    "        Model to be trained\n",
    "    x_train : pd.DataFrame\n",
    "        Training features\n",
    "    y_train : pd.DataFrame\n",
    "        Training targets\n",
    "    \n",
    "    Returns\n",
    "    \n",
    "    -------\n",
    "    list\n",
    "        List of trained models\n",
    "    \"\"\"\n",
    "\n",
    "    models = []\n",
    "    for target in TARGET_COLS:\n",
    "        model.fit(x_train, y_train[target])\n",
    "        models.append(model)\n",
    "    return models\n",
    "\n",
    "\n",
    "def predict_targets(models, x_test):\n",
    "    \"\"\"Predict the targets for each model\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    models : list\n",
    "        List of trained models\n",
    "    x_test : pd.DataFrame\n",
    "        Test features\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Predictions for each target column\n",
    "    \"\"\"\n",
    "\n",
    "    y_preds = pd.DataFrame(columns=TARGET_COLS)\n",
    "    for target, model in zip(TARGET_COLS, models):\n",
    "        y_preds[target] = model.predict(x_test)\n",
    "    return y_preds\n",
    "\n",
    "\n",
    "def evaluate_mae(y_true, y_pred):\n",
    "    \"\"\"Evaluate the mean absolute error for each target column and the average MAE\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : pd.DataFrame\n",
    "        True labels\n",
    "    y_pred : pd.DataFrame\n",
    "        Predictions\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Mean absolute error for each target column\n",
    "    \"\"\"\n",
    "    maes = {}\n",
    "    for target in TARGET_COLS:\n",
    "        mae = mean_absolute_error(y_true[target], y_pred[target])\n",
    "        maes[target] = mae\n",
    "    maes['average'] = np.mean(list(maes.values()))\n",
    "    return maes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Models sem PlayerBoxScore\n",
    "\n",
    "Para os modelos de baseline, fizemos:\n",
    "- Média\n",
    "- Média por jogador\n",
    "- Mediana\n",
    "- Mediana por jogador\n",
    "- Naive\n",
    "\n",
    "Calculamos todos com o dataset sem o PlayerBoxScore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val = pd.concat([train, val], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "media = train_val[TARGET_COLS].mean()\n",
    "media_por_jogador = train_val.groupby('IdPlayer')[TARGET_COLS].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mediana = train_val[TARGET_COLS].median()\n",
    "mediana_por_jogador = train_val.groupby('IdPlayer')[TARGET_COLS].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive = train_val[train_val['Dt']=='2021-04-30'].set_index('IdPlayer')[TARGET_COLS]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>target1</th>\n",
       "      <th>target2</th>\n",
       "      <th>target3</th>\n",
       "      <th>target4</th>\n",
       "      <th>average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Média (sem PBS)</td>\n",
       "      <td>1.126844</td>\n",
       "      <td>2.739029</td>\n",
       "      <td>1.068968</td>\n",
       "      <td>1.477766</td>\n",
       "      <td>1.603152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Média por Jogador (sem PBS)</td>\n",
       "      <td>0.939999</td>\n",
       "      <td>2.251019</td>\n",
       "      <td>0.954300</td>\n",
       "      <td>1.025011</td>\n",
       "      <td>1.292582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mediana (sem PBS)</td>\n",
       "      <td>0.712801</td>\n",
       "      <td>1.651943</td>\n",
       "      <td>0.498075</td>\n",
       "      <td>1.139852</td>\n",
       "      <td>1.000668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mediana por Jogador (sem PBS)</td>\n",
       "      <td>0.702606</td>\n",
       "      <td>1.560620</td>\n",
       "      <td>0.493126</td>\n",
       "      <td>0.925954</td>\n",
       "      <td>0.920577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Naive (sem PBS)</td>\n",
       "      <td>1.168903</td>\n",
       "      <td>1.808041</td>\n",
       "      <td>0.761283</td>\n",
       "      <td>1.520494</td>\n",
       "      <td>1.314680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           model   target1   target2   target3   target4  \\\n",
       "0                Média (sem PBS)  1.126844  2.739029  1.068968  1.477766   \n",
       "1    Média por Jogador (sem PBS)  0.939999  2.251019  0.954300  1.025011   \n",
       "2              Mediana (sem PBS)  0.712801  1.651943  0.498075  1.139852   \n",
       "3  Mediana por Jogador (sem PBS)  0.702606  1.560620  0.493126  0.925954   \n",
       "4                Naive (sem PBS)  1.168903  1.808041  0.761283  1.520494   \n",
       "\n",
       "    average  \n",
       "0  1.603152  \n",
       "1  1.292582  \n",
       "2  1.000668  \n",
       "3  0.920577  \n",
       "4  1.314680  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = pd.DataFrame()\n",
    "\n",
    "for target in TARGET_COLS:\n",
    "    \n",
    "    y_true = test[target]\n",
    "    \n",
    "    mediapj_pred = test['IdPlayer'].map(media_por_jogador[target].to_dict())\n",
    "    medianapj_pred = test['IdPlayer'].map(mediana_por_jogador[target].to_dict())\n",
    "    naive_pred = test['IdPlayer'].map(naive[target].to_dict())\n",
    "    \n",
    "    mediana_pred = [mediana[target] for i in test.index]\n",
    "    media_pred = [media[target] for i in test.index]\n",
    "    \n",
    "\n",
    "    summary.loc['Média (sem PBS)',target]  = mean_absolute_error(y_true,media_pred)\n",
    "    summary.loc['Média por Jogador (sem PBS)',target]  = mean_absolute_error(y_true,mediapj_pred)\n",
    "    summary.loc['Mediana (sem PBS)',target]  = mean_absolute_error(y_true,mediana_pred)\n",
    "    summary.loc['Mediana por Jogador (sem PBS)',target]  = mean_absolute_error(y_true,medianapj_pred)\n",
    "    summary.loc['Naive (sem PBS)',target]  = mean_absolute_error(y_true,naive_pred)\n",
    "    \n",
    "summary['average'] = summary.mean(axis=1)\n",
    "\n",
    "summary = summary.reset_index()\n",
    "summary = summary.rename(columns = {\"index\": \"model\"})\n",
    "df_results = df_results.append(summary, ignore_index = True)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao final, é possível perceber que os dados por jogador tiveram uma performance melhor que os gerais, demonstrando uma grande dependência do resultado em quem é o jogador que está sendo avaliado, o que em termos de negócio é bem relevante já que a popularidade de cada jogador irá se comportar diferente de acordo com o quão famoso ele é. \n",
    "\n",
    "O modelo que obteve melhor resultado foi o de Mediana por Jogador, em todos os targets e na média final. Isso pode seguir de uma ideia que um jogador terá um engagement parecido com a sua mediana (que, ao contrário da média, não é tão afetado por valores extremos), ou seja, um dia de fama não lhe garante fama pra sempre. Os valores extremos que afetam a média possivelmente são casos isolados em que determiado jogador teve uma jogada excelente, foi transferido para um outro time ou até mesmo seu nome apareceu em notícias por motivos externos ao jogo em si. Além disso há toda a questão que uma temporada um jogador pode ter um desempenho excelente e em outras acabar decaindo, ou vice-versa, o que também não afeta tanto a mediana mas acaba alterando um tanto a média."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Models\n",
    "\n",
    "Testaremos agora alguns modelos lineares."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LASSO\n",
    "\n",
    "Primeiro, o modelo LASSO com alpha pré-fixado em 0.1 e os dados contendo o PlayerBoxScores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_join['Dt'] = pd.to_numeric(pd.to_datetime(train_join['Dt']))\n",
    "test_join['Dt']= pd.to_numeric(pd.to_datetime(test_join['Dt']))\n",
    "val_join['Dt'] = pd.to_numeric(pd.to_datetime(val_join['Dt']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 42min 51s\n",
      "Wall time: 7min 9s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>target1</th>\n",
       "      <th>target2</th>\n",
       "      <th>target3</th>\n",
       "      <th>target4</th>\n",
       "      <th>average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lasso | alpha = 0.1 (com PBS)</td>\n",
       "      <td>1.330856</td>\n",
       "      <td>1.458303</td>\n",
       "      <td>1.273847</td>\n",
       "      <td>0.746225</td>\n",
       "      <td>1.202308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           model   target1   target2   target3   target4  \\\n",
       "5  Lasso | alpha = 0.1 (com PBS)  1.330856  1.458303  1.273847  0.746225   \n",
       "\n",
       "    average  \n",
       "5  1.202308  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = Lasso(alpha=0.1, random_state=RANDOM_SEED)\n",
    "\n",
    "# train the models\n",
    "models = train_models(\n",
    "            model = model, \n",
    "            x_train = train_join.drop(TARGET_COLS, axis=1), \n",
    "            y_train = train_join[TARGET_COLS]\n",
    "        )\n",
    "\n",
    "# predict the targets for each trained model\n",
    "y_pred = predict_targets(models, test_join.drop(TARGET_COLS, axis=1))\n",
    "\n",
    "# evaluate the models\n",
    "mae = evaluate_mae(y_true = test_join[TARGET_COLS], y_pred = y_pred)\n",
    "\n",
    "# save the results\n",
    "df_results = df_results.append({'model': 'Lasso | alpha = 0.1 (com PBS)', **mae}, ignore_index=True)\n",
    "\n",
    "# delete the variables to save RAM\n",
    "del models, y_pred, mae\n",
    "\n",
    "# show the results\n",
    "df_results[df_results['model'] == 'Lasso | alpha = 0.1 (com PBS)']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nosso modelo possui uma performance pior que a mediana, mas melhor que outras baselines. \n",
    "\n",
    "Rodamos também o Lasso sem o PlayerBoxScores, o que apresentou uma diferença pouco significativa (indicando talvez que essas features não descrevem os targets muito bem). Mesmo assim, decidimos continuar treinando os modelos com o df_join."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lasso com alpha escolhido por CV\n",
    "\n",
    "Agora, ao invés do alpha pré-fixado, testaremos o parâmetro por meio de Cross Validation, com a função LassoCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3min 49s\n",
      "Wall time: 3min 9s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>target1</th>\n",
       "      <th>target2</th>\n",
       "      <th>target3</th>\n",
       "      <th>target4</th>\n",
       "      <th>average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LassoCV (com PSB)</td>\n",
       "      <td>1.565586</td>\n",
       "      <td>1.888583</td>\n",
       "      <td>1.439029</td>\n",
       "      <td>1.45282</td>\n",
       "      <td>1.586505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               model   target1   target2   target3  target4   average\n",
       "6  LassoCV (com PSB)  1.565586  1.888583  1.439029  1.45282  1.586505"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = LassoCV(random_state=RANDOM_SEED)\n",
    "\n",
    "# train the models\n",
    "models = train_models(\n",
    "            model = model, \n",
    "            x_train = train_join.drop(TARGET_COLS, axis=1), \n",
    "            y_train = train_join[TARGET_COLS]\n",
    "        )\n",
    "\n",
    "# predict the targets for each trained model\n",
    "y_pred = predict_targets(models, test_join.drop(TARGET_COLS, axis=1))\n",
    "\n",
    "# evaluate the models\n",
    "mae = evaluate_mae(y_true = test_join[TARGET_COLS], y_pred = y_pred)\n",
    "\n",
    "# save the results\n",
    "df_results = df_results.append({'model': 'LassoCV (com PSB)', **mae}, ignore_index=True)\n",
    "\n",
    "# delete the variables to save RAM\n",
    "del models, y_pred, mae\n",
    "\n",
    "# show the results\n",
    "df_results[df_results['model'] == 'LassoCV (com PSB)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1241975947556941.5"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alpha escolhido pelo LassoCV:\n",
    "model.alpha_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É possível reparar que o LassoCV selecionou um alpha absurdamente grande, o que significa uma penalização extremamente agressiva (lembrando que alpha = 0 significa, essencialmente, uma regressão linear). \n",
    "\n",
    "Os resultados do LassoCV foram piores que os resultados do Lasso com alpha = 0.1. Apesar de investigarmos o fenômeno, não conseguimos identificar a razão para isso. Mesmo asism, tomamos a decisão de representar a nossa experimentação e manter o código."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge\n",
    "\n",
    "Testaremos também o modelo Ridge, que apesar de parecido com o modelo Lasso, utiliza um método diferente de penalização (penalização L2, ao invés de L1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.69734e-40): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "c:\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.69734e-40): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "c:\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.69734e-40): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "c:\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.69734e-40): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 13.3 s\n",
      "Wall time: 11.3 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>target1</th>\n",
       "      <th>target2</th>\n",
       "      <th>target3</th>\n",
       "      <th>target4</th>\n",
       "      <th>average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ridge (com PSB)</td>\n",
       "      <td>1.329768</td>\n",
       "      <td>1.465329</td>\n",
       "      <td>1.280233</td>\n",
       "      <td>0.75688</td>\n",
       "      <td>1.208053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             model   target1   target2   target3  target4   average\n",
       "7  Ridge (com PSB)  1.329768  1.465329  1.280233  0.75688  1.208053"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = Ridge(random_state=RANDOM_SEED)\n",
    "\n",
    "# train the models\n",
    "models = train_models(\n",
    "            model = model, \n",
    "            x_train = train_join.drop(TARGET_COLS, axis=1), \n",
    "            y_train = train_join[TARGET_COLS]\n",
    "        )\n",
    "\n",
    "# predict the targets for each trained model\n",
    "y_pred = predict_targets(models, test_join.drop(TARGET_COLS, axis=1))\n",
    "\n",
    "# evaluate the models\n",
    "mae = evaluate_mae(y_true = test_join[TARGET_COLS], y_pred = y_pred)\n",
    "\n",
    "# save the results\n",
    "df_results = df_results.append({'model': 'Ridge (com PSB)', **mae}, ignore_index=True)\n",
    "\n",
    "# delete the variables to save RAM\n",
    "del models, y_pred, mae\n",
    "\n",
    "# show the results\n",
    "df_results[df_results['model'] == 'Ridge (com PSB)']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O modelo Ridge obteve resultados extremamente similares ao Lasso (1.201991 vs 1.208053), tendo um desempenho minimamente pior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ElasticNet\n",
    "\n",
    "Como último modelo linear, tentaremos o ElasticNet, que une o _feature elimination_ utilizado pelo Lasso com o _feature coefficient reduction_ utilizado pelo Ridge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 6min 52s\n",
      "Wall time: 1min 30s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>target1</th>\n",
       "      <th>target2</th>\n",
       "      <th>target3</th>\n",
       "      <th>target4</th>\n",
       "      <th>average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ElasticNet (com PSB)</td>\n",
       "      <td>1.329023</td>\n",
       "      <td>1.452151</td>\n",
       "      <td>1.272232</td>\n",
       "      <td>0.750266</td>\n",
       "      <td>1.200918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model   target1   target2   target3   target4   average\n",
       "8  ElasticNet (com PSB)  1.329023  1.452151  1.272232  0.750266  1.200918"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = ElasticNet(random_state=RANDOM_SEED)\n",
    "\n",
    "# train the models\n",
    "models = train_models(\n",
    "            model = model, \n",
    "            x_train = train_join.drop(TARGET_COLS, axis=1), \n",
    "            y_train = train_join[TARGET_COLS]\n",
    "        )\n",
    "\n",
    "# predict the targets for each trained model\n",
    "y_pred = predict_targets(models, test_join.drop(TARGET_COLS, axis=1))\n",
    "\n",
    "# evaluate the models\n",
    "mae = evaluate_mae(y_true = test_join[TARGET_COLS], y_pred = y_pred)\n",
    "\n",
    "# save the results\n",
    "df_results = df_results.append({'model': 'ElasticNet (com PSB)', **mae}, ignore_index=True)\n",
    "\n",
    "# delete the variables to save RAM\n",
    "del models, y_pred, mae\n",
    "\n",
    "# show the results\n",
    "df_results[df_results['model'] == 'ElasticNet (com PSB)']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O ElasticNet obteve resultados melhores que o Lasso e o Ridge, mas mantendo ainda uma diferença de valor apenas no terceiro decimal do MAE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LASSO com feature selection e alpha = 0.1\n",
    "\n",
    "Tentamos também realizar o feature selection utilizando RFE, sendo o modelo mais demorado (6h) e impossibilitando explorá-lo com maior variedade de valores alpha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.247e+07, tolerance: 8.975e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.247e+07, tolerance: 8.975e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.319e+07, tolerance: 5.878e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.319e+07, tolerance: 5.878e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.319e+07, tolerance: 5.878e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.319e+07, tolerance: 5.878e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.319e+07, tolerance: 5.878e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.319e+07, tolerance: 5.878e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.319e+07, tolerance: 5.878e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.319e+07, tolerance: 5.878e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.319e+07, tolerance: 5.878e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.911e+06, tolerance: 3.999e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.870e+06, tolerance: 3.999e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.870e+06, tolerance: 3.999e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.870e+06, tolerance: 3.999e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.870e+06, tolerance: 3.999e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.698e+06, tolerance: 3.999e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1d 8h 32min 42s\n",
      "Wall time: 6h 55min 51s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>target1</th>\n",
       "      <th>target2</th>\n",
       "      <th>target3</th>\n",
       "      <th>target4</th>\n",
       "      <th>average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Média (sem PBS)</td>\n",
       "      <td>1.126844</td>\n",
       "      <td>2.739029</td>\n",
       "      <td>1.068968</td>\n",
       "      <td>1.477766</td>\n",
       "      <td>1.603152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Média por Jogador (sem PBS)</td>\n",
       "      <td>0.939999</td>\n",
       "      <td>2.251019</td>\n",
       "      <td>0.954300</td>\n",
       "      <td>1.025011</td>\n",
       "      <td>1.292582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mediana (sem PBS)</td>\n",
       "      <td>0.712801</td>\n",
       "      <td>1.651943</td>\n",
       "      <td>0.498075</td>\n",
       "      <td>1.139852</td>\n",
       "      <td>1.000668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mediana por Jogador (sem PBS)</td>\n",
       "      <td>0.702606</td>\n",
       "      <td>1.560620</td>\n",
       "      <td>0.493126</td>\n",
       "      <td>0.925954</td>\n",
       "      <td>0.920577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Naive (sem PBS)</td>\n",
       "      <td>1.168903</td>\n",
       "      <td>1.808041</td>\n",
       "      <td>0.761283</td>\n",
       "      <td>1.520494</td>\n",
       "      <td>1.314680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lasso | alpha = 0.1 (com PBS)</td>\n",
       "      <td>1.330856</td>\n",
       "      <td>1.458303</td>\n",
       "      <td>1.273847</td>\n",
       "      <td>0.746225</td>\n",
       "      <td>1.202308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LassoCV (com PSB)</td>\n",
       "      <td>1.565586</td>\n",
       "      <td>1.888583</td>\n",
       "      <td>1.439029</td>\n",
       "      <td>1.452820</td>\n",
       "      <td>1.586505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ridge (com PSB)</td>\n",
       "      <td>1.329768</td>\n",
       "      <td>1.465329</td>\n",
       "      <td>1.280233</td>\n",
       "      <td>0.756880</td>\n",
       "      <td>1.208053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ElasticNet (com PSB)</td>\n",
       "      <td>1.329023</td>\n",
       "      <td>1.452151</td>\n",
       "      <td>1.272232</td>\n",
       "      <td>0.750266</td>\n",
       "      <td>1.200918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Decision Tree Regressor (com PBS)</td>\n",
       "      <td>2.119536</td>\n",
       "      <td>2.297577</td>\n",
       "      <td>2.065007</td>\n",
       "      <td>1.739166</td>\n",
       "      <td>2.055322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Gradient Boosting Regressor (com PBS)</td>\n",
       "      <td>1.364526</td>\n",
       "      <td>1.441502</td>\n",
       "      <td>1.331729</td>\n",
       "      <td>0.729498</td>\n",
       "      <td>1.216814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>FeatureSelection</td>\n",
       "      <td>1.330856</td>\n",
       "      <td>1.458303</td>\n",
       "      <td>1.273847</td>\n",
       "      <td>0.746225</td>\n",
       "      <td>1.202308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    model   target1   target2   target3  \\\n",
       "0                         Média (sem PBS)  1.126844  2.739029  1.068968   \n",
       "1             Média por Jogador (sem PBS)  0.939999  2.251019  0.954300   \n",
       "2                       Mediana (sem PBS)  0.712801  1.651943  0.498075   \n",
       "3           Mediana por Jogador (sem PBS)  0.702606  1.560620  0.493126   \n",
       "4                         Naive (sem PBS)  1.168903  1.808041  0.761283   \n",
       "5           Lasso | alpha = 0.1 (com PBS)  1.330856  1.458303  1.273847   \n",
       "6                       LassoCV (com PSB)  1.565586  1.888583  1.439029   \n",
       "7                         Ridge (com PSB)  1.329768  1.465329  1.280233   \n",
       "8                    ElasticNet (com PSB)  1.329023  1.452151  1.272232   \n",
       "9       Decision Tree Regressor (com PBS)  2.119536  2.297577  2.065007   \n",
       "10  Gradient Boosting Regressor (com PBS)  1.364526  1.441502  1.331729   \n",
       "11                       FeatureSelection  1.330856  1.458303  1.273847   \n",
       "\n",
       "     target4   average  \n",
       "0   1.477766  1.603152  \n",
       "1   1.025011  1.292582  \n",
       "2   1.139852  1.000668  \n",
       "3   0.925954  0.920577  \n",
       "4   1.520494  1.314680  \n",
       "5   0.746225  1.202308  \n",
       "6   1.452820  1.586505  \n",
       "7   0.756880  1.208053  \n",
       "8   0.750266  1.200918  \n",
       "9   1.739166  2.055322  \n",
       "10  0.729498  1.216814  \n",
       "11  0.746225  1.202308  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "rfe_lasso = RFE(Lasso(alpha = 0.1))\n",
    "# train the models\n",
    "models = train_models(\n",
    "            model = rfe_lasso,\n",
    "            x_train = train_join.drop(TARGET_COLS, axis=1),\n",
    "            y_train = train_join[TARGET_COLS]\n",
    "        )\n",
    "\n",
    "# predict the targets for each trained model\n",
    "y_pred = predict_targets(models, test_join.drop(TARGET_COLS, axis=1))\n",
    "\n",
    "# evaluate the models\n",
    "mae = evaluate_mae(y_true = test_join[TARGET_COLS], y_pred = y_pred)\n",
    "\n",
    "# save the results\n",
    "df_results = df_results.append({'model': 'FeatureSelection', **mae}, ignore_index=True)\n",
    "\n",
    "# delete the variables to save RAM\n",
    "del models, y_pred, mae\n",
    "\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe_lasso.get_support(indices=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O resultado do MAE do RFE foi o mesmo que do Lasso com alpha 0.1 sem feature selection, indicando que as features que foram excluídas não colaboraram com o resultado final."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Tree Models\n",
    "\n",
    "Terminada a seção de modelos lineares, testaremos a performance de modelos de árvore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import export_graphviz "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 16min 27s\n",
      "Wall time: 16min 36s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>target1</th>\n",
       "      <th>target2</th>\n",
       "      <th>target3</th>\n",
       "      <th>target4</th>\n",
       "      <th>average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Decision Tree Regressor (com PBS)</td>\n",
       "      <td>2.119536</td>\n",
       "      <td>2.297577</td>\n",
       "      <td>2.065007</td>\n",
       "      <td>1.739166</td>\n",
       "      <td>2.055322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               model   target1   target2   target3   target4  \\\n",
       "9  Decision Tree Regressor (com PBS)  2.119536  2.297577  2.065007  1.739166   \n",
       "\n",
       "    average  \n",
       "9  2.055322  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = DecisionTreeRegressor(random_state=RANDOM_SEED)\n",
    "\n",
    "# train the models\n",
    "models = train_models(\n",
    "            model = model, \n",
    "            x_train = train_join.drop(TARGET_COLS, axis=1), \n",
    "            y_train = train_join[TARGET_COLS]\n",
    "        )\n",
    "\n",
    "# predict the targets for each trained model\n",
    "y_pred = predict_targets(models, test_join.drop(TARGET_COLS, axis=1))\n",
    "\n",
    "# evaluate the models\n",
    "mae = evaluate_mae(y_true = test_join[TARGET_COLS], y_pred = y_pred)\n",
    "\n",
    "# save the results\n",
    "df_results = df_results.append({'model': 'Decision Tree Regressor (com PBS)', **mae}, ignore_index=True)\n",
    "\n",
    "# delete the variables to save RAM\n",
    "del models, y_pred, mae\n",
    "\n",
    "df_results[df_results['model'] == 'Decision Tree Regressor (com PBS)']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O modelo DecisionTreeRegressor obteve resultados piores que, até agora, qualquer outro modelo - sendo assim, não é um método apropriado para estimar os targets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting\n",
    "\n",
    "Por último, rodaremos o Gradient Boosting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2h 46min 44s\n",
      "Wall time: 2h 48min 6s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>target1</th>\n",
       "      <th>target2</th>\n",
       "      <th>target3</th>\n",
       "      <th>target4</th>\n",
       "      <th>average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Gradient Boosting Regressor (com PBS)</td>\n",
       "      <td>1.364526</td>\n",
       "      <td>1.441502</td>\n",
       "      <td>1.331729</td>\n",
       "      <td>0.729498</td>\n",
       "      <td>1.216814</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    model   target1   target2   target3  \\\n",
       "10  Gradient Boosting Regressor (com PBS)  1.364526  1.441502  1.331729   \n",
       "\n",
       "     target4   average  \n",
       "10  0.729498  1.216814  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = GradientBoostingRegressor(random_state=RANDOM_SEED)\n",
    "\n",
    "# train the models\n",
    "models = train_models(\n",
    "            model = model,\n",
    "            x_train = train_join.drop(TARGET_COLS, axis=1),\n",
    "            y_train = train_join[TARGET_COLS]\n",
    "        )\n",
    "\n",
    "# predict the targets for each trained model\n",
    "y_pred = predict_targets(models, test_join.drop(TARGET_COLS, axis=1))\n",
    "\n",
    "# evaluate the models\n",
    "mae = evaluate_mae(y_true = test_join[TARGET_COLS], y_pred = y_pred)\n",
    "\n",
    "# save the results\n",
    "df_results = df_results.append({'model': 'Gradient Boosting Regressor (com PBS)', **mae}, ignore_index=True)\n",
    "\n",
    "# delete the variables to save RAM\n",
    "del models, y_pred, mae\n",
    "\n",
    "df_results[df_results['model'] == 'Gradient Boosting Regressor (com PBS)']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O modelo de Gradient Boosting obteve resultados muito melhores que o Decision Tree Regressor, apesar de ter levado consideravelmente mais tempo (enquanto o DecisionTree levou 16 minutos, o Gradient Boosting levou 2h)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusões\n",
    "\n",
    "Segue abaixo uma tabela com o resultado de todos os modelos testados.\n",
    "\n",
    "Como método, rodamos cada modelo para cada um dos quatro targets invidualmente, calculando a métrica de Mean Absolute Error. Depois, fizemos a média dessa MAE para cada modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>target1</th>\n",
       "      <th>target2</th>\n",
       "      <th>target3</th>\n",
       "      <th>target4</th>\n",
       "      <th>average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Média (sem PBS)</td>\n",
       "      <td>1.126844</td>\n",
       "      <td>2.739029</td>\n",
       "      <td>1.068968</td>\n",
       "      <td>1.477766</td>\n",
       "      <td>1.603152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Média por Jogador (sem PBS)</td>\n",
       "      <td>0.939999</td>\n",
       "      <td>2.251019</td>\n",
       "      <td>0.954300</td>\n",
       "      <td>1.025011</td>\n",
       "      <td>1.292582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mediana (sem PBS)</td>\n",
       "      <td>0.712801</td>\n",
       "      <td>1.651943</td>\n",
       "      <td>0.498075</td>\n",
       "      <td>1.139852</td>\n",
       "      <td>1.000668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mediana por Jogador (sem PBS)</td>\n",
       "      <td>0.702606</td>\n",
       "      <td>1.560620</td>\n",
       "      <td>0.493126</td>\n",
       "      <td>0.925954</td>\n",
       "      <td>0.920577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Naive (sem PBS)</td>\n",
       "      <td>1.168903</td>\n",
       "      <td>1.808041</td>\n",
       "      <td>0.761283</td>\n",
       "      <td>1.520494</td>\n",
       "      <td>1.314680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lasso | alpha = 0.1 (com PBS)</td>\n",
       "      <td>1.330856</td>\n",
       "      <td>1.458303</td>\n",
       "      <td>1.273847</td>\n",
       "      <td>0.746225</td>\n",
       "      <td>1.202308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LassoCV (com PSB)</td>\n",
       "      <td>1.565586</td>\n",
       "      <td>1.888583</td>\n",
       "      <td>1.439029</td>\n",
       "      <td>1.452820</td>\n",
       "      <td>1.586505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ridge (com PSB)</td>\n",
       "      <td>1.329768</td>\n",
       "      <td>1.465329</td>\n",
       "      <td>1.280233</td>\n",
       "      <td>0.756880</td>\n",
       "      <td>1.208053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ElasticNet (com PSB)</td>\n",
       "      <td>1.329023</td>\n",
       "      <td>1.452151</td>\n",
       "      <td>1.272232</td>\n",
       "      <td>0.750266</td>\n",
       "      <td>1.200918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Decision Tree Regressor (com PBS)</td>\n",
       "      <td>2.119536</td>\n",
       "      <td>2.297577</td>\n",
       "      <td>2.065007</td>\n",
       "      <td>1.739166</td>\n",
       "      <td>2.055322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Gradient Boosting Regressor (com PBS)</td>\n",
       "      <td>1.364526</td>\n",
       "      <td>1.441502</td>\n",
       "      <td>1.331729</td>\n",
       "      <td>0.729498</td>\n",
       "      <td>1.216814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>FeatureSelection</td>\n",
       "      <td>1.330856</td>\n",
       "      <td>1.458303</td>\n",
       "      <td>1.273847</td>\n",
       "      <td>0.746225</td>\n",
       "      <td>1.202308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    model   target1   target2   target3  \\\n",
       "0                         Média (sem PBS)  1.126844  2.739029  1.068968   \n",
       "1             Média por Jogador (sem PBS)  0.939999  2.251019  0.954300   \n",
       "2                       Mediana (sem PBS)  0.712801  1.651943  0.498075   \n",
       "3           Mediana por Jogador (sem PBS)  0.702606  1.560620  0.493126   \n",
       "4                         Naive (sem PBS)  1.168903  1.808041  0.761283   \n",
       "5           Lasso | alpha = 0.1 (com PBS)  1.330856  1.458303  1.273847   \n",
       "6                       LassoCV (com PSB)  1.565586  1.888583  1.439029   \n",
       "7                         Ridge (com PSB)  1.329768  1.465329  1.280233   \n",
       "8                    ElasticNet (com PSB)  1.329023  1.452151  1.272232   \n",
       "9       Decision Tree Regressor (com PBS)  2.119536  2.297577  2.065007   \n",
       "10  Gradient Boosting Regressor (com PBS)  1.364526  1.441502  1.331729   \n",
       "11                       FeatureSelection  1.330856  1.458303  1.273847   \n",
       "\n",
       "     target4   average  \n",
       "0   1.477766  1.603152  \n",
       "1   1.025011  1.292582  \n",
       "2   1.139852  1.000668  \n",
       "3   0.925954  0.920577  \n",
       "4   1.520494  1.314680  \n",
       "5   0.746225  1.202308  \n",
       "6   1.452820  1.586505  \n",
       "7   0.756880  1.208053  \n",
       "8   0.750266  1.200918  \n",
       "9   1.739166  2.055322  \n",
       "10  0.729498  1.216814  \n",
       "11  0.746225  1.202308  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado os métodos e métricas utilizadas, é possível fazer alguns pontos finais ao trabalho:\n",
    "\n",
    "- Apesar de testarmos diversos modelos, a Mediana por Jogador permaneceu aquele que obteve os melhores resultados, seguido pela Média. Isso talvez evidencie o fato que existem muitos jogadores com engajamento médio, e estes permanecerão assim independentemente de possíveis picos e depressões em seus resultados. O engajamento geral não é muito afetado pelos outliers, tanto por dias onde há forte engajamento quanto por jogadores extremamente populares - no fim, o sucesso nas redes sociais da média é... mediano.\n",
    "\n",
    "- Modelos lineares obtiveram resultados parecidos independentemente de mudanças em feature selection ou penalização, mostrando que, em termos de hiperespaços, os dados não variam muito independentemente da técnica utilizada.\n",
    "\n",
    "- Como a média dos targets é baixa, provavelmente os modelos estão sempre prevendo um engajamento \"baixo\". Utilizando a métrica MAE, provavelmente o erro é causado pelos targets de jogadores com scores altos e grande popularidade. Outras métricas poderiam ser utilizadas caso estivéssemos tentando focar nos jogadores com picos ou jogadores com uma popularidade naturalmente alta.\n",
    "\n",
    "+ Vale ressaltar que, em modelos previamente apresentados (https://docs.google.com/document/d/17ZVZfrQG8ciJZ7QaXD29VkJ_YCo40uPrNUNhite5k5U/edit?usp=sharing) utilizamos modelos _multitask_, treinando eles para cada uma das 4 features, estes modelos tiveram um desempenho melhor, como por exemplo o Multitask LASSO com uma média de 0.928449 e o Lasso treinado para 4 variáveis simultâneamente com 0.897194. Mostrando que talvez treinar as variáveis simultâneamente seja mais efetivo do que fazê-lo separadamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
