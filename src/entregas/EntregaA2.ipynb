{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Fundação Getúlio Vargas - RJ <br>\n",
    "> Escola de Matemática Aplicada (EMAp) <br>\n",
    "> Graduação em Ciência de Dados e Inteligência Artificial <br>\n",
    "> Alunos: Gianlucca Devigili e Maisa de O. Fraiz <br>\n",
    "# Projetos em Ciência de Dados - A2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introdução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introdução e explicar o foco da A2 (melhorar os resultados dos modelos que a gente fez na A1, não necessariamente criar modelos novos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instruções de Execução"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variáveis de configuração\n",
    "# Variável que define se o dataset será carregado de um .csv ou de um .pkl\n",
    "load_from_csv = False\n",
    "\n",
    "# Caminho para o dataset\n",
    "raw_data_path = '../data/raw-data/'\n",
    "dataset_path = raw_data_path + 'train_updated.csv'\n",
    "\n",
    "# Caminho onde serão salvos os dados processados\n",
    "processed_data_path = '../data/processed-data/'\n",
    "processed_dataset_path = processed_data_path + 'train.pkl' \n",
    "\n",
    "# Prepare data\n",
    "# Variável que define se o dataset será processado ou se será carregado de um .pkl\n",
    "prepare_data = True\n",
    "\n",
    "# Varíavel que define se vai realizar o feature selection ou vai carregar de um .pkl\n",
    "feature_selection = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pickle as pkl\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from pandas.api.types import is_datetime64_any_dtype as is_datetime\n",
    "\n",
    "from functions import *\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "\n",
    "# disable warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variáveis globais\n",
    "\n",
    "PROCESSED_DATA_PATH = '../data/processed-data/'\n",
    "MODEL_PATH = '../models/trained-models/'\n",
    "\n",
    "TARGET_COLS = ['target1', 'target2', 'target3', 'target4']\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "TEST_SPLIT_DATE = '2021-04-30'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções auxiliares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comentar que tá em outro arquivo (ou botar aqui)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga e Tratamento de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframes\n",
    "dataset_names = {\n",
    "    'Awards': 'awards.csv', \n",
    "    'Example': 'example_test.csv', \n",
    "    'Players': 'players.csv',\n",
    "    'Seasons': 'seasons.csv', \n",
    "    'Teams': 'teams.csv', \n",
    "    'Train': 'train_updated.csv'\n",
    "}\n",
    "for key in dataset_names:\n",
    "    dataset_names[key] = raw_data_path + dataset_names[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregando o dataset Train Updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if load_from_csv:\n",
    "    df_train = pd.read_csv(dataset_names['Train'])\n",
    "    pd.to_pickle(df_train, raw_data_path + 'train.pkl')\n",
    "else:\n",
    "    df_train = pd.read_pickle(raw_data_path + 'train.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if prepare_data:\n",
    "\n",
    "    # criação do dataset de targets\n",
    "\n",
    "    # unpack the data\n",
    "    Y = unpack_data(df_train, dfs = ['nextDayPlayerEngagement'])['nextDayPlayerEngagement']\n",
    "\n",
    "    # change datatypes\n",
    "    Y = Y.astype({name: np.float32 for name in [\"target1\", \"target2\", \"target3\", \"target4\"]})\n",
    "\n",
    "    # match target dates to feature dates and create date index\n",
    "    Y = Y.rename(columns={'engagementMetricsDate': 'date'})\n",
    "\n",
    "    # change datatypes\n",
    "    Y['date'] = pd.to_datetime(Y['date'])\n",
    "\n",
    "    # reset index\n",
    "    Y = Y.set_index('date').to_period('D')\n",
    "    Y.index = Y.index - 1\n",
    "    Y = Y.reset_index()\n",
    "\n",
    "    # rename and select columns\n",
    "    cols_Y = {\n",
    "        'date': 'Dt',\n",
    "        'playerId': 'IdPlayer',\n",
    "        'target1': 'target1',\n",
    "        'target2': 'target2',\n",
    "        'target3': 'target3',\n",
    "        'target4': 'target4'\n",
    "    }\n",
    "    Y = Y[list(cols_Y)]\n",
    "    Y.columns = list(cols_Y.values())\n",
    "    Y['Dt'] = Y['Dt'].astype('datetime64[ns]')\n",
    "    Y = create_id(Y, ['Dt', 'IdPlayer'], 'Player')\n",
    "\n",
    "    pd.to_pickle(Y, processed_data_path + 'targets.pkl')\n",
    "\n",
    "    del Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PlayerBoxScores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 49.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if prepare_data:\n",
    "    # load the data\n",
    "    df_playerBoxScores = unpack_data(df_train, dfs = ['playerBoxScores'])['playerBoxScores']\n",
    "\n",
    "    # Cria o dataset de jogos\n",
    "    cols = {\n",
    "        # columns related to other dimensions\n",
    "        'gamePk': 'IdGame',\n",
    "        'gameDate': 'DtGame',\n",
    "        'gameTimeUTC': 'DtGameUTC',\n",
    "        'playerId': 'IdPlayer',\n",
    "        'teamId': 'IdTeam',\n",
    "        'jerseyNum': 'NuJersey',\n",
    "        'positionCode': 'CdPosition',\n",
    "        # suggested column\n",
    "        'strikeOutsPitching': 'NuStrikeOutsPitching',\n",
    "    }  \n",
    "    # numeric columns\n",
    "    for numeric_col in list(df_playerBoxScores.columns[12:]):\n",
    "        # skip the columns that contains data about pitching due the amount of Nan values\n",
    "        if 'Pitching' not in numeric_col:\n",
    "            cols[numeric_col] = 'Nu' + numeric_col[0].upper() + numeric_col[1:] + '_Player'\n",
    "\n",
    "    df_playerBoxScores = df_playerBoxScores[list(cols)]\n",
    "    df_playerBoxScores.columns = list(cols.values())\n",
    "\n",
    "    # df_playerBoxScores['DtGame'] = df_playerBoxScores['DtGame'] + \" 00:00:00\"\n",
    "    df_playerBoxScores['DtGame'] = df_playerBoxScores['DtGame'].astype('datetime64[ns]')\n",
    "    df_playerBoxScores['DtGameUTC'] = df_playerBoxScores['DtGameUTC'].astype('datetime64[ns]')\n",
    "    df_playerBoxScores = create_id(df_playerBoxScores, ['DtGame', 'IdPlayer'], 'Player')\n",
    "    df_playerBoxScores = create_id(df_playerBoxScores, ['DtGame', 'IdTeam'], 'Team')\n",
    "    df_playerBoxScores = create_id(df_playerBoxScores, ['DtGame', 'IdGame'], 'Game')\n",
    "\n",
    "    # Salva o dataset\n",
    "    pd.to_pickle(df_playerBoxScores, processed_data_path + 'playerBoxScores.pkl')\n",
    "\n",
    "    del df_playerBoxScores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Team Box Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.56 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if prepare_data:\n",
    "    df_tbs = unpack_data(df_train, dfs = ['teamBoxScores'])['teamBoxScores']\n",
    "\n",
    "    cols = {\n",
    "        'gameDate': 'DtGame',\n",
    "        'teamId': 'IdTeam',\n",
    "        'home': 'FlgHome',\n",
    "        'gamePk': 'IdGame',\n",
    "    }\n",
    "\n",
    "    for numeric_col in list(df_tbs.columns[4:]):\n",
    "        cols[numeric_col] = 'Nu' + numeric_col[0].upper() + numeric_col[1:] + '_Team'\n",
    "\n",
    "    df_tbs = df_tbs[list(cols)]\n",
    "    df_tbs.columns = list(cols.values())\n",
    "\n",
    "    df_tbs['DtGame'] = df_tbs['DtGame'].astype('datetime64[ns]')\n",
    "    df_tbs = create_id(df_tbs, ['DtGame', 'IdTeam'], 'Team')\n",
    "    df_tbs = create_id(df_tbs, ['DtGame', 'IdGame'], 'Game')\n",
    "    df_tbs['FlgHome'] = df_tbs['FlgHome'].astype('bool')\n",
    "\n",
    "    pd.to_pickle(df_tbs, processed_data_path + 'teamBoxScores.pkl')\n",
    "\n",
    "    del df_tbs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if prepare_data:\n",
    "    df_games = unpack_data(df_train, dfs = ['games'])['games']\n",
    "\n",
    "    cols = {\n",
    "        'gamePk': 'IdGame',\n",
    "        'gameType': 'CdGameType',\n",
    "        'season': 'NuSeason',\n",
    "        'gameDate': 'DtGame',\n",
    "        'codedGameState': 'CdGameState',\n",
    "        'detailedGameState': 'CdGameState',\n",
    "        'isTie': 'FlgTie',\n",
    "        'gameNumber': 'NuGame',\n",
    "        'doubleHeader': 'CdDoubleHeader',\n",
    "        'dayNight': 'CdDayNight',\n",
    "        'scheduledInnings': 'NuScheduledInnings',\n",
    "        'gamesInSeries': 'NuGamesInSeries',\n",
    "        'homeId': 'IdHomeTeam',\n",
    "        'homeWins': 'NuWinsHomeTeam',\n",
    "        'homeLosses': 'NuLossesHomeTeam',\n",
    "        'homeWinPct': 'NuWinPctHomeTeam',\n",
    "        'homeWinner': 'FlgWinnerHomeTeam',\n",
    "        'homeScore': 'NuScoreHomeTeam',\n",
    "        'awayId': 'IdAwayTeam',\n",
    "        'awayWins': 'NuWinsAwayTeam',\n",
    "        'awayLosses': 'NuLossesAwayTeam',\n",
    "        'awayWinPct': 'NuWinPctAwayTeam',\n",
    "        'awayWinner': 'FlgWinnerAwayTeam',\n",
    "        'awayScore': 'NuScoreAwayTeam',\n",
    "    }\n",
    "\n",
    "    df_games = df_games[list(cols)]\n",
    "    df_games.columns = list(cols.values())\n",
    "\n",
    "    df_games['DtGame'] = df_games['DtGame'].astype('datetime64[ns]')\n",
    "    df_games = create_id(df_games, ['DtGame', 'IdGame'], 'Game')\n",
    "\n",
    "    pd.to_pickle(df_games, processed_data_path + 'games.pkl')\n",
    "\n",
    "    del df_games"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamento dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carregando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 878 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if prepare_data:\n",
    "    df_targets = pd.read_pickle(processed_data_path + 'targets.pkl')\n",
    "    df_pbs = pd.read_pickle(processed_data_path + 'playerBoxScores.pkl')\n",
    "    df_tbs = pd.read_pickle(processed_data_path + 'teamBoxScores.pkl')\n",
    "    df_g = pd.read_pickle(processed_data_path + 'games.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reduzindo memória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 95.55 MB\n",
      "Memory usage after optimization is: 33.32 MB\n",
      "Decreased by 65.1%\n",
      "Memory usage of dataframe is 6.72 MB\n",
      "Memory usage after optimization is: 1.43 MB\n",
      "Decreased by 78.6%\n",
      "Wall time: 929 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if prepare_data:\n",
    "    df_pbs = reduce_mem_usage(df_pbs);\n",
    "    df_tbs = reduce_mem_usage(df_tbs);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shifting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if prepare_data:\n",
    "    sort_df(df_targets)\n",
    "    df_train = shift_targets(df_targets, shift_vals=[1, 2, 3, 4, 5, 6, 7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 851 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if prepare_data:\n",
    "    # Transform the datetime col into new features\n",
    "    df_train['DtYear'] = df_train['Dt'].dt.year\n",
    "    df_train['DtMonth'] = df_train['Dt'].dt.month\n",
    "    df_train['DtDay'] = df_train['Dt'].dt.day\n",
    "    df_train['DtDayOfWeek'] = df_train['Dt'].dt.dayofweek\n",
    "    df_train['DtDayOfYear'] = df_train['Dt'].dt.dayofyear\n",
    "    df_train['DtQuarter'] = df_train['Dt'].dt.quarter\n",
    "    # get the hour and minute from the PBS\n",
    "    df_pbs['DtHour'] = df_pbs['DtGameUTC'].dt.hour\n",
    "    df_pbs['DtMinute'] = df_pbs['DtGameUTC'].dt.minute\n",
    "    df_pbs['DtHour'][df_pbs['DtHour'] == 0] = 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unindo os datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Player Box Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 22.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if prepare_data:\n",
    "    df_train = pd.merge(df_train, df_pbs, on=['IdDtPlayer'], how='left')\n",
    "\n",
    "# Substitui os valores Nan das seguintes colunas por 0\n",
    "    f = [c for c in df_train.columns if c not in ['IdGame', 'DtGame', 'DtGameUTC',\n",
    "    'IdPlayer_y','IdTeam','NuJersey','CdPosition', 'target1_shift_1', 'target2_shift_1',\n",
    "    'target3_shift_1','target1_shift_2', 'target3_shift_2', 'target4_shift_2',\n",
    "    'target1_shift_3','target2_shift_3','target3_shift_3','target4_shift_3',\n",
    "    'target1_shift_4','target2_shift_4','target3_shift_4','target4_shift_4',\n",
    "    'target1_shift_5','target2_shift_5','target3_shift_5','target4_shift_5',\n",
    "    'target1_shift_6','target2_shift_6','target3_shift_6','target4_shift_6',\n",
    "    'target1_shift_7','target2_shift_7','target3_shift_7','target4_shift_7']]\n",
    "\n",
    "    df_train[f] = df_train[f].fillna(0)        \n",
    "\n",
    "    # Remove os na das seguintes colunas\n",
    "    df_train = df_train.dropna(subset=[             \n",
    "        'target1_shift_1', 'target2_shift_1', 'target3_shift_1', 'target1_shift_2',\n",
    "        'target3_shift_2', 'target4_shift_2', 'target1_shift_3', 'target2_shift_3',\n",
    "        'target3_shift_3', 'target4_shift_3', 'target1_shift_4', 'target2_shift_4',\n",
    "        'target3_shift_4', 'target4_shift_4', 'target1_shift_5', 'target3_shift_5',\n",
    "        'target4_shift_5', 'target1_shift_6', 'target2_shift_6', 'target3_shift_6',\n",
    "        'target4_shift_6', 'target1_shift_7', 'target2_shift_7', 'target3_shift_7',\n",
    "        'target4_shift_7'])\n",
    "\n",
    "    df_train.rename(columns={'IdPlayer_x': 'IdPlayer'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Team Box Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if prepare_data:\n",
    "    df_train = pd.merge(df_train, df_tbs, on = ['IdDtTeam'], how = 'left')\n",
    "\n",
    "    # Substitui os valores Nan das seguintes colunas por 0\n",
    "    f = [\n",
    "        'FlgHome','NuFlyOuts_Team', 'NuGroundOuts_Team', 'NuRunsScored_Team',\n",
    "        'NuDoubles_Team', 'NuTriples_Team', 'NuHomeRuns_Team', 'NuStrikeOuts_Team',\n",
    "        'NuBaseOnBalls_Team', 'NuIntentionalWalks_Team', 'NuHits_Team', 'NuHitByPitch_Team',\n",
    "        'NuAtBats_Team', 'NuCaughtStealing_Team', 'NuStolenBases_Team', 'NuGroundIntoDoublePlay_Team',\n",
    "        'NuGroundIntoTriplePlay_Team', 'NuPlateAppearances_Team', 'NuTotalBases_Team', 'NuRbi_Team',\n",
    "        'NuLeftOnBase_Team', 'NuSacBunts_Team', 'NuSacFlies_Team', 'NuCatchersInterference_Team',\n",
    "        'NuPickoffs_Team', 'NuAirOutsPitching_Team', 'NuGroundOutsPitching_Team', 'NuRunsPitching_Team',\n",
    "        'NuDoublesPitching_Team', 'NuTriplesPitching_Team', 'NuHomeRunsPitching_Team',\n",
    "        'NuStrikeOutsPitching_Team', 'NuBaseOnBallsPitching_Team', 'NuIntentionalWalksPitching_Team',\n",
    "        'NuHitsPitching_Team', 'NuHitByPitchPitching_Team', 'NuAtBatsPitching_Team',\n",
    "        'NuCaughtStealingPitching_Team', 'NuStolenBasesPitching_Team', 'NuInningsPitched_Team',\n",
    "        'NuEarnedRuns_Team', 'NuBattersFaced_Team', 'NuOutsPitching_Team', 'NuHitBatsmen_Team',\n",
    "        'NuBalks_Team', 'NuWildPitches_Team', 'NuPickoffsPitching_Team', 'NuRbiPitching_Team',\n",
    "        'NuInheritedRunners_Team', 'NuInheritedRunnersScored_Team', 'NuCatchersInterferencePitching_Team',\n",
    "        'NuSacBuntsPitching_Team', 'NuSacFliesPitching_Team'\n",
    "    ]\n",
    "\n",
    "    df_train[f] = df_train[f].fillna(0)        \n",
    "\n",
    "    df_train = df_train.rename(columns={'IdDtGame_y': 'IdDtGame'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min 50s\n",
      "Compiler : 516 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if prepare_data:\n",
    "    df_train = pd.merge(df_train, df_g, on = ['IdDtGame'], how = 'left')\n",
    "\n",
    "    f = [\n",
    "        'NuSeason', 'NuGame',\n",
    "        'NuScheduledInnings', 'NuGamesInSeries', 'NuWinsHomeTeam',\n",
    "        'NuLossesHomeTeam', 'NuWinPctHomeTeam', 'NuScoreHomeTeam',\n",
    "        'NuWinsAwayTeam', 'NuLossesAwayTeam', 'NuWinPctAwayTeam', 'NuScoreAwayTeam'\n",
    "    ]\n",
    "    df_train[f] = df_train[f].fillna(0)        \n",
    "\n",
    "    df_train = pd.get_dummies(df_train, columns = ['CdPosition', \"CdGameType\", \"CdGameState\", \"CdDoubleHeader\", \n",
    "                                        \"CdDayNight\", \"FlgWinnerHomeTeam\", \"FlgWinnerAwayTeam\",'FlgTie', 'FlgHome'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 31.8 s\n",
      "Compiler : 1.25 s\n",
      "Parser   : 715 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if prepare_data:\n",
    "    df_train.drop([\n",
    "    'IdGame_x', 'DtGame_x', 'DtGameUTC', 'IdPlayer_y',\n",
    "    'IdTeam_x', 'IdTeam_y', \"NuGameTimeUTC_Team\", \"IdDtGame\", \"DtGame\", \"IdGame\",\n",
    "    'IdGame_y', 'NuJersey', \"DtGame_y\", \"IdHomeTeam\", \"IdAwayTeam\", \"IdDtPlayer\",\n",
    "    \"IdDtTeam\", \"IdDtGame_x\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salvando datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 2504.28 MB\n",
      "Memory usage after optimization is: 1227.74 MB\n",
      "Decreased by 51.0%\n",
      "Wall time: 2min 45s\n",
      "Parser   : 128 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if prepare_data:\n",
    "    df_train_reduced = reduce_mem_usage(df_train[df_train.columns.difference(['target1', 'target2', 'target3', 'target4'])]) \n",
    "    df_train_reduced[TARGET_COLS]= df_train[TARGET_COLS]\n",
    "\n",
    "    df_train = df_train_reduced.copy()\n",
    "\n",
    "    del df_train_reduced\n",
    "\n",
    "    df_targets.to_pickle(processed_data_path + 'targets.pkl')\n",
    "    df_pbs.to_pickle(processed_data_path + 'playerBoxScores.pkl')\n",
    "    df_tbs.to_pickle(processed_data_path + 'teamBoxScores.pkl')\n",
    "    df_g.to_pickle(processed_data_path + 'games.pkl')\n",
    "\n",
    "    df_train.to_pickle(processed_data_path + 'train.pkl')\n",
    "    \n",
    "    del df_train, df_pbs, df_tbs, df_g, df_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lê os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_pickle(processed_dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparação e Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if feature_selection:\n",
    "    \n",
    "    df_train = df_train.drop(columns = ['IdPlayer'])\n",
    "\n",
    "    train, test, val = train_test_split(df_train)\n",
    "\n",
    "    train['Dt'] = pd.to_numeric(pd.to_datetime(train['Dt']))\n",
    "    test['Dt']= pd.to_numeric(pd.to_datetime(test['Dt']))\n",
    "    val['Dt'] = pd.to_numeric(pd.to_datetime(val['Dt']))\n",
    "\n",
    "    # defines the model and create the multioutput regressor\n",
    "    model = GradientBoostingRegressor(random_state=RANDOM_SEED, loss = 'absolute_error')\n",
    "    model_name = 'GradientBoostingRegressor | MultiOutput'\n",
    "    regressor = MultiOutputRegressor(model, n_jobs=-1)\n",
    "\n",
    "    # fit the model\n",
    "    regressor.fit(train.drop(columns=TARGET_COLS), train[TARGET_COLS])\n",
    "\n",
    "    # make predictions\n",
    "    y_pred = pd.DataFrame(regressor.predict(test.drop(columns=TARGET_COLS)), columns=TARGET_COLS)\n",
    "\n",
    "    for i in range(len(TARGET_COLS)):\n",
    "        plt.bar(range(len(regressor.estimators_[i].feature_importances_)), regressor.estimators_[i].feature_importances_)\n",
    "        plt.show()\n",
    "        for i in range(len(TARGET_COLS)):\n",
    "            plt.bar(range(len(regressor.estimators_[i].feature_importances_)), regressor.estimators_[i].feature_importances_)\n",
    "\n",
    "    selected_features = pd.array([])\n",
    "    for i in range(len(TARGET_COLS)):\n",
    "        features = np.where(regressor.estimators_[i].feature_importances_ >= 0.005)\n",
    "        selected_features = np.append(selected_features, train.drop(columns=TARGET_COLS).columns[features])\n",
    "        selected_features.extend(list(np.where(regressor.estimators_[i].feature_importances_ > 0.0001)))\n",
    "    np.where(regressor.estimators_[0].feature_importances_ > 0.0)\n",
    "    len(np.unique(selected_features))\n",
    "\n",
    "    with open('features.pkl', 'wb') as file:\n",
    "         pickle.dump(selected_features, file)\n",
    "    pickle.load(open('features.pkl', 'rb'))\n",
    "    \n",
    "else:\n",
    "    with open('features.pkl', 'rb') as f:\n",
    "        selected_features = pkl.load(f)\n",
    "    df_train = df_train[np.append(np.append(TARGET_COLS, selected_features), 'IdPlayer')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.loc[:,~df_train.columns.duplicated()].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, val = train_test_split(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(columns = ['model', 'target1 | AMAE', 'target2 | AMAE', 'target3 | AMAE', 'target4 | AMAE', 'average | AMAE', 'average | MAE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decisão de métrica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Texto sobre a decisão de métrica (não tem necessidade de incluir o código testando as métricas, acho)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 22s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>target1 | AMAE</th>\n",
       "      <th>target2 | AMAE</th>\n",
       "      <th>target3 | AMAE</th>\n",
       "      <th>target4 | AMAE</th>\n",
       "      <th>average | AMAE</th>\n",
       "      <th>average | MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Média</td>\n",
       "      <td>6844.194194</td>\n",
       "      <td>6399.400572</td>\n",
       "      <td>7122.047829</td>\n",
       "      <td>6824.235173</td>\n",
       "      <td>5438.296362</td>\n",
       "      <td>1.604042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Média por Jogador</td>\n",
       "      <td>6414.210091</td>\n",
       "      <td>5524.186487</td>\n",
       "      <td>6761.347046</td>\n",
       "      <td>6119.3349</td>\n",
       "      <td>4964.078976</td>\n",
       "      <td>1.316354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mediana</td>\n",
       "      <td>6900.822698</td>\n",
       "      <td>6587.090997</td>\n",
       "      <td>7190.300457</td>\n",
       "      <td>6912.138701</td>\n",
       "      <td>5518.274249</td>\n",
       "      <td>1.018393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mediana por Jogador</td>\n",
       "      <td>6833.982614</td>\n",
       "      <td>6005.49286</td>\n",
       "      <td>7149.275526</td>\n",
       "      <td>6419.210155</td>\n",
       "      <td>5281.781292</td>\n",
       "      <td>0.945302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Naive</td>\n",
       "      <td>6773.84043</td>\n",
       "      <td>6205.150573</td>\n",
       "      <td>7008.533742</td>\n",
       "      <td>6362.128265</td>\n",
       "      <td>5270.162311</td>\n",
       "      <td>1.158547</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model target1 | AMAE target2 | AMAE target3 | AMAE  \\\n",
       "0                Média    6844.194194    6399.400572    7122.047829   \n",
       "1    Média por Jogador    6414.210091    5524.186487    6761.347046   \n",
       "2              Mediana    6900.822698    6587.090997    7190.300457   \n",
       "3  Mediana por Jogador    6833.982614     6005.49286    7149.275526   \n",
       "4                Naive     6773.84043    6205.150573    7008.533742   \n",
       "\n",
       "  target4 | AMAE average | AMAE average | MAE  \n",
       "0    6824.235173    5438.296362      1.604042  \n",
       "1      6119.3349    4964.078976      1.316354  \n",
       "2    6912.138701    5518.274249      1.018393  \n",
       "3    6419.210155    5281.781292      0.945302  \n",
       "4    6362.128265    5270.162311      1.158547  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# naive\n",
    "naive = train[[\"target1_shift_1\", \"target2_shift_1\", \"target3_shift_1\", \"target4_shift_1\", \"IdPlayer\"]].set_index('IdPlayer')\n",
    "naive.rename(columns={'target1_shift_1': 'target1', 'target2_shift_1': 'target2', 'target3_shift_1': 'target3',\n",
    "                     'target4_shift_1': 'target4'}, inplace=True)\n",
    "# media\n",
    "media = train[TARGET_COLS].mean()\n",
    "media_por_jogador = train.groupby('IdPlayer')[TARGET_COLS].mean()\n",
    "\n",
    "# mediana\n",
    "mediana = train[TARGET_COLS].median()\n",
    "mediana_por_jogador = train.groupby('IdPlayer')[TARGET_COLS].median()\n",
    "\n",
    "summary = pd.DataFrame()\n",
    "temp = pd.DataFrame()\n",
    "\n",
    "for target in TARGET_COLS:\n",
    "    \n",
    "    y_true = test[target]\n",
    "   \n",
    "    mediapj_pred = test['IdPlayer'].map(media_por_jogador[target].to_dict())\n",
    "    medianapj_pred = test['IdPlayer'].map(mediana_por_jogador[target].to_dict())\n",
    "    naive_pred = test['IdPlayer'].map(naive[target].to_dict())\n",
    "  \n",
    "    mediana_pred = [mediana[target] for i in test.index]\n",
    "    media_pred = [media[target] for i in test.index]\n",
    "    \n",
    "\n",
    "    temp.loc['Média',target]  = mean_absolute_error(y_true,media_pred)\n",
    "    temp.loc['Média por Jogador',target]  = mean_absolute_error(y_true,mediapj_pred)\n",
    "    temp.loc['Mediana',target]  = mean_absolute_error(y_true,mediana_pred)\n",
    "    temp.loc['Mediana por Jogador',target]  = mean_absolute_error(y_true,medianapj_pred)\n",
    "    temp.loc['Naive',target]  = mean_absolute_error(y_true,naive_pred)\n",
    "    summary.loc['Média',target + \" | AMAE\"]  =  AMAE(y_true,media_pred,show = False)\n",
    "    summary.loc['Média por Jogador',target + \" | AMAE\"]  =  AMAE(y_true,mediapj_pred,show = False)\n",
    "    summary.loc['Mediana',target + \" | AMAE\"]  =  AMAE(y_true,mediana_pred,show = False)\n",
    "    summary.loc['Mediana por Jogador',target + \" | AMAE\"]  =  AMAE(y_true,medianapj_pred,show = False)\n",
    "    summary.loc['Naive',target + \" | AMAE\"]  =  AMAE(y_true,naive_pred,show = False)\n",
    "    \n",
    "summary['average | MAE'] = temp.mean(axis=1)\n",
    "summary['average | AMAE'] = summary.mean(axis=1)\n",
    "\n",
    "summary = summary.reset_index()\n",
    "summary = summary.rename(columns = {\"index\": \"model\"})\n",
    "\n",
    "df_results = df_results.append(summary, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelos Lineares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(columns = ['IdPlayer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Dt'] = pd.to_numeric(pd.to_datetime(train['Dt']))\n",
    "test['Dt']= pd.to_numeric(pd.to_datetime(test['Dt']))\n",
    "val['Dt'] = pd.to_numeric(pd.to_datetime(val['Dt']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# defines the model and create the multioutput regressor\n",
    "model = Lasso(alpha=0.1, random_state=RANDOM_SEED)\n",
    "model_name = 'Lasso | MultiOutput'\n",
    "regressor = MultiOutputRegressor(model, n_jobs=-1)\n",
    "\n",
    "# fit the model\n",
    "regressor.fit(train.drop(columns=TARGET_COLS), train[TARGET_COLS])\n",
    "\n",
    "# make predictions\n",
    "y_pred = pd.DataFrame(regressor.predict(test.drop(columns=TARGET_COLS)), columns=TARGET_COLS)\n",
    "\n",
    "# evaluate the model\n",
    "mae = evaluate_mae(test[TARGET_COLS], y_pred)\n",
    "amae = evaluate_amae(test[TARGET_COLS], y_pred)\n",
    "result_dict = {**amae, **{f'average | MAE': mae['average | MAE']}}\n",
    "\n",
    "# save the results\n",
    "df_results = df_results.append({'model': model_name, **result_dict}, ignore_index=True)\n",
    "df_results[df_results['model'] == model_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 50s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>target1 | AMAE</th>\n",
       "      <th>target2 | AMAE</th>\n",
       "      <th>target3 | AMAE</th>\n",
       "      <th>target4 | AMAE</th>\n",
       "      <th>average | AMAE</th>\n",
       "      <th>average | MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Média</td>\n",
       "      <td>6844.194194</td>\n",
       "      <td>6399.400572</td>\n",
       "      <td>7122.047829</td>\n",
       "      <td>6824.235173</td>\n",
       "      <td>5438.296362</td>\n",
       "      <td>1.604042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Média por Jogador</td>\n",
       "      <td>6414.210091</td>\n",
       "      <td>5524.186487</td>\n",
       "      <td>6761.347046</td>\n",
       "      <td>6119.3349</td>\n",
       "      <td>4964.078976</td>\n",
       "      <td>1.316354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mediana</td>\n",
       "      <td>6900.822698</td>\n",
       "      <td>6587.090997</td>\n",
       "      <td>7190.300457</td>\n",
       "      <td>6912.138701</td>\n",
       "      <td>5518.274249</td>\n",
       "      <td>1.018393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mediana por Jogador</td>\n",
       "      <td>6833.982614</td>\n",
       "      <td>6005.49286</td>\n",
       "      <td>7149.275526</td>\n",
       "      <td>6419.210155</td>\n",
       "      <td>5281.781292</td>\n",
       "      <td>0.945302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Naive</td>\n",
       "      <td>6773.84043</td>\n",
       "      <td>6205.150573</td>\n",
       "      <td>7008.533742</td>\n",
       "      <td>6362.128265</td>\n",
       "      <td>5270.162311</td>\n",
       "      <td>1.158547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ridge | MultiOutput</td>\n",
       "      <td>4895.420876</td>\n",
       "      <td>3919.150979</td>\n",
       "      <td>5695.694745</td>\n",
       "      <td>3599.351708</td>\n",
       "      <td>4527.404577</td>\n",
       "      <td>0.925028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model target1 | AMAE target2 | AMAE target3 | AMAE  \\\n",
       "0                Média    6844.194194    6399.400572    7122.047829   \n",
       "1    Média por Jogador    6414.210091    5524.186487    6761.347046   \n",
       "2              Mediana    6900.822698    6587.090997    7190.300457   \n",
       "3  Mediana por Jogador    6833.982614     6005.49286    7149.275526   \n",
       "4                Naive     6773.84043    6205.150573    7008.533742   \n",
       "5  Ridge | MultiOutput    4895.420876    3919.150979    5695.694745   \n",
       "\n",
       "  target4 | AMAE average | AMAE average | MAE  \n",
       "0    6824.235173    5438.296362      1.604042  \n",
       "1      6119.3349    4964.078976      1.316354  \n",
       "2    6912.138701    5518.274249      1.018393  \n",
       "3    6419.210155    5281.781292      0.945302  \n",
       "4    6362.128265    5270.162311      1.158547  \n",
       "5    3599.351708    4527.404577      0.925028  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# defines the model and create the multioutput regressor\n",
    "model = Ridge(alpha=0.1, random_state=RANDOM_SEED)\n",
    "model_name = 'Ridge | MultiOutput'\n",
    "regressor = MultiOutputRegressor(model, n_jobs=-1)\n",
    "\n",
    "# fit the model\n",
    "regressor.fit(train.drop(columns=TARGET_COLS), train[TARGET_COLS])\n",
    "\n",
    "# make predictions\n",
    "y_pred = pd.DataFrame(regressor.predict(test.drop(columns=TARGET_COLS)), columns=TARGET_COLS)\n",
    "\n",
    "# evaluate the model\n",
    "mae = evaluate_mae(test[TARGET_COLS], y_pred)\n",
    "amae = evaluate_amae(test[TARGET_COLS], y_pred)\n",
    "result_dict = {**amae, **{f'average | MAE': mae['average | MAE']}}\n",
    "\n",
    "# save the results\n",
    "df_results = df_results.append({'model': model_name, **result_dict}, ignore_index=True)\n",
    "df_results[df_results['model'] == model_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "# defines the model and create the multioutput regressor\n",
    "model = ElasticNet(alpha=0.1, random_state=RANDOM_SEED)\n",
    "model_name = 'ElasticNet | MultiOutput'\n",
    "regressor = MultiOutputRegressor(model, n_jobs=-1)\n",
    "\n",
    "# fit the model\n",
    "regressor.fit(train.drop(columns=TARGET_COLS), train[TARGET_COLS])\n",
    "\n",
    "# make predictions\n",
    "y_pred = pd.DataFrame(regressor.predict(test.drop(columns=TARGET_COLS)), columns=TARGET_COLS)\n",
    "\n",
    "\n",
    "# evaluate the model\n",
    "mae = evaluate_mae(test[TARGET_COLS], y_pred)\n",
    "amae = evaluate_amae(test[TARGET_COLS], y_pred)\n",
    "result_dict = {**amae, **{f'average | MAE': mae['average | MAE']}}\n",
    "\n",
    "# save the results\n",
    "df_results = df_results.append({'model': model_name, **result_dict}, ignore_index=True)\n",
    "df_results[df_results['model'] == model_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# defines the model and create the multioutput regressor\n",
    "model = GradientBoostingRegressor(random_state=RANDOM_SEED, loss = 'absolute_error')\n",
    "model_name = 'GradientBoostingRegressor | MultiOutput'\n",
    "regressor = MultiOutputRegressor(model, n_jobs=-1)\n",
    "\n",
    "# fit the model\n",
    "regressor.fit(train.drop(columns=TARGET_COLS), train[TARGET_COLS])\n",
    "\n",
    "# make predictions\n",
    "y_pred = pd.DataFrame(regressor.predict(test.drop(columns=TARGET_COLS)), columns=TARGET_COLS)\n",
    "\n",
    "\n",
    "# evaluate the model\n",
    "mae = evaluate_mae(test[TARGET_COLS], y_pred)\n",
    "amae = evaluate_amae(test[TARGET_COLS], y_pred)\n",
    "result_dict = {**amae, **{f'average | MAE': mae['average | MAE']}}\n",
    "\n",
    "# save the results\n",
    "df_results = df_results.append({'model': model_name, **result_dict}, ignore_index=True)\n",
    "df_results[df_results['model'] == model_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>target1 | AMAE</th>\n",
       "      <th>target2 | AMAE</th>\n",
       "      <th>target3 | AMAE</th>\n",
       "      <th>target4 | AMAE</th>\n",
       "      <th>average | AMAE</th>\n",
       "      <th>average | MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Média</td>\n",
       "      <td>6844.194194</td>\n",
       "      <td>6399.400572</td>\n",
       "      <td>7122.047829</td>\n",
       "      <td>6824.235173</td>\n",
       "      <td>5438.296362</td>\n",
       "      <td>1.604042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Média por Jogador</td>\n",
       "      <td>6414.210091</td>\n",
       "      <td>5524.186487</td>\n",
       "      <td>6761.347046</td>\n",
       "      <td>6119.3349</td>\n",
       "      <td>4964.078976</td>\n",
       "      <td>1.316354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mediana</td>\n",
       "      <td>6900.822698</td>\n",
       "      <td>6587.090997</td>\n",
       "      <td>7190.300457</td>\n",
       "      <td>6912.138701</td>\n",
       "      <td>5518.274249</td>\n",
       "      <td>1.018393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mediana por Jogador</td>\n",
       "      <td>6833.982614</td>\n",
       "      <td>6005.49286</td>\n",
       "      <td>7149.275526</td>\n",
       "      <td>6419.210155</td>\n",
       "      <td>5281.781292</td>\n",
       "      <td>0.945302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Naive</td>\n",
       "      <td>6773.84043</td>\n",
       "      <td>6205.150573</td>\n",
       "      <td>7008.533742</td>\n",
       "      <td>6362.128265</td>\n",
       "      <td>5270.162311</td>\n",
       "      <td>1.158547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ridge | MultiOutput</td>\n",
       "      <td>4895.420876</td>\n",
       "      <td>3919.150979</td>\n",
       "      <td>5695.694745</td>\n",
       "      <td>3599.351708</td>\n",
       "      <td>4527.404577</td>\n",
       "      <td>0.925028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model target1 | AMAE target2 | AMAE target3 | AMAE  \\\n",
       "0                Média    6844.194194    6399.400572    7122.047829   \n",
       "1    Média por Jogador    6414.210091    5524.186487    6761.347046   \n",
       "2              Mediana    6900.822698    6587.090997    7190.300457   \n",
       "3  Mediana por Jogador    6833.982614     6005.49286    7149.275526   \n",
       "4                Naive     6773.84043    6205.150573    7008.533742   \n",
       "5  Ridge | MultiOutput    4895.420876    3919.150979    5695.694745   \n",
       "\n",
       "  target4 | AMAE average | AMAE average | MAE  \n",
       "0    6824.235173    5438.296362      1.604042  \n",
       "1      6119.3349    4964.078976      1.316354  \n",
       "2    6912.138701    5518.274249      1.018393  \n",
       "3    6419.210155    5281.781292      0.945302  \n",
       "4    6362.128265    5270.162311      1.158547  \n",
       "5    3599.351708    4527.404577      0.925028  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusão e melhorias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostrar o que tá melhor que a A1\n",
    "\n",
    "Talvez comentar do multioutput chainging aqui?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Output Chaining\n",
    "\n",
    "[note] adicionar aqui o teste falho de multi output chaining, explicar porque deu errado e mostrar que os resultados de um target não dependem dos demais. Além disso adicionar a correlação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi Output Regressor e Modelos Finais"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
