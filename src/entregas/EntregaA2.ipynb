{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Fundação Getúlio Vargas - RJ <br>\n",
    "> Escola de Matemática Aplicada (EMAp) <br>\n",
    "> Graduação em Ciência de Dados e Inteligência Artificial <br>\n",
    "> Alunos: Gianlucca Devigili e Maisa de O. Fraiz <br>\n",
    "# Projetos em Ciência de Dados - A2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introdução"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introdução e explicar o foco da A2 (melhorar os resultados dos modelos que a gente fez na A1, não necessariamente criar modelos novos)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instruções de Execução"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variáveis de configuração\n",
    "# Variável que define se o dataset será carregado de um .csv ou de um .pkl\n",
    "load_from_csv = False\n",
    "\n",
    "# Caminho para o dataset\n",
    "raw_data_path = '../data/raw-data/'\n",
    "dataset_path = raw_data_path + 'train_updated.csv'\n",
    "\n",
    "# Caminho onde serão salvos os dados processados\n",
    "processed_data_path = '../data/processed-data/'\n",
    "processed_dataset_path = processed_data_path + 'train.pkl' \n",
    "\n",
    "# Prepare data\n",
    "# Variável que define se o dataset será processado ou se será carregado de um .pkl\n",
    "prepare_data = True\n",
    "\n",
    "# Varíavel que define se vai realizar o feature selection ou vai carregar de um .pkl\n",
    "feature_selection = False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pickle as pkl\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from pandas.api.types import is_datetime64_any_dtype as is_datetime\n",
    "\n",
    "from functions import *\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "\n",
    "# disable warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variáveis globais\n",
    "\n",
    "PROCESSED_DATA_PATH = '../data/processed-data/'\n",
    "MODEL_PATH = '../models/trained-models/'\n",
    "\n",
    "TARGET_COLS = ['target1', 'target2', 'target3', 'target4']\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "TEST_SPLIT_DATE = '2021-04-30'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Funções auxiliares"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De modo a manter o notebook mais limpo, optamos por mover as funções aqui utilizadas no arquivo `functions.py`. No arquivo estão as funções:\n",
    "+ `unpack_json` e `unpack_data`: funções provenientes do notebook getting started para o tratamento inicial dos dados.\n",
    "+ `create_id`: função que cria um id baseado na coluna de data e mais uma coluna a ser escolhida de modo a facilitar a operação de _JOIN_ dos diferentes subconjuntos de dados. Os ids utilizados foram `IdDtPlayer`, `IdDtTeam` e `IdDtGame`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Carga e Tratamento de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframes\n",
    "dataset_names = {\n",
    "    'Awards': 'awards.csv', \n",
    "    'Example': 'example_test.csv', \n",
    "    'Players': 'players.csv',\n",
    "    'Seasons': 'seasons.csv', \n",
    "    'Teams': 'teams.csv', \n",
    "    'Train': 'train_updated.csv'\n",
    "}\n",
    "for key in dataset_names:\n",
    "    dataset_names[key] = raw_data_path + dataset_names[key]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregando o dataset Train Updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 59.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if load_from_csv:\n",
    "    df_train = pd.read_csv(dataset_names['Train'])\n",
    "    pd.to_pickle(df_train, raw_data_path + 'train.pkl')\n",
    "else:\n",
    "    df_train = pd.read_pickle(raw_data_path + 'train.pkl')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if prepare_data:\n",
    "\n",
    "    # criação do dataset de targets\n",
    "\n",
    "    # unpack the data\n",
    "    Y = unpack_data(df_train, dfs = ['nextDayPlayerEngagement'])['nextDayPlayerEngagement']\n",
    "\n",
    "    # change datatypes\n",
    "    Y = Y.astype({name: np.float32 for name in [\"target1\", \"target2\", \"target3\", \"target4\"]})\n",
    "\n",
    "    # match target dates to feature dates and create date index\n",
    "    Y = Y.rename(columns={'engagementMetricsDate': 'date'})\n",
    "\n",
    "    # change datatypes\n",
    "    Y['date'] = pd.to_datetime(Y['date'])\n",
    "\n",
    "    # reset index\n",
    "    Y = Y.set_index('date').to_period('D')\n",
    "    Y.index = Y.index - 1\n",
    "    Y = Y.reset_index()\n",
    "\n",
    "    # rename and select columns\n",
    "    cols_Y = {\n",
    "        'date': 'Dt',\n",
    "        'playerId': 'IdPlayer',\n",
    "        'target1': 'target1',\n",
    "        'target2': 'target2',\n",
    "        'target3': 'target3',\n",
    "        'target4': 'target4'\n",
    "    }\n",
    "    Y = Y[list(cols_Y)]\n",
    "    Y.columns = list(cols_Y.values())\n",
    "    Y['Dt'] = Y['Dt'].astype('datetime64[ns]')\n",
    "    Y = create_id(Y, ['Dt', 'IdPlayer'], 'Player')\n",
    "\n",
    "    pd.to_pickle(Y, processed_data_path + 'targets.pkl')\n",
    "\n",
    "    del Y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PlayerBoxScores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 52.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if prepare_data:\n",
    "    # load the data\n",
    "    df_playerBoxScores = unpack_data(df_train, dfs = ['playerBoxScores'])['playerBoxScores']\n",
    "\n",
    "    # Cria o dataset de jogos\n",
    "    cols = {\n",
    "        # columns related to other dimensions\n",
    "        'gamePk': 'IdGame',\n",
    "        'gameDate': 'DtGame',\n",
    "        'gameTimeUTC': 'DtGameUTC',\n",
    "        'playerId': 'IdPlayer',\n",
    "        'teamId': 'IdTeam',\n",
    "        'jerseyNum': 'NuJersey',\n",
    "        'positionCode': 'CdPosition',\n",
    "        # suggested column\n",
    "        'strikeOutsPitching': 'NuStrikeOutsPitching',\n",
    "    }  \n",
    "    # numeric columns\n",
    "    for numeric_col in list(df_playerBoxScores.columns[12:]):\n",
    "        # skip the columns that contains data about pitching due the amount of Nan values\n",
    "        if 'Pitching' not in numeric_col:\n",
    "            cols[numeric_col] = 'Nu' + numeric_col[0].upper() + numeric_col[1:] + '_Player'\n",
    "\n",
    "    df_playerBoxScores = df_playerBoxScores[list(cols)]\n",
    "    df_playerBoxScores.columns = list(cols.values())\n",
    "\n",
    "    # df_playerBoxScores['DtGame'] = df_playerBoxScores['DtGame'] + \" 00:00:00\"\n",
    "    df_playerBoxScores['DtGame'] = df_playerBoxScores['DtGame'].astype('datetime64[ns]')\n",
    "    df_playerBoxScores['DtGameUTC'] = df_playerBoxScores['DtGameUTC'].astype('datetime64[ns]')\n",
    "    df_playerBoxScores = create_id(df_playerBoxScores, ['DtGame', 'IdPlayer'], 'Player')\n",
    "    df_playerBoxScores = create_id(df_playerBoxScores, ['DtGame', 'IdTeam'], 'Team')\n",
    "    df_playerBoxScores = create_id(df_playerBoxScores, ['DtGame', 'IdGame'], 'Game')\n",
    "\n",
    "    # Salva o dataset\n",
    "    pd.to_pickle(df_playerBoxScores, processed_data_path + 'playerBoxScores.pkl')\n",
    "\n",
    "    del df_playerBoxScores"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Team Box Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.54 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if prepare_data:\n",
    "    df_tbs = unpack_data(df_train, dfs = ['teamBoxScores'])['teamBoxScores']\n",
    "\n",
    "    cols = {\n",
    "        'gameDate': 'DtGame',\n",
    "        'teamId': 'IdTeam',\n",
    "        'home': 'FlgHome',\n",
    "        'gamePk': 'IdGame',\n",
    "    }\n",
    "\n",
    "    for numeric_col in list(df_tbs.columns[4:]):\n",
    "        cols[numeric_col] = 'Nu' + numeric_col[0].upper() + numeric_col[1:] + '_Team'\n",
    "\n",
    "    df_tbs = df_tbs[list(cols)]\n",
    "    df_tbs.columns = list(cols.values())\n",
    "\n",
    "    df_tbs['DtGame'] = df_tbs['DtGame'].astype('datetime64[ns]')\n",
    "    df_tbs = create_id(df_tbs, ['DtGame', 'IdTeam'], 'Team')\n",
    "    df_tbs = create_id(df_tbs, ['DtGame', 'IdGame'], 'Game')\n",
    "    df_tbs['FlgHome'] = df_tbs['FlgHome'].astype('bool')\n",
    "\n",
    "    pd.to_pickle(df_tbs, processed_data_path + 'teamBoxScores.pkl')\n",
    "\n",
    "    del df_tbs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7.93 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if prepare_data:\n",
    "    df_games = unpack_data(df_train, dfs = ['games'])['games']\n",
    "\n",
    "    cols = {\n",
    "        'gamePk': 'IdGame',\n",
    "        'gameType': 'CdGameType',\n",
    "        'season': 'NuSeason',\n",
    "        'gameDate': 'DtGame',\n",
    "        'codedGameState': 'CdGameState',\n",
    "        'detailedGameState': 'CdGameState',\n",
    "        'isTie': 'FlgTie',\n",
    "        'gameNumber': 'NuGame',\n",
    "        'doubleHeader': 'CdDoubleHeader',\n",
    "        'dayNight': 'CdDayNight',\n",
    "        'scheduledInnings': 'NuScheduledInnings',\n",
    "        'gamesInSeries': 'NuGamesInSeries',\n",
    "        'homeId': 'IdHomeTeam',\n",
    "        'homeWins': 'NuWinsHomeTeam',\n",
    "        'homeLosses': 'NuLossesHomeTeam',\n",
    "        'homeWinPct': 'NuWinPctHomeTeam',\n",
    "        'homeWinner': 'FlgWinnerHomeTeam',\n",
    "        'homeScore': 'NuScoreHomeTeam',\n",
    "        'awayId': 'IdAwayTeam',\n",
    "        'awayWins': 'NuWinsAwayTeam',\n",
    "        'awayLosses': 'NuLossesAwayTeam',\n",
    "        'awayWinPct': 'NuWinPctAwayTeam',\n",
    "        'awayWinner': 'FlgWinnerAwayTeam',\n",
    "        'awayScore': 'NuScoreAwayTeam',\n",
    "    }\n",
    "\n",
    "    df_games = df_games[list(cols)]\n",
    "    df_games.columns = list(cols.values())\n",
    "\n",
    "    df_games['DtGame'] = df_games['DtGame'].astype('datetime64[ns]')\n",
    "    df_games = create_id(df_games, ['DtGame', 'IdGame'], 'Game')\n",
    "\n",
    "    pd.to_pickle(df_games, processed_data_path + 'games.pkl')\n",
    "\n",
    "    del df_games"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamento dos dados"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carregando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 929 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if prepare_data:\n",
    "    df_targets = pd.read_pickle(processed_data_path + 'targets.pkl')\n",
    "    df_pbs = pd.read_pickle(processed_data_path + 'playerBoxScores.pkl')\n",
    "    df_tbs = pd.read_pickle(processed_data_path + 'teamBoxScores.pkl')\n",
    "    df_g = pd.read_pickle(processed_data_path + 'games.pkl')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reduzindo memória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 95.55 MB\n",
      "Memory usage after optimization is: 33.32 MB\n",
      "Decreased by 65.1%\n",
      "Memory usage of dataframe is 6.72 MB\n",
      "Memory usage after optimization is: 1.43 MB\n",
      "Decreased by 78.6%\n",
      "Wall time: 1.02 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if prepare_data:\n",
    "    df_pbs = reduce_mem_usage(df_pbs);\n",
    "    df_tbs = reduce_mem_usage(df_tbs);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shifting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if prepare_data:\n",
    "    sort_df(df_targets)\n",
    "    df_train = shift_targets(df_targets, shift_vals=[1, 2, 3, 4, 5, 6, 7])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features de Datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.32 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if prepare_data:\n",
    "    # Transform the datetime col into new features\n",
    "    df_train['DtYear'] = df_train['Dt'].dt.year\n",
    "    df_train['DtMonth'] = df_train['Dt'].dt.month\n",
    "    df_train['DtDay'] = df_train['Dt'].dt.day\n",
    "    df_train['DtDayOfWeek'] = df_train['Dt'].dt.dayofweek\n",
    "    df_train['DtDayOfYear'] = df_train['Dt'].dt.dayofyear\n",
    "    df_train['DtQuarter'] = df_train['Dt'].dt.quarter\n",
    "    # get the hour and minute from the PBS\n",
    "    df_pbs['DtHour'] = df_pbs['DtGameUTC'].dt.hour\n",
    "    df_pbs['DtMinute'] = df_pbs['DtGameUTC'].dt.minute\n",
    "    df_pbs['DtHour'][df_pbs['DtHour'] == 0] = 24"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unindo os datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Player Box Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 19.3 s\n",
      "Compiler : 532 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if prepare_data:\n",
    "    df_train = pd.merge(df_train, df_pbs, on=['IdDtPlayer'], how='left')\n",
    "\n",
    "# Substitui os valores Nan das seguintes colunas por 0\n",
    "    f = [c for c in df_train.columns if c not in ['IdGame', 'DtGame', 'DtGameUTC',\n",
    "    'IdPlayer_y','IdTeam','NuJersey','CdPosition', 'target1_shift_1', 'target2_shift_1',\n",
    "    'target3_shift_1','target1_shift_2', 'target3_shift_2', 'target4_shift_2',\n",
    "    'target1_shift_3','target2_shift_3','target3_shift_3','target4_shift_3',\n",
    "    'target1_shift_4','target2_shift_4','target3_shift_4','target4_shift_4',\n",
    "    'target1_shift_5','target2_shift_5','target3_shift_5','target4_shift_5',\n",
    "    'target1_shift_6','target2_shift_6','target3_shift_6','target4_shift_6',\n",
    "    'target1_shift_7','target2_shift_7','target3_shift_7','target4_shift_7']]\n",
    "\n",
    "    df_train[f] = df_train[f].fillna(0)        \n",
    "\n",
    "    # Remove os na das seguintes colunas\n",
    "    df_train = df_train.dropna(subset=[             \n",
    "        'target1_shift_1', 'target2_shift_1', 'target3_shift_1', 'target1_shift_2',\n",
    "        'target3_shift_2', 'target4_shift_2', 'target1_shift_3', 'target2_shift_3',\n",
    "        'target3_shift_3', 'target4_shift_3', 'target1_shift_4', 'target2_shift_4',\n",
    "        'target3_shift_4', 'target4_shift_4', 'target1_shift_5', 'target3_shift_5',\n",
    "        'target4_shift_5', 'target1_shift_6', 'target2_shift_6', 'target3_shift_6',\n",
    "        'target4_shift_6', 'target1_shift_7', 'target2_shift_7', 'target3_shift_7',\n",
    "        'target4_shift_7'])\n",
    "\n",
    "    df_train.rename(columns={'IdPlayer_x': 'IdPlayer'}, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Team Box Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 29.6 s\n",
      "Compiler : 329 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if prepare_data:\n",
    "    df_train = pd.merge(df_train, df_tbs, on = ['IdDtTeam'], how = 'left')\n",
    "\n",
    "    # Substitui os valores Nan das seguintes colunas por 0\n",
    "    f = [\n",
    "        'FlgHome','NuFlyOuts_Team', 'NuGroundOuts_Team', 'NuRunsScored_Team',\n",
    "        'NuDoubles_Team', 'NuTriples_Team', 'NuHomeRuns_Team', 'NuStrikeOuts_Team',\n",
    "        'NuBaseOnBalls_Team', 'NuIntentionalWalks_Team', 'NuHits_Team', 'NuHitByPitch_Team',\n",
    "        'NuAtBats_Team', 'NuCaughtStealing_Team', 'NuStolenBases_Team', 'NuGroundIntoDoublePlay_Team',\n",
    "        'NuGroundIntoTriplePlay_Team', 'NuPlateAppearances_Team', 'NuTotalBases_Team', 'NuRbi_Team',\n",
    "        'NuLeftOnBase_Team', 'NuSacBunts_Team', 'NuSacFlies_Team', 'NuCatchersInterference_Team',\n",
    "        'NuPickoffs_Team', 'NuAirOutsPitching_Team', 'NuGroundOutsPitching_Team', 'NuRunsPitching_Team',\n",
    "        'NuDoublesPitching_Team', 'NuTriplesPitching_Team', 'NuHomeRunsPitching_Team',\n",
    "        'NuStrikeOutsPitching_Team', 'NuBaseOnBallsPitching_Team', 'NuIntentionalWalksPitching_Team',\n",
    "        'NuHitsPitching_Team', 'NuHitByPitchPitching_Team', 'NuAtBatsPitching_Team',\n",
    "        'NuCaughtStealingPitching_Team', 'NuStolenBasesPitching_Team', 'NuInningsPitched_Team',\n",
    "        'NuEarnedRuns_Team', 'NuBattersFaced_Team', 'NuOutsPitching_Team', 'NuHitBatsmen_Team',\n",
    "        'NuBalks_Team', 'NuWildPitches_Team', 'NuPickoffsPitching_Team', 'NuRbiPitching_Team',\n",
    "        'NuInheritedRunners_Team', 'NuInheritedRunnersScored_Team', 'NuCatchersInterferencePitching_Team',\n",
    "        'NuSacBuntsPitching_Team', 'NuSacFliesPitching_Team'\n",
    "    ]\n",
    "\n",
    "    df_train[f] = df_train[f].fillna(0)        \n",
    "\n",
    "    df_train = df_train.rename(columns={'IdDtGame_y': 'IdDtGame'})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 30s\n",
      "Compiler : 187 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if prepare_data:\n",
    "    df_train = pd.merge(df_train, df_g, on = ['IdDtGame'], how = 'left')\n",
    "\n",
    "    f = [\n",
    "        'NuSeason', 'NuGame',\n",
    "        'NuScheduledInnings', 'NuGamesInSeries', 'NuWinsHomeTeam',\n",
    "        'NuLossesHomeTeam', 'NuWinPctHomeTeam', 'NuScoreHomeTeam',\n",
    "        'NuWinsAwayTeam', 'NuLossesAwayTeam', 'NuWinPctAwayTeam', 'NuScoreAwayTeam'\n",
    "    ]\n",
    "    df_train[f] = df_train[f].fillna(0)        \n",
    "\n",
    "    df_train = pd.get_dummies(df_train, columns = ['CdPosition', \"CdGameType\", \"CdGameState\", \"CdDoubleHeader\", \n",
    "                                        \"CdDayNight\", \"FlgWinnerHomeTeam\", \"FlgWinnerAwayTeam\",'FlgTie', 'FlgHome'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 30.8 s\n",
      "Compiler : 1.03 s\n",
      "Parser   : 219 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if prepare_data:\n",
    "    df_train.drop([\n",
    "    'IdGame_x', 'DtGame_x', 'DtGameUTC', 'IdPlayer_y',\n",
    "    'IdTeam_x', 'IdTeam_y', \"NuGameTimeUTC_Team\", \"IdDtGame\", \"DtGame\", \"IdGame\",\n",
    "    'IdGame_y', 'NuJersey', \"DtGame_y\", \"IdHomeTeam\", \"IdAwayTeam\", \"IdDtPlayer\",\n",
    "    \"IdDtTeam\", \"IdDtGame_x\"], axis = 1, inplace = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salvando datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 2134.42 MB\n",
      "Memory usage after optimization is: 960.62 MB\n",
      "Decreased by 55.0%\n",
      "Wall time: 2min 15s\n",
      "Parser   : 345 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if prepare_data:\n",
    "    df_train_reduced = reduce_mem_usage(df_train[df_train.columns.difference(['target1', 'target2', 'target3', 'target4'])]) \n",
    "    df_train_reduced[TARGET_COLS]= df_train[TARGET_COLS]\n",
    "\n",
    "    df_train = df_train_reduced.copy()\n",
    "\n",
    "    del df_train_reduced\n",
    "\n",
    "    df_targets.to_pickle(processed_data_path + 'targets.pkl')\n",
    "    df_pbs.to_pickle(processed_data_path + 'playerBoxScores.pkl')\n",
    "    df_tbs.to_pickle(processed_data_path + 'teamBoxScores.pkl')\n",
    "    df_g.to_pickle(processed_data_path + 'games.pkl')\n",
    "\n",
    "    df_train.to_pickle(processed_data_path + 'train.pkl')\n",
    "    \n",
    "    del df_train, df_pbs, df_tbs, df_g, df_targets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lê os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_pickle(processed_dataset_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparação e Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if feature_selection:\n",
    "    \n",
    "    df_train = df_train.drop(columns = ['IdPlayer'])\n",
    "\n",
    "    train, test, val = train_test_split(df_train)\n",
    "\n",
    "    train['Dt'] = pd.to_numeric(pd.to_datetime(train['Dt']))\n",
    "    test['Dt']= pd.to_numeric(pd.to_datetime(test['Dt']))\n",
    "    val['Dt'] = pd.to_numeric(pd.to_datetime(val['Dt']))\n",
    "\n",
    "    # defines the model and create the multioutput regressor\n",
    "    model = GradientBoostingRegressor(random_state=RANDOM_SEED, loss = 'absolute_error')\n",
    "    model_name = 'GradientBoostingRegressor | MultiOutput'\n",
    "    regressor = MultiOutputRegressor(model, n_jobs=-1)\n",
    "\n",
    "    # fit the model\n",
    "    regressor.fit(train.drop(columns=TARGET_COLS), train[TARGET_COLS])\n",
    "\n",
    "    # make predictions\n",
    "    y_pred = pd.DataFrame(regressor.predict(test.drop(columns=TARGET_COLS)), columns=TARGET_COLS)\n",
    "\n",
    "    for i in range(len(TARGET_COLS)):\n",
    "        plt.bar(range(len(regressor.estimators_[i].feature_importances_)), regressor.estimators_[i].feature_importances_)\n",
    "        plt.show()\n",
    "        for i in range(len(TARGET_COLS)):\n",
    "            plt.bar(range(len(regressor.estimators_[i].feature_importances_)), regressor.estimators_[i].feature_importances_)\n",
    "\n",
    "    selected_features = pd.array([])\n",
    "    for i in range(len(TARGET_COLS)):\n",
    "        features = np.where(regressor.estimators_[i].feature_importances_ >= 0.005)\n",
    "        selected_features = np.append(selected_features, train.drop(columns=TARGET_COLS).columns[features])\n",
    "        selected_features.extend(list(np.where(regressor.estimators_[i].feature_importances_ > 0.0001)))\n",
    "    np.where(regressor.estimators_[0].feature_importances_ > 0.0)\n",
    "    len(np.unique(selected_features))\n",
    "\n",
    "    with open('features.pkl', 'wb') as file:\n",
    "         pickle.dump(selected_features, file)\n",
    "    pickle.load(open('features.pkl', 'rb'))\n",
    "    \n",
    "else:\n",
    "    with open('features.pkl', 'rb') as f:\n",
    "        selected_features = pkl.load(f)\n",
    "    df_train = df_train[np.append(np.append(TARGET_COLS, selected_features), 'IdPlayer')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.loc[:,~df_train.columns.duplicated()].copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, val = train_test_split(df_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(columns = ['model', 'target1 | AMAE', 'target2 | AMAE', 'target3 | AMAE', 'target4 | AMAE', 'average | AMAE', 'average | MAE'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decisão de métrica"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Texto sobre a decisão de métrica (não tem necessidade de incluir o código testando as métricas, acho)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 18s\n",
      "Compiler : 188 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# naive\n",
    "naive = train[[\"target1_shift_1\", \"target2_shift_1\", \"target3_shift_1\", \"target4_shift_1\", \"IdPlayer\"]].set_index('IdPlayer')\n",
    "naive.rename(columns={'target1_shift_1': 'target1', 'target2_shift_1': 'target2', 'target3_shift_1': 'target3',\n",
    "                     'target4_shift_1': 'target4'}, inplace=True)\n",
    "# media\n",
    "media = train[TARGET_COLS].mean()\n",
    "media_por_jogador = train.groupby('IdPlayer')[TARGET_COLS].mean()\n",
    "\n",
    "# mediana\n",
    "mediana = train[TARGET_COLS].median()\n",
    "mediana_por_jogador = train.groupby('IdPlayer')[TARGET_COLS].median()\n",
    "\n",
    "summary = pd.DataFrame()\n",
    "temp = pd.DataFrame()\n",
    "\n",
    "for target in TARGET_COLS:\n",
    "    \n",
    "    y_true = test[target]\n",
    "   \n",
    "    mediapj_pred = test['IdPlayer'].map(media_por_jogador[target].to_dict())\n",
    "    medianapj_pred = test['IdPlayer'].map(mediana_por_jogador[target].to_dict())\n",
    "    naive_pred = test['IdPlayer'].map(naive[target].to_dict())\n",
    "  \n",
    "    mediana_pred = [mediana[target] for i in test.index]\n",
    "    media_pred = [media[target] for i in test.index]\n",
    "    \n",
    "\n",
    "    temp.loc['Média',target]  = mean_absolute_error(y_true,media_pred)\n",
    "    temp.loc['Média por Jogador',target]  = mean_absolute_error(y_true,mediapj_pred)\n",
    "    temp.loc['Mediana',target]  = mean_absolute_error(y_true,mediana_pred)\n",
    "    temp.loc['Mediana por Jogador',target]  = mean_absolute_error(y_true,medianapj_pred)\n",
    "    temp.loc['Naive',target]  = mean_absolute_error(y_true,naive_pred)\n",
    "    summary.loc['Média',target + \" | AMAE\"]  =  AMAE(y_true,media_pred,show = False)\n",
    "    summary.loc['Média por Jogador',target + \" | AMAE\"]  =  AMAE(y_true,mediapj_pred,show = False)\n",
    "    summary.loc['Mediana',target + \" | AMAE\"]  =  AMAE(y_true,mediana_pred,show = False)\n",
    "    summary.loc['Mediana por Jogador',target + \" | AMAE\"]  =  AMAE(y_true,medianapj_pred,show = False)\n",
    "    summary.loc['Naive',target + \" | AMAE\"]  =  AMAE(y_true,naive_pred,show = False)\n",
    "    \n",
    "summary['average | MAE'] = temp.mean(axis=1)\n",
    "summary['average | AMAE'] = summary.mean(axis=1)\n",
    "\n",
    "summary = summary.reset_index()\n",
    "summary = summary.rename(columns = {\"index\": \"model\"})\n",
    "\n",
    "df_results = df_results.append(summary, ignore_index = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelos Lineares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(columns = ['IdPlayer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Dt'] = pd.to_numeric(pd.to_datetime(train['Dt']))\n",
    "test['Dt']= pd.to_numeric(pd.to_datetime(test['Dt']))\n",
    "val['Dt'] = pd.to_numeric(pd.to_datetime(val['Dt']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 17min 17s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>target1 | AMAE</th>\n",
       "      <th>target2 | AMAE</th>\n",
       "      <th>target3 | AMAE</th>\n",
       "      <th>target4 | AMAE</th>\n",
       "      <th>average | AMAE</th>\n",
       "      <th>average | MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lasso | MultiOutput</td>\n",
       "      <td>5067.59576</td>\n",
       "      <td>3949.374541</td>\n",
       "      <td>5768.626309</td>\n",
       "      <td>3629.895891</td>\n",
       "      <td>4603.873125</td>\n",
       "      <td>0.909959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model target1 | AMAE target2 | AMAE target3 | AMAE  \\\n",
       "5  Lasso | MultiOutput     5067.59576    3949.374541    5768.626309   \n",
       "\n",
       "  target4 | AMAE average | AMAE average | MAE  \n",
       "5    3629.895891    4603.873125      0.909959  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# defines the model and create the multioutput regressor\n",
    "model = Lasso(alpha=0.1, random_state=RANDOM_SEED)\n",
    "model_name = 'Lasso | MultiOutput'\n",
    "regressor = MultiOutputRegressor(model, n_jobs=-1)\n",
    "\n",
    "# fit the model\n",
    "regressor.fit(train.drop(columns=TARGET_COLS), train[TARGET_COLS])\n",
    "\n",
    "# make predictions\n",
    "y_pred = pd.DataFrame(regressor.predict(test.drop(columns=TARGET_COLS)), columns=TARGET_COLS)\n",
    "\n",
    "# evaluate the model\n",
    "mae = evaluate_mae(test[TARGET_COLS], y_pred)\n",
    "amae = evaluate_amae(test[TARGET_COLS], y_pred)\n",
    "result_dict = {**amae, **{f'average | MAE': mae['average | MAE']}}\n",
    "\n",
    "# save the results\n",
    "df_results = df_results.append({'model': model_name, **result_dict}, ignore_index=True)\n",
    "df_results[df_results['model'] == model_name]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 37s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>target1 | AMAE</th>\n",
       "      <th>target2 | AMAE</th>\n",
       "      <th>target3 | AMAE</th>\n",
       "      <th>target4 | AMAE</th>\n",
       "      <th>average | AMAE</th>\n",
       "      <th>average | MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ridge | MultiOutput</td>\n",
       "      <td>4895.420876</td>\n",
       "      <td>3919.150979</td>\n",
       "      <td>5695.694745</td>\n",
       "      <td>3599.351708</td>\n",
       "      <td>4527.404577</td>\n",
       "      <td>0.925028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model target1 | AMAE target2 | AMAE target3 | AMAE  \\\n",
       "6  Ridge | MultiOutput    4895.420876    3919.150979    5695.694745   \n",
       "\n",
       "  target4 | AMAE average | AMAE average | MAE  \n",
       "6    3599.351708    4527.404577      0.925028  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# defines the model and create the multioutput regressor\n",
    "model = Ridge(alpha=0.1, random_state=RANDOM_SEED)\n",
    "model_name = 'Ridge | MultiOutput'\n",
    "regressor = MultiOutputRegressor(model, n_jobs=-1)\n",
    "\n",
    "# fit the model\n",
    "regressor.fit(train.drop(columns=TARGET_COLS), train[TARGET_COLS])\n",
    "\n",
    "# make predictions\n",
    "y_pred = pd.DataFrame(regressor.predict(test.drop(columns=TARGET_COLS)), columns=TARGET_COLS)\n",
    "\n",
    "# evaluate the model\n",
    "mae = evaluate_mae(test[TARGET_COLS], y_pred)\n",
    "amae = evaluate_amae(test[TARGET_COLS], y_pred)\n",
    "result_dict = {**amae, **{f'average | MAE': mae['average | MAE']}}\n",
    "\n",
    "# save the results\n",
    "df_results = df_results.append({'model': model_name, **result_dict}, ignore_index=True)\n",
    "df_results[df_results['model'] == model_name]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11min 52s\n",
      "Parser   : 291 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>target1 | AMAE</th>\n",
       "      <th>target2 | AMAE</th>\n",
       "      <th>target3 | AMAE</th>\n",
       "      <th>target4 | AMAE</th>\n",
       "      <th>average | AMAE</th>\n",
       "      <th>average | MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ElasticNet | MultiOutput</td>\n",
       "      <td>5039.66974</td>\n",
       "      <td>3940.878062</td>\n",
       "      <td>5750.295247</td>\n",
       "      <td>3620.259616</td>\n",
       "      <td>4587.775666</td>\n",
       "      <td>0.914881</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      model target1 | AMAE target2 | AMAE target3 | AMAE  \\\n",
       "7  ElasticNet | MultiOutput     5039.66974    3940.878062    5750.295247   \n",
       "\n",
       "  target4 | AMAE average | AMAE average | MAE  \n",
       "7    3620.259616    4587.775666      0.914881  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "# defines the model and create the multioutput regressor\n",
    "model = ElasticNet(alpha=0.1, random_state=RANDOM_SEED)\n",
    "model_name = 'ElasticNet | MultiOutput'\n",
    "regressor = MultiOutputRegressor(model, n_jobs=-1)\n",
    "\n",
    "# fit the model\n",
    "regressor.fit(train.drop(columns=TARGET_COLS), train[TARGET_COLS])\n",
    "\n",
    "# make predictions\n",
    "y_pred = pd.DataFrame(regressor.predict(test.drop(columns=TARGET_COLS)), columns=TARGET_COLS)\n",
    "\n",
    "\n",
    "# evaluate the model\n",
    "mae = evaluate_mae(test[TARGET_COLS], y_pred)\n",
    "amae = evaluate_amae(test[TARGET_COLS], y_pred)\n",
    "result_dict = {**amae, **{f'average | MAE': mae['average | MAE']}}\n",
    "\n",
    "# save the results\n",
    "df_results = df_results.append({'model': model_name, **result_dict}, ignore_index=True)\n",
    "df_results[df_results['model'] == model_name]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 58min 33s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>target1 | AMAE</th>\n",
       "      <th>target2 | AMAE</th>\n",
       "      <th>target3 | AMAE</th>\n",
       "      <th>target4 | AMAE</th>\n",
       "      <th>average | AMAE</th>\n",
       "      <th>average | MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GradientBoostingRegressor | MultiOutput</td>\n",
       "      <td>6181.200965</td>\n",
       "      <td>5375.246921</td>\n",
       "      <td>6602.535582</td>\n",
       "      <td>5236.409038</td>\n",
       "      <td>5848.848126</td>\n",
       "      <td>0.707736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     model target1 | AMAE target2 | AMAE  \\\n",
       "8  GradientBoostingRegressor | MultiOutput    6181.200965    5375.246921   \n",
       "\n",
       "  target3 | AMAE target4 | AMAE average | AMAE average | MAE  \n",
       "8    6602.535582    5236.409038    5848.848126      0.707736  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# defines the model and create the multioutput regressor\n",
    "model = GradientBoostingRegressor(random_state=RANDOM_SEED, loss = 'absolute_error')\n",
    "model_name = 'GradientBoostingRegressor | MultiOutput'\n",
    "regressor = MultiOutputRegressor(model, n_jobs=-1)\n",
    "\n",
    "# fit the model\n",
    "regressor.fit(train.drop(columns=TARGET_COLS), train[TARGET_COLS])\n",
    "\n",
    "# make predictions\n",
    "y_pred = pd.DataFrame(regressor.predict(test.drop(columns=TARGET_COLS)), columns=TARGET_COLS)\n",
    "\n",
    "\n",
    "# evaluate the model\n",
    "mae = evaluate_mae(test[TARGET_COLS], y_pred)\n",
    "amae = evaluate_amae(test[TARGET_COLS], y_pred)\n",
    "result_dict = {**amae, **{f'average | MAE': mae['average | MAE']}}\n",
    "\n",
    "# save the results\n",
    "df_results = df_results.append({'model': model_name, **result_dict}, ignore_index=True)\n",
    "df_results[df_results['model'] == model_name]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>target1 | AMAE</th>\n",
       "      <th>target2 | AMAE</th>\n",
       "      <th>target3 | AMAE</th>\n",
       "      <th>target4 | AMAE</th>\n",
       "      <th>average | AMAE</th>\n",
       "      <th>average | MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Média</td>\n",
       "      <td>6844.194194</td>\n",
       "      <td>6399.400572</td>\n",
       "      <td>7122.047829</td>\n",
       "      <td>6824.235173</td>\n",
       "      <td>5438.296362</td>\n",
       "      <td>1.604042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Média por Jogador</td>\n",
       "      <td>6414.210091</td>\n",
       "      <td>5524.186487</td>\n",
       "      <td>6761.347046</td>\n",
       "      <td>6119.3349</td>\n",
       "      <td>4964.078976</td>\n",
       "      <td>1.316354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mediana</td>\n",
       "      <td>6900.822698</td>\n",
       "      <td>6587.090997</td>\n",
       "      <td>7190.300457</td>\n",
       "      <td>6912.138701</td>\n",
       "      <td>5518.274249</td>\n",
       "      <td>1.018393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mediana por Jogador</td>\n",
       "      <td>6833.982614</td>\n",
       "      <td>6005.49286</td>\n",
       "      <td>7149.275526</td>\n",
       "      <td>6419.210155</td>\n",
       "      <td>5281.781292</td>\n",
       "      <td>0.945302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Naive</td>\n",
       "      <td>6773.84043</td>\n",
       "      <td>6205.150573</td>\n",
       "      <td>7008.533742</td>\n",
       "      <td>6362.128265</td>\n",
       "      <td>5270.162311</td>\n",
       "      <td>1.158547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lasso | MultiOutput</td>\n",
       "      <td>5067.59576</td>\n",
       "      <td>3949.374541</td>\n",
       "      <td>5768.626309</td>\n",
       "      <td>3629.895891</td>\n",
       "      <td>4603.873125</td>\n",
       "      <td>0.909959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ridge | MultiOutput</td>\n",
       "      <td>4895.420876</td>\n",
       "      <td>3919.150979</td>\n",
       "      <td>5695.694745</td>\n",
       "      <td>3599.351708</td>\n",
       "      <td>4527.404577</td>\n",
       "      <td>0.925028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ElasticNet | MultiOutput</td>\n",
       "      <td>5039.66974</td>\n",
       "      <td>3940.878062</td>\n",
       "      <td>5750.295247</td>\n",
       "      <td>3620.259616</td>\n",
       "      <td>4587.775666</td>\n",
       "      <td>0.914881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GradientBoostingRegressor | MultiOutput</td>\n",
       "      <td>6181.200965</td>\n",
       "      <td>5375.246921</td>\n",
       "      <td>6602.535582</td>\n",
       "      <td>5236.409038</td>\n",
       "      <td>5848.848126</td>\n",
       "      <td>0.707736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     model target1 | AMAE target2 | AMAE  \\\n",
       "0                                    Média    6844.194194    6399.400572   \n",
       "1                        Média por Jogador    6414.210091    5524.186487   \n",
       "2                                  Mediana    6900.822698    6587.090997   \n",
       "3                      Mediana por Jogador    6833.982614     6005.49286   \n",
       "4                                    Naive     6773.84043    6205.150573   \n",
       "5                      Lasso | MultiOutput     5067.59576    3949.374541   \n",
       "6                      Ridge | MultiOutput    4895.420876    3919.150979   \n",
       "7                 ElasticNet | MultiOutput     5039.66974    3940.878062   \n",
       "8  GradientBoostingRegressor | MultiOutput    6181.200965    5375.246921   \n",
       "\n",
       "  target3 | AMAE target4 | AMAE average | AMAE average | MAE  \n",
       "0    7122.047829    6824.235173    5438.296362      1.604042  \n",
       "1    6761.347046      6119.3349    4964.078976      1.316354  \n",
       "2    7190.300457    6912.138701    5518.274249      1.018393  \n",
       "3    7149.275526    6419.210155    5281.781292      0.945302  \n",
       "4    7008.533742    6362.128265    5270.162311      1.158547  \n",
       "5    5768.626309    3629.895891    4603.873125      0.909959  \n",
       "6    5695.694745    3599.351708    4527.404577      0.925028  \n",
       "7    5750.295247    3620.259616    4587.775666      0.914881  \n",
       "8    6602.535582    5236.409038    5848.848126      0.707736  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusão e melhorias"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostrar o que tá melhor que a A1\n",
    "\n",
    "Talvez comentar do multioutput chainging aqui?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Output Chaining\n",
    "\n",
    "[note] adicionar aqui o teste falho de multi output chaining, explicar porque deu errado e mostrar que os resultados de um target não dependem dos demais. Além disso adicionar a correlação."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi Output Regressor e Modelos Finais"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
