{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Fundação Getúlio Vargas - RJ <br>\n",
    "> Escola de Matemática Aplicada (EMAp) <br>\n",
    "> Graduação em Ciência de Dados e Inteligência Artificial <br>\n",
    "> Alunos: Gianlucca Devigili e Maisa de O. Fraiz <br>\n",
    "# Projetos em Ciência de Dados - A2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introdução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esse trabalho tem como intuito melhorar os resultados obtidos na A1 da matéria de Projetos em Ciência de Dados, e, para isso, decidimos seguir a abordagem de otimizar os modelos já utilizados, ao invés de seguir testando novos.\n",
    "\n",
    "O primeiro passo pós-A1 foi a refatoração dos códigos, de modo a organizar e padronizar os notebooks, além de reorganizar o repositório. A estrutura atual do repositório é:\n",
    "\n",
    "```\n",
    "src/\n",
    "├── data/\n",
    "|   ├── processed-data/\n",
    "|   |   └── arquivos .pkl com os dados processados e prontos para serem usados nos modelos\n",
    "|   |   raw-data/\n",
    "|   |   └── arquivos .csv baixados do kaggle e o arquivo train.pkl que é a versão pickle do arquivo train.csv\n",
    "├── data-engineering/\n",
    "|   ├── pre-process-data.ipynb\n",
    "|   └── transform-data.ipynb\n",
    "├── EDA/\n",
    "|   └── EDA.ipynb\n",
    "├── models/\n",
    "|   ├── old_notebooks\n",
    "|   |   └── arquivos antigos usados na A1\n",
    "|   ├── chain-models.ipynb\n",
    "|   ├── data-preparation.py\n",
    "|   ├── metrics.ipynb\n",
    "|   ├── models.py\n",
    "|   ├── multitask-models.py\n",
    "└── └── template.ipynb\n",
    "```\n",
    "\n",
    "Contendo agora um pipeline de execução melhor definido, sendo necessária a execução do arquivo `pre-process-data.ipynb` para carregar os dados, renomear colunas e criar id's. Tambpem realizamos ajustes pontuais na tipagem de colunas de datas. \n",
    "\n",
    "Após isso, deve ser feita a execução do arquivo `transform-data.ipynb`, que realiza as devidas transformações nos dados, como criação de novas features, otimização de memória (a ser descrita abaixo) e o processo de _JOIN_ dos diversos datasets em um só. Esse arqueivo gera os .pkl (pickle) dos subconjuntos de dados, bem como o arquivo principal chamado `train.pkl`, fazendo com que tenhamos um dataset prontamente tratado para ser executado nos arquivos de modelos do diretório `models/`. \n",
    "\n",
    "Tal refatoração e separação de arquivos foi feita de modo a garantir que os dados utilizados pelos membros da dupla sempre estivessem na mesma versão e não houvessem problemas gerados por conta de diferenças nos datasets, algo que acabamos enfrentando no decorrer da A1.\n",
    "\n",
    "O principal avanço em termos de resultados obtivemos ao começar a treinar os modelos utilizando o [sklearn.multioutput.MultiOutputRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputRegressor.html). Obtivemos melhores resultados especialmente no modelo de Gradient Boosting (sklearn) que tinha uma MAE de 1.216814, e teve seu erro reduzido para 0.797927. Além disso, o seu tempo de execução diminuído em quase 1h.\n",
    "\n",
    "Por útlimo, foram adicionados mais dados e então realizada a seleção das novas features conforme sua importância, assim conseguindo obter MAEs menores, com a menor sendo a de 0.703 do Gradient Boosting.\n",
    "\n",
    "O notebook aqui apresentado une esses processos em um só arquivo, e, sendo assim, não é necessário acesso ao repositório completo para a execução."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instruções de Execução\n",
    "\n",
    "**IMPORTANTE:**\n",
    "\n",
    "> As versões das bibliotecas utilizadas se encontram no arquivo [`requirements.txt`](https://github.com/GDevigili/player-digital-engagement-forecasting/blob/main/requirements.txt). Versões mais recentes das bibliotecas podem gerar erros no código devido a funções e métodos que foram deprecados em atualizações que ocorreram no decorrer deste semestre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variáveis de configuração\n",
    "\n",
    "# Variável que define se o dataset será carregado de um .csv ou de um .pkl\n",
    "# Se você nunca tiver rodado esse notebook e não possuir os arquivos em .pkl, é necessário atualizar a variável para TRUE\n",
    "load_from_csv = False\n",
    "\n",
    "# Caminho para o dataset\n",
    "raw_data_path = '../data/raw-data/'\n",
    "dataset_path = raw_data_path + 'train_updated.csv'\n",
    "\n",
    "# Caminho onde serão salvos os dados processados\n",
    "processed_data_path = '../data/processed-data/'\n",
    "processed_dataset_path = processed_data_path + 'train.pkl' \n",
    "\n",
    "# Variável que define se o dataset será processado ou se será carregado de um .pkl\n",
    "\n",
    "# Se você já rodou o arquivo alguma vez e já possui o train.pkl atualizado e tratado,\n",
    "# alterar a variável para FALSE reduzirá o tempo de execução do notebook\n",
    "\n",
    "prepare_data = True\n",
    "\n",
    "# Varíavel que define se será realizado o feature selection ou vai carregar de um .pkl\n",
    "\n",
    "# Se você já possui o arquivo features.pkl, é recomendado manter essa variável como FALSE,\n",
    "# pois o feature_selection é realizado com Gradient Boosting\n",
    "\n",
    "feature_selection = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Inicial\n",
    "\n",
    "**IMPORTANTE:**\n",
    "\n",
    "> As funções que foram criada para o trabalho estão em um arquivo functions.py, que é importado aqui. Esse arquivo será disponibilizado junto com o trabalho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pickle as pkl\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from pandas.api.types import is_datetime64_any_dtype as is_datetime\n",
    "\n",
    "from functions import *\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "\n",
    "# disable warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variáveis globais\n",
    "\n",
    "PROCESSED_DATA_PATH = '../data/processed-data/'\n",
    "MODEL_PATH = '../models/trained-models/'\n",
    "\n",
    "TARGET_COLS = ['target1', 'target2', 'target3', 'target4']\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "TEST_SPLIT_DATE = '2021-04-30'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Funções auxiliares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De modo a manter o notebook mais limpo, optamos por mover as funções aqui utilizadas no arquivo `functions.py`. No arquivo estão as funções:\n",
    "+ `unpack_json` e `unpack_data`: funções provenientes do notebook getting started para o tratamento inicial dos dados.\n",
    "+ `create_id`: função que cria um id baseado na coluna de data e mais uma coluna a ser escolhida de modo a facilitar a operação de _JOIN_ dos diferentes subconjuntos de dados. Os ids utilizados foram `IdDtPlayer`, `IdDtTeam` e `IdDtGame`.\n",
    "+ `reduce_mem_usage`: função que modifica o data type das colunas do dataframe para reduzir o uso de memória.\n",
    "+ `sort_df`: organiza (sort) o dataframe com base no argumento.\n",
    "+ `shift_targets`: realiza o shift dos targets.\n",
    "+ `train_test_split`: realiza a divisão do dataset em train, test e validation.\n",
    "+ `x_y_split`: realiza a divisão do dataset em dois sets x e y.\n",
    "+ `naive`: modelo naive utilizando shift 1.\n",
    "+ `MeanModel`: modelo mean.\n",
    "+ `evaluate_mae`: calcula o MAE para cada target, além da média dos MAE.\n",
    "+ `MAE`: define o MAE (função utilizada para calcular a métrica AMAE).\n",
    "+ `AMAE`: calcula a métrica AMAE (explicada na seção \"métricas\" do trabalho) dado y_pred e y_obs.\n",
    "+ `evaluate_amae`: calcula o AMAE para cada target, além da média dos AMAE.\n",
    "+ `fit_predict_targets`: realiza o fit do modelo e a predição dos targets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Carga e Tratamento de Dados\n",
    "\n",
    "O principal problema tratado nesta parte do trabalho foi o grande volume dos dados, que dificultava a execução do trabalho por questões computacionais como limitação de RAM e processamento, além de atrasar o desenvolvimento do mesmo. \n",
    "\n",
    "A redução foi feita transformando as tipagens dos dados em tipos mais simples, por exemplo salvando as variáveis float64 em variáveis float16. Tal redução conseguiu ao todo diminuir o dataset total de 2134.42 MB para 960.62 MB, redução de 55.0%.\n",
    "\n",
    "Além disso, foram adicionados dois novos datasets ao conjunto de treino, aumentando a quantidade de features, estes sendo os datasets de _Team Box Scores_ e _Games_. As colunas foram selecionadas manualmente e renomeadas seguindo os padrões pré-definidos pela equipe.\n",
    "\n",
    "Parte do tratamento também consistiu em transformar todas as features de Cd e Flg (as features que envolviam algum código, como tipo de jogo ou período do dia, e features de flag, que indicavam algum valor booleano) em _dummies_. Assim, features categóricas com _N_ distintas categorias viraram _N_ features booleanas distintas, indicando a presença ou não daquele valor. Em casos de NaN, todos as features dummies eram zeradas. Esta modificação foi realizada de modo a conseguir considerar tais valores em modelos lineares que não suportam valores categóricos.\n",
    "\n",
    "Outro ponto importante do tratamento dos dados foi a definição de regra para tratamento de valores nulos com a substituição dos mesmos por 0. A ocorrência de valores nulos era baixa na maioria das colunas, porém aumentava drasticamente após a junção de datasets - vez que dados de Box Scores se referem aos dados dos dias em que existem jogos. Acreditamos ser plausível colocar os dados como sendo 0, fazendo com que em dias sem jogos, jogadores/equipes tivessem um número 0 de \"vitórias\", \"home runs\" e afins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframes\n",
    "dataset_names = {\n",
    "    'Awards': 'awards.csv', \n",
    "    'Example': 'example_test.csv', \n",
    "    'Players': 'players.csv',\n",
    "    'Seasons': 'seasons.csv', \n",
    "    'Teams': 'teams.csv', \n",
    "    'Train': 'train_updated.csv'\n",
    "}\n",
    "for key in dataset_names:\n",
    "    dataset_names[key] = raw_data_path + dataset_names[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregando o dataset de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2.23 s\n",
      "Wall time: 7.72 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if load_from_csv:\n",
    "    df_train = pd.read_csv(dataset_names['Train'])\n",
    "    pd.to_pickle(df_train, raw_data_path + 'train.pkl')\n",
    "else:\n",
    "    df_train = pd.read_pickle(raw_data_path + 'train.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if prepare_data:\n",
    "\n",
    "    # criação do dataset de targets\n",
    "\n",
    "    # unpack the data\n",
    "    Y = unpack_data(df_train, dfs = ['nextDayPlayerEngagement'])['nextDayPlayerEngagement']\n",
    "\n",
    "    # change datatypes\n",
    "    Y = Y.astype({name: np.float32 for name in [\"target1\", \"target2\", \"target3\", \"target4\"]})\n",
    "\n",
    "    # match target dates to feature dates and create date index\n",
    "    Y = Y.rename(columns={'engagementMetricsDate': 'date'})\n",
    "\n",
    "    # change datatypes\n",
    "    Y['date'] = pd.to_datetime(Y['date'])\n",
    "\n",
    "    # reset index\n",
    "    Y = Y.set_index('date').to_period('D')\n",
    "    Y.index = Y.index - 1\n",
    "    Y = Y.reset_index()\n",
    "\n",
    "    # rename and select columns\n",
    "    cols_Y = {\n",
    "        'date': 'Dt',\n",
    "        'playerId': 'IdPlayer',\n",
    "        'target1': 'target1',\n",
    "        'target2': 'target2',\n",
    "        'target3': 'target3',\n",
    "        'target4': 'target4'\n",
    "    }\n",
    "    Y = Y[list(cols_Y)]\n",
    "    Y.columns = list(cols_Y.values())\n",
    "    Y['Dt'] = Y['Dt'].astype('datetime64[ns]')\n",
    "    Y = create_id(Y, ['Dt', 'IdPlayer'], 'Player')\n",
    "\n",
    "    pd.to_pickle(Y, processed_data_path + 'targets.pkl')\n",
    "\n",
    "    del Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PlayerBoxScores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if prepare_data:\n",
    "    # load the data\n",
    "    df_playerBoxScores = unpack_data(df_train, dfs = ['playerBoxScores'])['playerBoxScores']\n",
    "\n",
    "    # Cria o dataset de jogos\n",
    "    cols = {\n",
    "        # columns related to other dimensions\n",
    "        'gamePk': 'IdGame',\n",
    "        'gameDate': 'DtGame',\n",
    "        'gameTimeUTC': 'DtGameUTC',\n",
    "        'playerId': 'IdPlayer',\n",
    "        'teamId': 'IdTeam',\n",
    "        'jerseyNum': 'NuJersey',\n",
    "        'positionCode': 'CdPosition',\n",
    "        # suggested column\n",
    "        'strikeOutsPitching': 'NuStrikeOutsPitching',\n",
    "    }  \n",
    "    # numeric columns\n",
    "    for numeric_col in list(df_playerBoxScores.columns[12:]):\n",
    "        # skip the columns that contains data about pitching due the amount of Nan values\n",
    "        if 'Pitching' not in numeric_col:\n",
    "            cols[numeric_col] = 'Nu' + numeric_col[0].upper() + numeric_col[1:] + '_Player'\n",
    "\n",
    "    df_playerBoxScores = df_playerBoxScores[list(cols)]\n",
    "    df_playerBoxScores.columns = list(cols.values())\n",
    "\n",
    "    # df_playerBoxScores['DtGame'] = df_playerBoxScores['DtGame'] + \" 00:00:00\"\n",
    "    df_playerBoxScores['DtGame'] = df_playerBoxScores['DtGame'].astype('datetime64[ns]')\n",
    "    df_playerBoxScores['DtGameUTC'] = df_playerBoxScores['DtGameUTC'].astype('datetime64[ns]')\n",
    "    df_playerBoxScores = create_id(df_playerBoxScores, ['DtGame', 'IdPlayer'], 'Player')\n",
    "    df_playerBoxScores = create_id(df_playerBoxScores, ['DtGame', 'IdTeam'], 'Team')\n",
    "    df_playerBoxScores = create_id(df_playerBoxScores, ['DtGame', 'IdGame'], 'Game')\n",
    "\n",
    "    # Salva o dataset\n",
    "    pd.to_pickle(df_playerBoxScores, processed_data_path + 'playerBoxScores.pkl')\n",
    "\n",
    "    del df_playerBoxScores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Team Box Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if prepare_data:\n",
    "    df_tbs = unpack_data(df_train, dfs = ['teamBoxScores'])['teamBoxScores']\n",
    "\n",
    "    cols = {\n",
    "        'gameDate': 'DtGame',\n",
    "        'teamId': 'IdTeam',\n",
    "        'home': 'FlgHome',\n",
    "        'gamePk': 'IdGame',\n",
    "    }\n",
    "\n",
    "    for numeric_col in list(df_tbs.columns[4:]):\n",
    "        cols[numeric_col] = 'Nu' + numeric_col[0].upper() + numeric_col[1:] + '_Team'\n",
    "\n",
    "    df_tbs = df_tbs[list(cols)]\n",
    "    df_tbs.columns = list(cols.values())\n",
    "\n",
    "    df_tbs['DtGame'] = df_tbs['DtGame'].astype('datetime64[ns]')\n",
    "    df_tbs = create_id(df_tbs, ['DtGame', 'IdTeam'], 'Team')\n",
    "    df_tbs = create_id(df_tbs, ['DtGame', 'IdGame'], 'Game')\n",
    "    df_tbs['FlgHome'] = df_tbs['FlgHome'].astype('bool')\n",
    "\n",
    "    pd.to_pickle(df_tbs, processed_data_path + 'teamBoxScores.pkl')\n",
    "\n",
    "    del df_tbs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if prepare_data:\n",
    "    df_games = unpack_data(df_train, dfs = ['games'])['games']\n",
    "\n",
    "    cols = {\n",
    "        'gamePk': 'IdGame',\n",
    "        'gameType': 'CdGameType',\n",
    "        'season': 'NuSeason',\n",
    "        'gameDate': 'DtGame',\n",
    "        'codedGameState': 'CdGameState',\n",
    "        'detailedGameState': 'CdGameState',\n",
    "        'isTie': 'FlgTie',\n",
    "        'gameNumber': 'NuGame',\n",
    "        'doubleHeader': 'CdDoubleHeader',\n",
    "        'dayNight': 'CdDayNight',\n",
    "        'scheduledInnings': 'NuScheduledInnings',\n",
    "        'gamesInSeries': 'NuGamesInSeries',\n",
    "        'homeId': 'IdHomeTeam',\n",
    "        'homeWins': 'NuWinsHomeTeam',\n",
    "        'homeLosses': 'NuLossesHomeTeam',\n",
    "        'homeWinPct': 'NuWinPctHomeTeam',\n",
    "        'homeWinner': 'FlgWinnerHomeTeam',\n",
    "        'homeScore': 'NuScoreHomeTeam',\n",
    "        'awayId': 'IdAwayTeam',\n",
    "        'awayWins': 'NuWinsAwayTeam',\n",
    "        'awayLosses': 'NuLossesAwayTeam',\n",
    "        'awayWinPct': 'NuWinPctAwayTeam',\n",
    "        'awayWinner': 'FlgWinnerAwayTeam',\n",
    "        'awayScore': 'NuScoreAwayTeam',\n",
    "    }\n",
    "\n",
    "    df_games = df_games[list(cols)]\n",
    "    df_games.columns = list(cols.values())\n",
    "\n",
    "    df_games['DtGame'] = df_games['DtGame'].astype('datetime64[ns]')\n",
    "    df_games = create_id(df_games, ['DtGame', 'IdGame'], 'Game')\n",
    "\n",
    "    pd.to_pickle(df_games, processed_data_path + 'games.pkl')\n",
    "\n",
    "    del df_games"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamento dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carregando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if prepare_data:\n",
    "    df_targets = pd.read_pickle(processed_data_path + 'targets.pkl')\n",
    "    df_pbs = pd.read_pickle(processed_data_path + 'playerBoxScores.pkl')\n",
    "    df_tbs = pd.read_pickle(processed_data_path + 'teamBoxScores.pkl')\n",
    "    df_g = pd.read_pickle(processed_data_path + 'games.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reduzindo memória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if prepare_data:\n",
    "    df_pbs = reduce_mem_usage(df_pbs);\n",
    "    df_tbs = reduce_mem_usage(df_tbs);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shifting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if prepare_data:\n",
    "    sort_df(df_targets)\n",
    "    df_train = shift_targets(df_targets, shift_vals=[1, 2, 3, 4, 5, 6, 7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features de Datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if prepare_data:\n",
    "    # Transform the datetime col into new features\n",
    "    df_train['DtYear'] = df_train['Dt'].dt.year\n",
    "    df_train['DtMonth'] = df_train['Dt'].dt.month\n",
    "    df_train['DtDay'] = df_train['Dt'].dt.day\n",
    "    df_train['DtDayOfWeek'] = df_train['Dt'].dt.dayofweek\n",
    "    df_train['DtDayOfYear'] = df_train['Dt'].dt.dayofyear\n",
    "    df_train['DtQuarter'] = df_train['Dt'].dt.quarter\n",
    "    # get the hour and minute from the PBS\n",
    "    df_pbs['DtHour'] = df_pbs['DtGameUTC'].dt.hour\n",
    "    df_pbs['DtMinute'] = df_pbs['DtGameUTC'].dt.minute\n",
    "    df_pbs['DtHour'][df_pbs['DtHour'] == 0] = 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unindo os datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Player Box Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if prepare_data:\n",
    "    df_train = pd.merge(df_train, df_pbs, on=['IdDtPlayer'], how='left')\n",
    "\n",
    "# Substitui os valores Nan das seguintes colunas por 0\n",
    "    f = [c for c in df_train.columns if c not in ['IdGame', 'DtGame', 'DtGameUTC',\n",
    "    'IdPlayer_y','IdTeam','NuJersey','CdPosition', 'target1_shift_1', 'target2_shift_1',\n",
    "    'target3_shift_1','target1_shift_2', 'target3_shift_2', 'target4_shift_2',\n",
    "    'target1_shift_3','target2_shift_3','target3_shift_3','target4_shift_3',\n",
    "    'target1_shift_4','target2_shift_4','target3_shift_4','target4_shift_4',\n",
    "    'target1_shift_5','target2_shift_5','target3_shift_5','target4_shift_5',\n",
    "    'target1_shift_6','target2_shift_6','target3_shift_6','target4_shift_6',\n",
    "    'target1_shift_7','target2_shift_7','target3_shift_7','target4_shift_7']]\n",
    "\n",
    "    df_train[f] = df_train[f].fillna(0)        \n",
    "\n",
    "    # Remove os na das seguintes colunas\n",
    "    df_train = df_train.dropna(subset=[             \n",
    "        'target1_shift_1', 'target2_shift_1', 'target3_shift_1', 'target1_shift_2',\n",
    "        'target3_shift_2', 'target4_shift_2', 'target1_shift_3', 'target2_shift_3',\n",
    "        'target3_shift_3', 'target4_shift_3', 'target1_shift_4', 'target2_shift_4',\n",
    "        'target3_shift_4', 'target4_shift_4', 'target1_shift_5', 'target3_shift_5',\n",
    "        'target4_shift_5', 'target1_shift_6', 'target2_shift_6', 'target3_shift_6',\n",
    "        'target4_shift_6', 'target1_shift_7', 'target2_shift_7', 'target3_shift_7',\n",
    "        'target4_shift_7'])\n",
    "\n",
    "    df_train.rename(columns={'IdPlayer_x': 'IdPlayer'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Team Box Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if prepare_data:\n",
    "    df_train = pd.merge(df_train, df_tbs, on = ['IdDtTeam'], how = 'left')\n",
    "\n",
    "    # Substitui os valores Nan das seguintes colunas por 0\n",
    "    f = [\n",
    "        'FlgHome','NuFlyOuts_Team', 'NuGroundOuts_Team', 'NuRunsScored_Team',\n",
    "        'NuDoubles_Team', 'NuTriples_Team', 'NuHomeRuns_Team', 'NuStrikeOuts_Team',\n",
    "        'NuBaseOnBalls_Team', 'NuIntentionalWalks_Team', 'NuHits_Team', 'NuHitByPitch_Team',\n",
    "        'NuAtBats_Team', 'NuCaughtStealing_Team', 'NuStolenBases_Team', 'NuGroundIntoDoublePlay_Team',\n",
    "        'NuGroundIntoTriplePlay_Team', 'NuPlateAppearances_Team', 'NuTotalBases_Team', 'NuRbi_Team',\n",
    "        'NuLeftOnBase_Team', 'NuSacBunts_Team', 'NuSacFlies_Team', 'NuCatchersInterference_Team',\n",
    "        'NuPickoffs_Team', 'NuAirOutsPitching_Team', 'NuGroundOutsPitching_Team', 'NuRunsPitching_Team',\n",
    "        'NuDoublesPitching_Team', 'NuTriplesPitching_Team', 'NuHomeRunsPitching_Team',\n",
    "        'NuStrikeOutsPitching_Team', 'NuBaseOnBallsPitching_Team', 'NuIntentionalWalksPitching_Team',\n",
    "        'NuHitsPitching_Team', 'NuHitByPitchPitching_Team', 'NuAtBatsPitching_Team',\n",
    "        'NuCaughtStealingPitching_Team', 'NuStolenBasesPitching_Team', 'NuInningsPitched_Team',\n",
    "        'NuEarnedRuns_Team', 'NuBattersFaced_Team', 'NuOutsPitching_Team', 'NuHitBatsmen_Team',\n",
    "        'NuBalks_Team', 'NuWildPitches_Team', 'NuPickoffsPitching_Team', 'NuRbiPitching_Team',\n",
    "        'NuInheritedRunners_Team', 'NuInheritedRunnersScored_Team', 'NuCatchersInterferencePitching_Team',\n",
    "        'NuSacBuntsPitching_Team', 'NuSacFliesPitching_Team'\n",
    "    ]\n",
    "\n",
    "    df_train[f] = df_train[f].fillna(0)        \n",
    "\n",
    "    df_train = df_train.rename(columns={'IdDtGame_y': 'IdDtGame'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if prepare_data:\n",
    "    df_train = pd.merge(df_train, df_g, on = ['IdDtGame'], how = 'left')\n",
    "\n",
    "    f = [\n",
    "        'NuSeason', 'NuGame',\n",
    "        'NuScheduledInnings', 'NuGamesInSeries', 'NuWinsHomeTeam',\n",
    "        'NuLossesHomeTeam', 'NuWinPctHomeTeam', 'NuScoreHomeTeam',\n",
    "        'NuWinsAwayTeam', 'NuLossesAwayTeam', 'NuWinPctAwayTeam', 'NuScoreAwayTeam'\n",
    "    ]\n",
    "    df_train[f] = df_train[f].fillna(0)        \n",
    "\n",
    "    df_train = pd.get_dummies(df_train, columns = ['CdPosition', \"CdGameType\", \"CdGameState\", \"CdDoubleHeader\", \n",
    "                                        \"CdDayNight\", \"FlgWinnerHomeTeam\", \"FlgWinnerAwayTeam\",'FlgTie', 'FlgHome'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if prepare_data:\n",
    "    df_train.drop([\n",
    "    'IdGame_x', 'DtGame_x', 'DtGameUTC', 'IdPlayer_y',\n",
    "    'IdTeam_x', 'IdTeam_y', \"NuGameTimeUTC_Team\", \"IdDtGame\", \"DtGame\", \"IdGame\",\n",
    "    'IdGame_y', 'NuJersey', \"DtGame_y\", \"IdHomeTeam\", \"IdAwayTeam\", \"IdDtPlayer\",\n",
    "    \"IdDtTeam\", \"IdDtGame_x\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salvando datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if prepare_data:\n",
    "    df_train_reduced = reduce_mem_usage(df_train[df_train.columns.difference(['target1', 'target2', 'target3', 'target4'])]) \n",
    "    df_train_reduced[TARGET_COLS]= df_train[TARGET_COLS]\n",
    "\n",
    "    df_train = df_train_reduced.copy()\n",
    "\n",
    "    del df_train_reduced\n",
    "\n",
    "    df_targets.to_pickle(processed_data_path + 'targets.pkl')\n",
    "    df_pbs.to_pickle(processed_data_path + 'playerBoxScores.pkl')\n",
    "    df_tbs.to_pickle(processed_data_path + 'teamBoxScores.pkl')\n",
    "    df_g.to_pickle(processed_data_path + 'games.pkl')\n",
    "\n",
    "    df_train.to_pickle(processed_data_path + 'train.pkl')\n",
    "    \n",
    "    del df_train, df_pbs, df_tbs, df_g, df_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modelos\n",
    "\n",
    "Os modelos finais foram treinados utilizando dados de 4 subconjuntos presentes do arquivo `train.csv`:\n",
    "\n",
    "- Targets (dados a serem previstos)\n",
    "- PlayerBoxScores (dados de jogador em determinado jogo)\n",
    "- TeamBoxScores (dados de equipe em determinado jogo)\n",
    "- Games (pontuação de jogo e vencedores/perdedores)\n",
    "\n",
    "O dataset atualizado contava com 195 colunas, sendo 191 de features que foram utilizadas para treinar os modelos. Após isso foi realizada a seleção de features e os modelos foram retreinados com apenas 32 colunas, apresentando melhores resultados conforme será discutido posteriormente.\n",
    "\n",
    "### Modelagens testadas\n",
    "\n",
    "### Métricas alternativas\n",
    "\n",
    "Para a A1, mencionamos que o MAE provavelmente não era a melhor métrica a ser utilizada para nossos dados, mas não apresentamos uma alternativa. Para esse trabalho, então, decidimos testar as seguintes métricas alternativas:\n",
    "\n",
    "+ `R2`: testamos essa métrica por ser independente de contexto, e ter um \"range\" entre 0 e 1, sendo melhor de comparar resultados.\n",
    "+ `MSE (Mean Squared Error)`: sendo uma variação do MAE, testamos pela sua sensibilidade a outliers.\n",
    "+ `MSLE (Mean Squared Log Error)`: testamos essa métrica pois ela penaliza subestimar o target mais do que superestimá-lo, e queríamos ver como esse comportamento modificaria nossos resultados.\n",
    "+ `Max`: testamos essa métrica pois ela retorna o maior erro que o modelo realizou. Apesar de ser interessante descobrir qual modelo tem o menor erro máximo, ela não retorna uma estimativa de qualidade geral do modelo, e sendo assim não é muito útil.\n",
    "+ `AMAE`: métrica proposta pelo Grupo 1, ela funciona da seguinte maneira: para cara limite $\\alpha_i$ entre 0 e 100 em uma coleção finita ${\\alpha_1, ..., \\alpha_n}$, é computado o MAE $m_i$ para amostras com engajamento maior que ou igual a $\\alpha_i$ para algum dos quatro targets. Com o conjunto de pares $(alpha_i, m_i)$, calculamos uma curva no plano por interpolação linear - o AMAE é a área sob essa curva. O resultado obtido é inversamente proporcional à efetividade do modelo em prever diferentes níveis de popularidade.\n",
    "\n",
    "Como métrica final para o nosso trabalho, escolhemos a AMAE, pois acreditamos que ela é a mais adaptada para o que acreditamos ser o objetivo de nossos modelos (prever diferentes níveis de popularidade). Mesmo assim, em nossa tabela final, também manteremos o cálculo do MAE, de forma a poder comparar nossos resultados com os obtidos na A1.\n",
    "\n",
    "### Feature Selection\n",
    "\n",
    "A primeira tentativa de feature selection na A1 foi utilizando o modelo MultitaskLASSO, porém não obtivemos melhora nos resultados após a seleção feita e a MAE se manteve superior à 1.2. Para a A2, a metodologia para a seleção das features utilizadas foi a escolha de todas as features dos quatro modelos de Gradient Boosting treinados pelo MultiOutputRegressor que apresentassem uma importância maior que 0.5%, resultando num total de 32 features. Dessas, a maioria foram os lags dos targets e as restantes selecionadas foram CdDayNight_night, CdPosition_1.0, Dt, DtDayOfYear, NuHomeRuns_Player, NuInningsPitched_Player, NuRbi_Player, NuTotalBases_Player. \n",
    "\n",
    "A conclusão que pode ser tirada com isso é que o período do dia, homeruns e inning pitches são as jogadas mais \"importantes\" para os target, além do número de Bases que o jogador fez e o índice \"Runs Batted In\", que indica a contribuição do jogador para marcar as bases. O único dado referente ao jogo que foi selecionado é se o mesmo é de noite, além de uma grande contribuição de se o jogador joga na posição de Pitcher. \n",
    "\n",
    "Além disso, a variável Dt (data) foi obviamente uma das mais importantes, por se tratar de uma série temporal. A decomposição de dia do ano foi relevante ao mostrar que a época do ano influencia no resultado final (provavelmente finais de temporada e períodos que não coincidem com momentos decisivos de outros esportes). Uma coisa interessante de se ressaltar é que alguns lags foram selecionados como features importantes para a previsão de outros targets (por exemplo o lag 1 do target 2 influenciando no target 4).\n",
    "\n",
    "Após selecionadas apenas as features mais importantes de acordo com o critério acima, os modelos foram rodados novamente agora com o dataset reduzido. Tal redução foi capaz de fazer com que o erro do GradientBoosting fosse de 1.0 para 0.7."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carrega os Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_pickle(processed_dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparação e Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if feature_selection:\n",
    "    \n",
    "    df_train = df_train.drop(columns = ['IdPlayer'])\n",
    "\n",
    "    train, test, val = train_test_split(df_train)\n",
    "\n",
    "    train['Dt'] = pd.to_numeric(pd.to_datetime(train['Dt']))\n",
    "    test['Dt']= pd.to_numeric(pd.to_datetime(test['Dt']))\n",
    "    val['Dt'] = pd.to_numeric(pd.to_datetime(val['Dt']))\n",
    "\n",
    "    # defines the model and create the multioutput regressor\n",
    "    model = GradientBoostingRegressor(random_state=RANDOM_SEED, loss = 'absolute_error')\n",
    "    model_name = 'GradientBoostingRegressor | MultiOutput'\n",
    "    regressor = MultiOutputRegressor(model, n_jobs=-1)\n",
    "\n",
    "    # fit the model\n",
    "    regressor.fit(train.drop(columns=TARGET_COLS), train[TARGET_COLS])\n",
    "\n",
    "    # make predictions\n",
    "    y_pred = pd.DataFrame(regressor.predict(test.drop(columns=TARGET_COLS)), columns=TARGET_COLS)\n",
    "\n",
    "    for i in range(len(TARGET_COLS)):\n",
    "        plt.bar(range(len(regressor.estimators_[i].feature_importances_)), regressor.estimators_[i].feature_importances_)\n",
    "        plt.show()\n",
    "        for i in range(len(TARGET_COLS)):\n",
    "            plt.bar(range(len(regressor.estimators_[i].feature_importances_)), regressor.estimators_[i].feature_importances_)\n",
    "\n",
    "    selected_features = pd.array([])\n",
    "    for i in range(len(TARGET_COLS)):\n",
    "        features = np.where(regressor.estimators_[i].feature_importances_ >= 0.005)\n",
    "        selected_features = np.append(selected_features, train.drop(columns=TARGET_COLS).columns[features])\n",
    "        selected_features.extend(list(np.where(regressor.estimators_[i].feature_importances_ > 0.0001)))\n",
    "    np.where(regressor.estimators_[0].feature_importances_ > 0.0)\n",
    "    len(np.unique(selected_features))\n",
    "\n",
    "    with open('features.pkl', 'wb') as file:\n",
    "         pickle.dump(selected_features, file)\n",
    "    pickle.load(open('features.pkl', 'rb'))\n",
    "    \n",
    "else:\n",
    "    with open('features.pkl', 'rb') as f:\n",
    "        selected_features = pkl.load(f)\n",
    "    df_train = df_train[np.append(np.append(TARGET_COLS, selected_features), 'IdPlayer')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CdDayNight_night', 'CdPosition_1.0', 'Dt', 'DtDayOfYear',\n",
       "       'NuHomeRuns_Player', 'NuInningsPitched_Player', 'NuRbi_Player',\n",
       "       'NuTotalBases_Player', 'target1_shift_1', 'target1_shift_2',\n",
       "       'target1_shift_3', 'target1_shift_4', 'target1_shift_5',\n",
       "       'target2_shift_1', 'target2_shift_3', 'target2_shift_4',\n",
       "       'target2_shift_5', 'target2_shift_6', 'target2_shift_7',\n",
       "       'target3_shift_1', 'target3_shift_2', 'target3_shift_3',\n",
       "       'target3_shift_4', 'target3_shift_5', 'target3_shift_7',\n",
       "       'target4_shift_1', 'target4_shift_2', 'target4_shift_3',\n",
       "       'target4_shift_4', 'target4_shift_5', 'target4_shift_6',\n",
       "       'target4_shift_7'], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.loc[:,~df_train.columns.duplicated()].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, val = train_test_split(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(columns = ['model', 'target1 | AMAE', 'target2 | AMAE', 'target3 | AMAE', 'target4 | AMAE', 'average | AMAE', 'average | MAE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 21s\n",
      "Wall time: 2min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# naive\n",
    "naive = train[[\"target1_shift_1\", \"target2_shift_1\", \"target3_shift_1\", \"target4_shift_1\", \"IdPlayer\"]].set_index('IdPlayer')\n",
    "naive.rename(columns={'target1_shift_1': 'target1', 'target2_shift_1': 'target2', 'target3_shift_1': 'target3',\n",
    "                     'target4_shift_1': 'target4'}, inplace=True)\n",
    "# media\n",
    "media = train[TARGET_COLS].mean()\n",
    "media_por_jogador = train.groupby('IdPlayer')[TARGET_COLS].mean()\n",
    "\n",
    "# mediana\n",
    "mediana = train[TARGET_COLS].median()\n",
    "mediana_por_jogador = train.groupby('IdPlayer')[TARGET_COLS].median()\n",
    "\n",
    "summary = pd.DataFrame()\n",
    "temp = pd.DataFrame()\n",
    "\n",
    "for target in TARGET_COLS:\n",
    "    \n",
    "    y_true = test[target]\n",
    "   \n",
    "    mediapj_pred = test['IdPlayer'].map(media_por_jogador[target].to_dict())\n",
    "    medianapj_pred = test['IdPlayer'].map(mediana_por_jogador[target].to_dict())\n",
    "    naive_pred = test['IdPlayer'].map(naive[target].to_dict())\n",
    "  \n",
    "    mediana_pred = [mediana[target] for i in test.index]\n",
    "    media_pred = [media[target] for i in test.index]\n",
    "    \n",
    "\n",
    "    temp.loc['Média',target]  = mean_absolute_error(y_true,media_pred)\n",
    "    temp.loc['Média por Jogador',target]  = mean_absolute_error(y_true,mediapj_pred)\n",
    "    temp.loc['Mediana',target]  = mean_absolute_error(y_true,mediana_pred)\n",
    "    temp.loc['Mediana por Jogador',target]  = mean_absolute_error(y_true,medianapj_pred)\n",
    "    temp.loc['Naive',target]  = mean_absolute_error(y_true,naive_pred)\n",
    "    summary.loc['Média',target + \" | AMAE\"]  =  AMAE(y_true,media_pred,show = False)\n",
    "    summary.loc['Média por Jogador',target + \" | AMAE\"]  =  AMAE(y_true,mediapj_pred,show = False)\n",
    "    summary.loc['Mediana',target + \" | AMAE\"]  =  AMAE(y_true,mediana_pred,show = False)\n",
    "    summary.loc['Mediana por Jogador',target + \" | AMAE\"]  =  AMAE(y_true,medianapj_pred,show = False)\n",
    "    summary.loc['Naive',target + \" | AMAE\"]  =  AMAE(y_true,naive_pred,show = False)\n",
    "    \n",
    "summary['average | MAE'] = temp.mean(axis=1)\n",
    "summary['average | AMAE'] = summary.mean(axis=1)\n",
    "\n",
    "summary = summary.reset_index()\n",
    "summary = summary.rename(columns = {\"index\": \"model\"})\n",
    "\n",
    "df_results = df_results.append(summary, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelos Lineares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(columns = ['IdPlayer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Dt'] = pd.to_numeric(pd.to_datetime(train['Dt']))\n",
    "test['Dt']= pd.to_numeric(pd.to_datetime(test['Dt']))\n",
    "val['Dt'] = pd.to_numeric(pd.to_datetime(val['Dt']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3.22 s\n",
      "Wall time: 10min 16s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>target1 | AMAE</th>\n",
       "      <th>target2 | AMAE</th>\n",
       "      <th>target3 | AMAE</th>\n",
       "      <th>target4 | AMAE</th>\n",
       "      <th>average | AMAE</th>\n",
       "      <th>average | MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lasso | MultiOutput</td>\n",
       "      <td>5067.59576</td>\n",
       "      <td>3949.374541</td>\n",
       "      <td>5768.626309</td>\n",
       "      <td>3629.895891</td>\n",
       "      <td>4603.873125</td>\n",
       "      <td>0.909959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  target1 | AMAE  target2 | AMAE  target3 | AMAE  \\\n",
       "5  Lasso | MultiOutput      5067.59576     3949.374541     5768.626309   \n",
       "\n",
       "   target4 | AMAE  average | AMAE  average | MAE  \n",
       "5     3629.895891     4603.873125       0.909959  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# defines the model and create the multioutput regressor\n",
    "model = Lasso(alpha=0.1, random_state=RANDOM_SEED)\n",
    "model_name = 'Lasso | MultiOutput'\n",
    "regressor = MultiOutputRegressor(model, n_jobs=-1)\n",
    "\n",
    "# fit the model\n",
    "regressor.fit(train.drop(columns=TARGET_COLS), train[TARGET_COLS])\n",
    "\n",
    "# make predictions\n",
    "y_pred = pd.DataFrame(regressor.predict(test.drop(columns=TARGET_COLS)), columns=TARGET_COLS)\n",
    "\n",
    "# evaluate the model\n",
    "mae = evaluate_mae(test[TARGET_COLS], y_pred)\n",
    "amae = evaluate_amae(test[TARGET_COLS], y_pred)\n",
    "result_dict = {**amae, **{f'average | MAE': mae['average | MAE']}}\n",
    "\n",
    "# save the results\n",
    "df_results = df_results.append({'model': model_name, **result_dict}, ignore_index=True)\n",
    "df_results[df_results['model'] == model_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3.34 s\n",
      "Wall time: 8.29 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>target1 | AMAE</th>\n",
       "      <th>target2 | AMAE</th>\n",
       "      <th>target3 | AMAE</th>\n",
       "      <th>target4 | AMAE</th>\n",
       "      <th>average | AMAE</th>\n",
       "      <th>average | MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ridge | MultiOutput</td>\n",
       "      <td>4895.420876</td>\n",
       "      <td>3919.150979</td>\n",
       "      <td>5695.694745</td>\n",
       "      <td>3599.351708</td>\n",
       "      <td>4527.404577</td>\n",
       "      <td>0.925028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  target1 | AMAE  target2 | AMAE  target3 | AMAE  \\\n",
       "6  Ridge | MultiOutput     4895.420876     3919.150979     5695.694745   \n",
       "\n",
       "   target4 | AMAE  average | AMAE  average | MAE  \n",
       "6     3599.351708     4527.404577       0.925028  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# defines the model and create the multioutput regressor\n",
    "model = Ridge(alpha=0.1, random_state=RANDOM_SEED)\n",
    "model_name = 'Ridge | MultiOutput'\n",
    "regressor = MultiOutputRegressor(model, n_jobs=-1)\n",
    "\n",
    "# fit the model\n",
    "regressor.fit(train.drop(columns=TARGET_COLS), train[TARGET_COLS])\n",
    "\n",
    "# make predictions\n",
    "y_pred = pd.DataFrame(regressor.predict(test.drop(columns=TARGET_COLS)), columns=TARGET_COLS)\n",
    "\n",
    "# evaluate the model\n",
    "mae = evaluate_mae(test[TARGET_COLS], y_pred)\n",
    "amae = evaluate_amae(test[TARGET_COLS], y_pred)\n",
    "result_dict = {**amae, **{f'average | MAE': mae['average | MAE']}}\n",
    "\n",
    "# save the results\n",
    "df_results = df_results.append({'model': model_name, **result_dict}, ignore_index=True)\n",
    "df_results[df_results['model'] == model_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3.94 s\n",
      "Wall time: 7min 20s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>target1 | AMAE</th>\n",
       "      <th>target2 | AMAE</th>\n",
       "      <th>target3 | AMAE</th>\n",
       "      <th>target4 | AMAE</th>\n",
       "      <th>average | AMAE</th>\n",
       "      <th>average | MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ElasticNet | MultiOutput</td>\n",
       "      <td>5039.66974</td>\n",
       "      <td>3940.878062</td>\n",
       "      <td>5750.295247</td>\n",
       "      <td>3620.259616</td>\n",
       "      <td>4587.775666</td>\n",
       "      <td>0.914881</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      model  target1 | AMAE  target2 | AMAE  target3 | AMAE  \\\n",
       "7  ElasticNet | MultiOutput      5039.66974     3940.878062     5750.295247   \n",
       "\n",
       "   target4 | AMAE  average | AMAE  average | MAE  \n",
       "7     3620.259616     4587.775666       0.914881  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "# defines the model and create the multioutput regressor\n",
    "model = ElasticNet(alpha=0.1, random_state=RANDOM_SEED)\n",
    "model_name = 'ElasticNet | MultiOutput'\n",
    "regressor = MultiOutputRegressor(model, n_jobs=-1)\n",
    "\n",
    "# fit the model\n",
    "regressor.fit(train.drop(columns=TARGET_COLS), train[TARGET_COLS])\n",
    "\n",
    "# make predictions\n",
    "y_pred = pd.DataFrame(regressor.predict(test.drop(columns=TARGET_COLS)), columns=TARGET_COLS)\n",
    "\n",
    "\n",
    "# evaluate the model\n",
    "mae = evaluate_mae(test[TARGET_COLS], y_pred)\n",
    "amae = evaluate_amae(test[TARGET_COLS], y_pred)\n",
    "result_dict = {**amae, **{f'average | MAE': mae['average | MAE']}}\n",
    "\n",
    "# save the results\n",
    "df_results = df_results.append({'model': model_name, **result_dict}, ignore_index=True)\n",
    "df_results[df_results['model'] == model_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# defines the model and create the multioutput regressor\n",
    "model = GradientBoostingRegressor(random_state=RANDOM_SEED, loss = 'absolute_error')\n",
    "model_name = 'GradientBoostingRegressor | MultiOutput'\n",
    "regressor = MultiOutputRegressor(model, n_jobs=-1)\n",
    "\n",
    "# fit the model\n",
    "regressor.fit(train.drop(columns=TARGET_COLS), train[TARGET_COLS])\n",
    "\n",
    "# make predictions\n",
    "y_pred = pd.DataFrame(regressor.predict(test.drop(columns=TARGET_COLS)), columns=TARGET_COLS)\n",
    "\n",
    "\n",
    "# evaluate the model\n",
    "mae = evaluate_mae(test[TARGET_COLS], y_pred)\n",
    "amae = evaluate_amae(test[TARGET_COLS], y_pred)\n",
    "result_dict = {**amae, **{f'average | MAE': mae['average | MAE']}}\n",
    "\n",
    "# save the results\n",
    "df_results = df_results.append({'model': model_name, **result_dict}, ignore_index=True)\n",
    "df_results[df_results['model'] == model_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Resultados e Conclusões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>target1 | AMAE</th>\n",
       "      <th>target2 | AMAE</th>\n",
       "      <th>target3 | AMAE</th>\n",
       "      <th>target4 | AMAE</th>\n",
       "      <th>average | AMAE</th>\n",
       "      <th>average | MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Média</td>\n",
       "      <td>6844.194194</td>\n",
       "      <td>6399.400572</td>\n",
       "      <td>7122.047829</td>\n",
       "      <td>6824.235173</td>\n",
       "      <td>5438.296362</td>\n",
       "      <td>1.604042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Média por Jogador</td>\n",
       "      <td>6414.210091</td>\n",
       "      <td>5524.186487</td>\n",
       "      <td>6761.347046</td>\n",
       "      <td>6119.3349</td>\n",
       "      <td>4964.078976</td>\n",
       "      <td>1.316354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mediana</td>\n",
       "      <td>6900.822698</td>\n",
       "      <td>6587.090997</td>\n",
       "      <td>7190.300457</td>\n",
       "      <td>6912.138701</td>\n",
       "      <td>5518.274249</td>\n",
       "      <td>1.018393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mediana por Jogador</td>\n",
       "      <td>6833.982614</td>\n",
       "      <td>6005.49286</td>\n",
       "      <td>7149.275526</td>\n",
       "      <td>6419.210155</td>\n",
       "      <td>5281.781292</td>\n",
       "      <td>0.945302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Naive</td>\n",
       "      <td>6773.84043</td>\n",
       "      <td>6205.150573</td>\n",
       "      <td>7008.533742</td>\n",
       "      <td>6362.128265</td>\n",
       "      <td>5270.162311</td>\n",
       "      <td>1.158547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lasso | MultiOutput</td>\n",
       "      <td>5067.59576</td>\n",
       "      <td>3949.374541</td>\n",
       "      <td>5768.626309</td>\n",
       "      <td>3629.895891</td>\n",
       "      <td>4603.873125</td>\n",
       "      <td>0.909959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ridge | MultiOutput</td>\n",
       "      <td>4895.420876</td>\n",
       "      <td>3919.150979</td>\n",
       "      <td>5695.694745</td>\n",
       "      <td>3599.351708</td>\n",
       "      <td>4527.404577</td>\n",
       "      <td>0.925028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ElasticNet | MultiOutput</td>\n",
       "      <td>5039.66974</td>\n",
       "      <td>3940.878062</td>\n",
       "      <td>5750.295247</td>\n",
       "      <td>3620.259616</td>\n",
       "      <td>4587.775666</td>\n",
       "      <td>0.914881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GradientBoostingRegressor | MultiOutput</td>\n",
       "      <td>6181.200965</td>\n",
       "      <td>5375.246921</td>\n",
       "      <td>6602.535582</td>\n",
       "      <td>5236.409038</td>\n",
       "      <td>5848.848126</td>\n",
       "      <td>0.707736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     model target1 | AMAE target2 | AMAE  \\\n",
       "0                                    Média    6844.194194    6399.400572   \n",
       "1                        Média por Jogador    6414.210091    5524.186487   \n",
       "2                                  Mediana    6900.822698    6587.090997   \n",
       "3                      Mediana por Jogador    6833.982614     6005.49286   \n",
       "4                                    Naive     6773.84043    6205.150573   \n",
       "5                      Lasso | MultiOutput     5067.59576    3949.374541   \n",
       "6                      Ridge | MultiOutput    4895.420876    3919.150979   \n",
       "7                 ElasticNet | MultiOutput     5039.66974    3940.878062   \n",
       "8  GradientBoostingRegressor | MultiOutput    6181.200965    5375.246921   \n",
       "\n",
       "  target3 | AMAE target4 | AMAE average | AMAE average | MAE  \n",
       "0    7122.047829    6824.235173    5438.296362      1.604042  \n",
       "1    6761.347046      6119.3349    4964.078976      1.316354  \n",
       "2    7190.300457    6912.138701    5518.274249      1.018393  \n",
       "3    7149.275526    6419.210155    5281.781292      0.945302  \n",
       "4    7008.533742    6362.128265    5270.162311      1.158547  \n",
       "5    5768.626309    3629.895891    4603.873125      0.909959  \n",
       "6    5695.694745    3599.351708    4527.404577      0.925028  \n",
       "7    5750.295247    3620.259616    4587.775666      0.914881  \n",
       "8    6602.535582    5236.409038    5848.848126      0.707736  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostrar o que tá melhor que a A1\n",
    "\n",
    "Talvez comentar do multioutput chainging aqui?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Output Chaining\n",
    "\n",
    "[note] adicionar aqui o teste falho de multi output chaining, explicar porque deu errado e mostrar que os resultados de um target não dependem dos demais. Além disso adicionar a correlação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi Output Regressor e Modelos Finais"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
