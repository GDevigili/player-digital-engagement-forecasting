{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre Processing Datasets\n",
    "\n",
    "Notebook que irá conter o código para o pré-processamento dos dados, nenhum tratamento/higienização é realizado neste notebook, apenas a extração dos dados e a transformação dos dataset em `.pkl` serão realizadas aqui.\n",
    "\n",
    "os dados \"crus\" estão localizados em `/src/data/raw-data` e os dados tratados estão salvos em `/src/data/processed-data`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pickle as pkl\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Awards': '../data/raw-data/awards.csv',\n",
       " 'Example': '../data/raw-data/example_test.csv',\n",
       " 'Players': '../data/raw-data/players.csv',\n",
       " 'Seasons': '../data/raw-data/seasons.csv',\n",
       " 'Teams': '../data/raw-data/teams.csv',\n",
       " 'Train': '../data/raw-data/train_updated.csv'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Global Variables\n",
    "# file paths\n",
    "raw_data_path = '../data/raw-data/'\n",
    "processed_data_path = '../data/processed-data/'\n",
    "\n",
    "# dataframes\n",
    "dataset_names = {\n",
    "    'Awards': 'awards.csv', \n",
    "    'Example': 'example_test.csv', \n",
    "    'Players': 'players.csv',\n",
    "    'Seasons': 'seasons.csv', \n",
    "    'Teams': 'teams.csv', \n",
    "    'Train': 'train_updated.csv'\n",
    "}\n",
    "for key in dataset_names:\n",
    "  dataset_names[key] = raw_data_path + dataset_names[key]\n",
    "dataset_names"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxiliary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funções auxiliares para carregar os dados\n",
    "def unpack_json(json_str):\n",
    "    return pd.DataFrame() if pd.isna(json_str) else pd.read_json(json_str)\n",
    "\n",
    "def unpack_data(data, dfs=None, n_jobs=-1):\n",
    "    if dfs is not None:\n",
    "        data = data.loc[:, dfs]\n",
    "    unnested_dfs = {}\n",
    "    for name, column in data.iteritems():\n",
    "        daily_dfs = Parallel(n_jobs=n_jobs)(\n",
    "            delayed(unpack_json)(item) for date, item in column.iteritems())\n",
    "        df = pd.concat(daily_dfs)\n",
    "        unnested_dfs[name] = df\n",
    "    return unnested_dfs\n",
    "\n",
    "def create_id(df, id_cols, id_col_name, dt_col_name = 'Dt'):\n",
    "    df['Id' + dt_col_name + id_col_name] = df[id_cols].apply(lambda x: '_'.join(x.astype(str)), axis=1)\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Train Updated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 37.5 s\n",
      "Wall time: 1min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_train = pd.read_csv(dataset_names['Train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_pickle(df_train, raw_data_path + 'train.pkl')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2min 26s\n",
      "Wall time: 3min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# criação do dataset de targets\n",
    "# unpack the data\n",
    "Y = unpack_data(df_train, dfs = ['nextDayPlayerEngagement'])['nextDayPlayerEngagement']\n",
    "\n",
    "# change datatypes\n",
    "Y = Y.astype({name: np.float32 for name in [\"target1\", \"target2\", \"target3\", \"target4\"]})\n",
    "\n",
    "# match target dates to feature dates and create date index\n",
    "Y = Y.rename(columns={'engagementMetricsDate': 'date'})\n",
    "\n",
    "# change datatypes\n",
    "Y['date'] = pd.to_datetime(Y['date'])\n",
    "\n",
    "# reset index\n",
    "Y = Y.set_index('date').to_period('D')\n",
    "Y.index = Y.index - 1\n",
    "Y = Y.reset_index()\n",
    "\n",
    "# rename and select columns\n",
    "cols_Y = {\n",
    "    'date': 'Dt',\n",
    "    'playerId': 'IdPlayer',\n",
    "    'target1': 'target1',\n",
    "    'target2': 'target2',\n",
    "    'target3': 'target3',\n",
    "    'target4': 'target4'\n",
    "}\n",
    "Y = Y[list(cols_Y)]\n",
    "Y.columns = list(cols_Y.values())\n",
    "Y['Dt'] = Y['Dt'].astype('datetime64[ns]')\n",
    "Y = create_id(Y, ['Dt', 'IdPlayer'], 'Player')\n",
    "\n",
    "pd.to_pickle(Y, processed_data_path + 'targets.pkl')\n",
    "\n",
    "del Y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Player Box Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 34.8 s\n",
      "Wall time: 59.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# load the data\n",
    "df_playerBoxScores = unpack_data(df_train, dfs = ['playerBoxScores'])['playerBoxScores']\n",
    "\n",
    "# Cria o dataset de jogos\n",
    "cols = {\n",
    "    # columns related to other dimensions\n",
    "    'gamePk': 'IdGame',\n",
    "    'gameDate': 'DtGame',\n",
    "    'gameTimeUTC': 'DtGameUTC',\n",
    "    'playerId': 'IdPlayer',\n",
    "    'teamId': 'IdTeam',\n",
    "    'jerseyNum': 'NuJersey',\n",
    "    'positionCode': 'CdPosition',\n",
    "    # suggested column\n",
    "    'strikeOutsPitching': 'NuStrikeOutsPitching',\n",
    "}  \n",
    "# numeric columns\n",
    "for numeric_col in list(df_playerBoxScores.columns[12:]):\n",
    "    # skip the columns that contains data about pitching due the amount of Nan values\n",
    "    if 'Pitching' not in numeric_col:\n",
    "        cols[numeric_col] = 'Nu' + numeric_col[0].upper() + numeric_col[1:] + '_Player'\n",
    "\n",
    "df_playerBoxScores = df_playerBoxScores[list(cols)]\n",
    "df_playerBoxScores.columns = list(cols.values())\n",
    "\n",
    "# df_playerBoxScores['DtGame'] = df_playerBoxScores['DtGame'] + \" 00:00:00\"\n",
    "df_playerBoxScores['DtGame'] = df_playerBoxScores['DtGame'].astype('datetime64[ns]')\n",
    "df_playerBoxScores['DtGameUTC'] = df_playerBoxScores['DtGameUTC'].astype('datetime64[ns]')\n",
    "df_playerBoxScores = create_id(df_playerBoxScores, ['DtGame', 'IdPlayer'], 'Player')\n",
    "df_playerBoxScores = create_id(df_playerBoxScores, ['DtGame', 'IdTeam'], 'Team')\n",
    "df_playerBoxScores = create_id(df_playerBoxScores, ['DtGame', 'IdGame'], 'Game')\n",
    "\n",
    "# Salva o dataset\n",
    "pd.to_pickle(df_playerBoxScores, processed_data_path + 'playerBoxScores.pkl')\n",
    "\n",
    "del df_playerBoxScores"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Team Box Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2.03 s\n",
      "Wall time: 4.26 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_tbs = unpack_data(df_train, dfs = ['teamBoxScores'])['teamBoxScores']\n",
    "\n",
    "cols = {\n",
    "    'gameDate': 'DtGame',\n",
    "    'teamId': 'IdTeam',\n",
    "    'home': 'FlgHome',\n",
    "    'gamePk': 'IdGame',\n",
    "}\n",
    "\n",
    "for numeric_col in list(df_tbs.columns[4:]):\n",
    "    cols[numeric_col] = 'Nu' + numeric_col[0].upper() + numeric_col[1:] + '_Team'\n",
    "\n",
    "df_tbs = df_tbs[list(cols)]\n",
    "df_tbs.columns = list(cols.values())\n",
    "\n",
    "df_tbs['DtGame'] = df_tbs['DtGame'].astype('datetime64[ns]')\n",
    "df_tbs = create_id(df_tbs, ['DtGame', 'IdTeam'], 'Team')\n",
    "df_tbs = create_id(df_tbs, ['DtGame', 'IdGame'], 'Game')\n",
    "df_tbs['FlgHome'] = df_tbs['FlgHome'].astype('bool')\n",
    "\n",
    "pd.to_pickle(df_tbs, processed_data_path + 'teamBoxScores.pkl')\n",
    "\n",
    "del df_tbs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.58 s\n",
      "Wall time: 3.48 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_games = unpack_data(df_train, dfs = ['games'])['games']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "cols = {\n",
    "    'gamePk': 'IdGame',\n",
    "    'gameType': 'CdGameType',\n",
    "    'season': 'NuSeason',\n",
    "    'gameDate': 'DtGame',\n",
    "    'codedGameState': 'CdGameState',\n",
    "    'detailedGameState': 'CdGameState',\n",
    "    'isTie': 'FlgTie',\n",
    "    'gameNumber': 'NuGame',\n",
    "    'doubleHeader': 'CdDoubleHeader',\n",
    "    'dayNight': 'CdDayNight',\n",
    "    'scheduledInnings': 'NuScheduledInnings',\n",
    "    'gamesInSeries': 'NuGamesInSeries',\n",
    "    'homeId': 'IdHomeTeam',\n",
    "    'homeWins': 'NuWinsHomeTeam',\n",
    "    'homeLosses': 'NuLossesHomeTeam',\n",
    "    'homeWinPct': 'NuWinPctHomeTeam',\n",
    "    'homeWinner': 'FlgWinnerHomeTeam',\n",
    "    'homeScore': 'NuScoreHomeTeam',\n",
    "    'awayId': 'IdAwayTeam',\n",
    "    'awayWins': 'NuWinsAwayTeam',\n",
    "    'awayLosses': 'NuLossesAwayTeam',\n",
    "    'awayWinPct': 'NuWinPctAwayTeam',\n",
    "    'awayWinner': 'FlgWinnerAwayTeam',\n",
    "    'awayScore': 'NuScoreAwayTeam',\n",
    "}\n",
    "\n",
    "df_games = df_games[list(cols)]\n",
    "df_games.columns = list(cols.values())\n",
    "\n",
    "df_games['DtGame'] = df_games['DtGame'].astype('datetime64[ns]')\n",
    "df_games = create_id(df_games, ['DtGame', 'IdGame'], 'Game')\n",
    "\n",
    "pd.to_pickle(df_games, processed_data_path + 'games.pkl')\n",
    "\n",
    "del df_games"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Other datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
