{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform Data\n",
    "\n",
    "Notebook que irá conter o código para o processamento e transformações de dados. Este notebook deve ser rodado após o notebook `pre-process-data.ipynb`.\n",
    "\n",
    "os dados \"crus\" estão localizados em `/src/data/raw-data` e os dados tratados estão salvos em `/src/data/processed-data`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pickle as pkl\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# disable warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Variables\n",
    "# file paths\n",
    "raw_data_path = '../data/raw-data/'\n",
    "processed_data_path = '../data/processed-data/'\n",
    "\n",
    "\n",
    "TARGET_COLS = ['target1', 'target2', 'target3', 'target4']\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "TEST_SPLIT_DATE = '2021-04-30'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data\n",
    "df_targets = pd.read_pickle(processed_data_path + 'targets.pkl')\n",
    "df_pbs = pd.read_pickle(processed_data_path + 'playerBoxScores.pkl')\n",
    "df_tbs = pd.read_pickle(processed_data_path + 'teamBoxScores.pkl')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transformations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce Memory Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.api.types import is_datetime64_any_dtype as is_datetime\n",
    "\n",
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object and is_datetime(df[col]) == False and col_type != 'category':\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        elif is_datetime(df[col]) == True:\n",
    "            df[col] = df[col].astype('datetime64[ns]')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Df Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 102.84 MB\n",
      "Memory usage after optimization is: 71.99 MB\n",
      "Decreased by 30.0%\n"
     ]
    }
   ],
   "source": [
    "df_targets = reduce_mem_usage(df_targets);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Player Box Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 95.55 MB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 33.32 MB\n",
      "Decreased by 65.1%\n"
     ]
    }
   ],
   "source": [
    "df_pbs = reduce_mem_usage(df_pbs);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Team Box Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 6.72 MB\n",
      "Memory usage after optimization is: 1.43 MB\n",
      "Decreased by 78.6%\n"
     ]
    }
   ],
   "source": [
    "df_tbs = reduce_mem_usage(df_tbs);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting and Shifting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funções auxiliares para o pré-processamento dos dados\n",
    "def sort_df(df: pd.DataFrame, columns: list = ['IdPlayer', 'Dt']) -> None:\n",
    "    \"\"\"Sort the dataframe by the columns passed as argument.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Dataframe to be sorted.\n",
    "        columns (list, optional): Columns to sort the dataframe. Defaults to ['IdPlayer', 'Dt'].\n",
    "        \n",
    "        Returns:\n",
    "            None\n",
    "    \"\"\"\n",
    "    df.sort_values(by=columns, inplace=True)\n",
    "    # reset index\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "def shift_targets(df, shift_vals: list = [1, 2, 3, 4, 5, 6, 7, 14, 30]):\n",
    "    \"\"\"Shift the targets by the values passed as argument.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Dataframe to be shifted.\n",
    "        shift_vals (list, optional): Values to shift the targets. Defaults to [1, 2, 3, 4, 5, 6, 7, 14, 30].\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Dataframe with the shifted targets.\n",
    "    \"\"\"\n",
    "    df_aux = pd.DataFrame()\n",
    "    # Iterate over players to make the shift only using the player data\n",
    "    for player in df['IdPlayer'].unique():\n",
    "        df_player = df[df['IdPlayer'] == player]\n",
    "        # Iterate over the pre-defined shift values\n",
    "        for shift_val in shift_vals:\n",
    "            # Iterate over the targets\n",
    "            for target in TARGET_COLS:\n",
    "                # Make the shift\n",
    "                df_player[f'{target}_shift_{shift_val}'] = df_player[target].shift(shift_val)\n",
    "        # Concatenate the player data with the rest of the data\n",
    "        df_aux = pd.concat([df_aux, df_player], axis=0)\n",
    "        # Remove the player data from memory\n",
    "        del df_player\n",
    "    # df.dropna(inplace=True)\n",
    "    return df_aux\n",
    "\n",
    "\n",
    "def train_test_split(\n",
    "    df: pd.DataFrame\n",
    "    ,test_split_date: str = TEST_SPLIT_DATE\n",
    "    ):\n",
    "    \"\"\"Split the dataframe into train and test sets.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Dataframe to be split.\n",
    "        test_split_date (str, optional): Date to split the dataframe. Defaults to TEST_SPLIT_DATE.\n",
    "    \"\"\"\n",
    "\n",
    "    train = df[(df.Dt <= \"2021-01-31\") & (df.Dt >= \"2018-01-01\")] \n",
    "    val = df[(df.Dt <= \"2021-04-30\") & (df.Dt >= \"2021-02-01\")] \n",
    "    test = df[(df.Dt <= \"2021-07-31\") & (df.Dt >= \"2021-05-01\")]\n",
    "    # train.to_csv('train.csv', index=None)\n",
    "    # val.to_csv('validation.csv', index=None) \n",
    "    # test.to_csv('test.csv', index=None) \n",
    "\n",
    "    return train, test, val\n",
    "\n",
    "\n",
    "def x_y_split(df: pd.DataFrame, target_cols: list = TARGET_COLS):\n",
    "    \"\"\"Split the dataframe into x and y sets.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Dataframe to be split.\n",
    "    \"\"\"\n",
    "    y = df[target_cols]\n",
    "    x = df.drop(target_cols, axis=1)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3min 18s\n",
      "Wall time: 4min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sort_df(df_targets)\n",
    "df_train = shift_targets(df_targets, shift_vals=[1, 2, 3, 4, 5, 6, 7])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the datetime col into new features\n",
    "df_train['DtYear'] = df_train['Dt'].dt.year\n",
    "df_train['DtMonth'] = df_train['Dt'].dt.month\n",
    "df_train['DtDay'] = df_train['Dt'].dt.day\n",
    "df_train['DtDayOfWeek'] = df_train['Dt'].dt.dayofweek\n",
    "df_train['DtDayOfYear'] = df_train['Dt'].dt.dayofyear\n",
    "df_train['DtQuarter'] = df_train['Dt'].dt.quarter\n",
    "# get the hour and minute from the PBS\n",
    "df_pbs['DtHour'] = df_pbs['DtGameUTC'].dt.hour\n",
    "df_pbs['DtMinute'] = df_pbs['DtGameUTC'].dt.minute\n",
    "df_pbs['DtHour'][df_pbs['DtHour'] == 0] = 24"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining Datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Player Box Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.merge(df_train, df_pbs, on=['IdDtPlayer'], how='left')\n",
    "\n",
    "# Substitui os valores Nan das seguintes colunas por 0\n",
    "f = [c for c in df_train.columns if c not in ['IdGame', 'DtGame', 'DtGameUTC',\n",
    "'IdPlayer_y','IdTeam','NuJersey','CdPosition', 'target1_shift_1', 'target2_shift_1',\n",
    "'target3_shift_1','target1_shift_2', 'target3_shift_2', 'target4_shift_2',\n",
    "'target1_shift_3','target2_shift_3','target3_shift_3','target4_shift_3',\n",
    "'target1_shift_4','target2_shift_4','target3_shift_4','target4_shift_4',\n",
    "'target1_shift_5','target2_shift_5','target3_shift_5','target4_shift_5',\n",
    "'target1_shift_6','target2_shift_6','target3_shift_6','target4_shift_6',\n",
    "'target1_shift_7','target2_shift_7','target3_shift_7','target4_shift_7']]\n",
    "\n",
    "df_train[f] = df_train[f].fillna(0)        \n",
    "\n",
    "# Remove os na das seguintes colunas\n",
    "df_train = df_train.dropna(subset=[             \n",
    "    'target1_shift_1', 'target2_shift_1', 'target3_shift_1', 'target1_shift_2',\n",
    "    'target3_shift_2', 'target4_shift_2', 'target1_shift_3', 'target2_shift_3',\n",
    "    'target3_shift_3', 'target4_shift_3', 'target1_shift_4', 'target2_shift_4',\n",
    "    'target3_shift_4', 'target4_shift_4', 'target1_shift_5', 'target3_shift_5',\n",
    "    'target4_shift_5', 'target1_shift_6', 'target2_shift_6', 'target3_shift_6',\n",
    "    'target4_shift_6', 'target1_shift_7', 'target2_shift_7', 'target3_shift_7',\n",
    "    'target4_shift_7'])\n",
    "\n",
    "# Dropa colunas com vários valores Nan\n",
    "df_train.drop(['IdGame',\n",
    "             'DtGame',\n",
    "             'DtGameUTC',\n",
    "             'IdPlayer_y',\n",
    "             'IdTeam',\n",
    "             'NuJersey',\n",
    "             'CdPosition',\n",
    "             'IdDtPlayer'], axis = 1, inplace = True)\n",
    "\n",
    "\n",
    "df_train.rename(columns={'IdPlayer_x': 'IdPlayer'}, inplace=True)\n",
    "# df_train.info(null_counts=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Team Box Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.merge(df_train, df_tbs, on = ['IdDtTeam'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2693260 entries, 0 to 2693259\n",
      "Columns: 148 entries, Dt to IdDtGame_y\n",
      "dtypes: datetime64[ns](2), float16(80), float64(55), int32(1), int64(6), object(4)\n",
      "memory usage: 1.8+ GB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 1818.49 MB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 873.29 MB\n",
      "Decreased by 52.0%\n"
     ]
    }
   ],
   "source": [
    "df_train = reduce_mem_usage(df_train);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Prepared Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_targets.to_pickle(processed_data_path + 'targets.pkl')\n",
    "df_pbs.to_pickle(processed_data_path + 'playerBoxScores.pkl')\n",
    "\n",
    "df_train.to_pickle(processed_data_path + 'train.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2693260 entries, 0 to 2693259\n",
      "Columns: 148 entries, Dt to IdDtGame_y\n",
      "dtypes: datetime64[ns](2), float16(134), float32(1), int16(2), int32(1), int8(4), object(4)\n",
      "memory usage: 873.3+ MB\n"
     ]
    }
   ],
   "source": [
    "pd.read_pickle(processed_data_path + 'train.pkl').info(null_counts=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
